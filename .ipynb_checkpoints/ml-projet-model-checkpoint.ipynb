{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
       "3         Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n",
       "4         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0       2    2008        WD         Normal  \n",
       "1         NaN       0       5    2007        WD         Normal  \n",
       "2         NaN       0       9    2008        WD         Normal  \n",
       "3         NaN       0       2    2006        WD        Abnorml  \n",
       "4         NaN       0      12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '/kaggle/input/house-prices-advanced-regression-techniques/'\n",
    "train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "test_index = test.Id\n",
    "train = train.drop(['Id'], axis=1)\n",
    "test = test.drop(['Id'], axis=1)\n",
    "\n",
    "# Concat the train data and test data\n",
    "target = train['SalePrice']\n",
    "train_index = len(train) - 1\n",
    "all_data = pd.concat([train.drop(['SalePrice'], axis=1),test]).reset_index(drop=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(all_data):\n",
    "    all_data['MSSubClass'] = all_data['MSSubClass'].astype('str')\n",
    "    \n",
    "    ###### Fill missing values\n",
    "    all_data['LotFrontage'] = all_data.groupby(['Neighborhood'])['LotFrontage'].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    # # MasVnrArea: Masonry veneer area in square feet\n",
    "    all_data['MasVnrArea'] = all_data['MasVnrArea'].fillna(all_data['MasVnrArea'].mode()[0])\n",
    "\n",
    "    # # GarageYrBlt: Year garage was built\n",
    "    all_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(all_data['GarageYrBlt'].median())\n",
    "\n",
    "    # # Bsmt & Garage\n",
    "    for c in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\\\n",
    "             'GarageCars', 'GarageArea']:\n",
    "        all_data[c] = all_data[c].fillna(0)\n",
    "    \n",
    "    # MSZoning\n",
    "    # all_data['MSZoning'].hist()\n",
    "    all_data['MSZoning'] = all_data.groupby(['MSSubClass']).MSZoning.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "    # Alley, PoolQC,Fence, MiscFeature\n",
    "    for c in ['Alley', 'PoolQC', 'MiscFeature']:\n",
    "        all_data[c] = all_data[c].fillna('None')\n",
    "\n",
    "    # MasVnrType, Electrical, Utilities, \n",
    "    all_data['MasVnrType'] = all_data['MasVnrType'].fillna('None')\n",
    "    for c in ['Electrical', 'Utilities', 'Exterior1st', 'Exterior2nd', 'Functional', 'SaleType']:\n",
    "        all_data[c] = all_data[c].fillna(all_data[c].mode()[0])\n",
    "\n",
    "    # KitchenQual\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].fillna('TA')\n",
    "\n",
    "    # Bsmt\n",
    "    for c in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']:\n",
    "        all_data[c] = all_data[c].fillna('None')\n",
    "\n",
    "    # Garage\n",
    "    for c in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "        all_data[c] = all_data[c].fillna('None')\n",
    "\n",
    "    # FireplaceQu, Fence\n",
    "    all_data['FireplaceQu'] = all_data['FireplaceQu'].fillna('None')\n",
    "    all_data['Fence'] = all_data['Fence'].fillna('None')    \n",
    "        \n",
    "        \n",
    "        \n",
    "    ###### manipulating features\n",
    "    all_data['diff_build_remodel'] = all_data['YearRemodAdd'] - all_data['YearBuilt']\n",
    "    all_data['fresh'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "    \n",
    "    # create a MasVnrArea band \n",
    "    all_data['MasVnrArea_band'] = all_data['MasVnrArea'].map(lambda x: 0 if x==0.0 else\n",
    "                                                 1 if x<400 else\n",
    "                                                 2)\n",
    "\n",
    "    # create feature total_FlrSF\n",
    "    all_data['total_FlrSF'] = all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "    \n",
    "    all_data['total_porch'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + all_data['ScreenPorch'] + all_data['3SsnPorch']\n",
    "    all_data['OpenPorchSF_have'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x>0.0 else 0)\n",
    "    all_data['have_porch'] = all_data['total_porch'].apply(lambda x: 1 if x>0.0 else 0)\n",
    "    \n",
    "    # create feature total_bath\n",
    "    all_data['total_bath'] = 0.5 * all_data['HalfBath'] + all_data['BsmtFullBath'] + 0.5 * all_data['BsmtHalfBath'] + all_data['FullBath']\n",
    "    \n",
    "    all_data['Garage_age'] = all_data['YrSold'] - all_data['GarageYrBlt']\n",
    "    all_data['Garage_age'] = all_data['Garage_age'].apply(lambda x: 0 if x<0 else x)\n",
    "    \n",
    "    # Fireplaces\n",
    "    all_data['Fireplaces_exist'] = all_data['Fireplaces'].apply(lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    # Skewness data transformation\n",
    "    num_cols = all_data.select_dtypes(exclude='object').columns\n",
    "    skewness = all_data[num_cols].skew().abs().sort_values(ascending=False)\n",
    "    cols_to_transform = skewness[skewness > 0.75].index\n",
    "    for c in cols_to_transform:\n",
    "        try:\n",
    "            all_data[c] = boxcox1p(all_data[c], 0.15)\n",
    "        except:\n",
    "            print('columns: ', c)\n",
    "    \n",
    "    all_data['Street'] = all_data['Street'].map({'Pave':1, 'Grvl':0})\n",
    "    all_data['Alley'] = all_data['Alley'].map({'Pave':1, 'Grvl':0, 'None':-1})\n",
    "    all_data['LotShape'] = all_data['LotShape'].map({'IR3':0, 'IR2':1, 'IR1':2, 'Reg':3})\n",
    "    all_data['LandSlope'] = all_data['LandSlope'].map({'Gtl':0, 'Mod':1, 'Sev':2})\n",
    "\n",
    "    all_data['HouseStyle'] = all_data['HouseStyle'].map({'1Story':1,\n",
    "                                                         '1.5Unf':2,\n",
    "                                                        '1.5Fin':3,\n",
    "                                                        '2Story':4,\n",
    "                                                        '2.5Unf':5,\n",
    "                                                        '2.5Fin':6,\n",
    "                                                        'SFoyer':4,\n",
    "                                                        'SLvl':7})\n",
    "\n",
    "    for c in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']:\n",
    "        all_data[c] = all_data[c].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4,'None':-1})\n",
    "\n",
    "    all_data['BsmtExposure'] = all_data['BsmtExposure'].map({'None':-1,'No':0,'Mn':1,'Av':2,'Gd':3})\n",
    "    for c in ['BsmtFinType1', 'BsmtFinType2']:\n",
    "        all_data[c] = all_data[c].map({'None':-1,\n",
    "                                      'Unf':0,\n",
    "                                      'LwQ':1,\n",
    "                                      'Rec':2,\n",
    "                                      'BLQ':3,'ALQ':4,'GLQ':5})\n",
    "    all_data['CentralAir'] = all_data['CentralAir'].map({'N':0, 'Y':1})\n",
    "\n",
    "    all_data['GarageType'] = all_data['GarageType'].apply(lambda x: 2 if x in ['Attchd', 'BuiltIn']\n",
    "                                                         else 0 if x=='None'\n",
    "                                                         else 1)\n",
    "    all_data['GarageFinish'] = all_data['GarageFinish'].apply(lambda x: 2 if x in ['Fin', 'RFn']\n",
    "                                                         else 1 if x=='Unf'\n",
    "                                                         else 0)\n",
    "\n",
    "    all_data['PavedDrive'] = all_data['PavedDrive'].map({'N':-1, 'P':0, 'Y':1})\n",
    "\n",
    "    all_data['SaleType'] = all_data['SaleType'].apply(lambda x:1 if x in ['WD', 'NEW', 'CWD','Con']\n",
    "                                               else 0 if x=='Oth'\n",
    "                                               else 2)\n",
    "    \n",
    "    \n",
    "    # Drop features\n",
    "    all_data = all_data.drop(['BsmtFinSF2', 'BedroomAbvGr', 'KitchenAbvGr', 'LowQualFinSF', 'MiscVal', 'Utilities', 'PoolArea', '3SsnPorch',\\\n",
    "                             'have_porch', 'OpenPorchSF_have', 'BsmtFullBath', 'HalfBath', 'Fireplaces_exist', 'ScreenPorch', 'YrSold','Fireplaces'], axis=1)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1 = data_preprocessing(all_data)\n",
    "train_data = all_data1.iloc[:1460,:].join(train['SalePrice'])\n",
    "test_data = all_data1.iloc[1460:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = all_data1.select_dtypes(include=['O']).columns\n",
    "num_features = all_data1.select_dtypes(exclude=['O']).columns\n",
    "cat_data = all_data1[cat_features]\n",
    "num_data = all_data1[num_features]\n",
    "\n",
    "num_data_train = num_data.iloc[:1460,:]\n",
    "cat_data_train = cat_data.iloc[:1460,:]\n",
    "\n",
    "num_data_test = num_data.iloc[1460:,]\n",
    "cat_data_test = cat_data.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num features\n",
    "scaler = StandardScaler()\n",
    "num_data_train = scaler.fit_transform(num_data_train)\n",
    "num_data_test = scaler.fit_transform(num_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "# Cat features\n",
    "categories = []\n",
    "most_appear_each_categories = {}\n",
    "for col in cat_data.columns:\n",
    "    cat_data.loc[:,col] = col + \"__\" + cat_data[col].astype(str)\n",
    "    most_appear_each_categories[col] = list(cat_data[col].value_counts().index)[0]\n",
    "    categories.append(cat_data[col].unique())\n",
    "categories = np.hstack(categories)\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(categories)\n",
    "for col in cat_data.columns:\n",
    "    cat_data.loc[:, col] = le.transform(cat_data[col])\n",
    "num_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_x = cat_data.iloc[:1460,:]\n",
    "cat_test_x = cat_data.iloc[1460:,:]\n",
    "\n",
    "train_y = np.log(train_data.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Embedding, Input, Concatenate, BatchNormalization, Dropout\n",
    "from keras import regularizers\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def build_model():\n",
    "    # Inputs\n",
    "    input_dense = Input(shape=(num_data_train.shape[1],), name='dense_data')\n",
    "    input_cat = Input(shape=(cat_train_x.shape[1],), name='categorical_data')\n",
    "    \n",
    "    # Embedding\n",
    "    embedding = Embedding(num_classes, 3, embeddings_regularizer=regularizers.l2(1e-4))\n",
    "    embedding_cat = embedding(input_cat)\n",
    "    embedding_cat = Flatten()(embedding_cat)\n",
    "    \n",
    "    # Combine features\n",
    "    cf = Concatenate(name = 'combined_features')([input_dense, embedding_cat])\n",
    "    \n",
    "    cf = Dense(128, activation='relu')(cf)\n",
    "    cf = BatchNormalization()(cf)\n",
    "    cf = Dropout(0.5)(cf)\n",
    "    \n",
    "    cf = Dense(64, activation='relu')(cf)\n",
    "    cf = BatchNormalization()(cf)\n",
    "    cf = Dropout(0.5)(cf)\n",
    "    \n",
    "    cf = Dense(16, activation='relu')(cf)\n",
    "    cf = BatchNormalization()(cf)\n",
    "    cf = Dropout(0.2)(cf)\n",
    "    \n",
    "    output = Dense(1, activation=None, name='output_regression')(cf)\n",
    "    \n",
    "    model = Model(inputs=[input_dense, input_cat], outputs=output)\n",
    "    model.compile(loss='msle', optimizer=optimizers.Adam(learning_rate=0.002, decay=0.), metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "categorical_data (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 3)        498         categorical_data[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_data (InputLayer)         (None, 53)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 60)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "combined_features (Concatenate) (None, 113)          0           dense_data[0][0]                 \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          14592       combined_features[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           1040        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16)           64          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_regression (Dense)       (None, 1)            17          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,235\n",
      "Trainable params: 24,819\n",
      "Non-trainable params: 416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/2000\n",
      "1168/1168 [==============================] - 1s 945us/step - loss: 4.9774 - mse: 146.5963 - val_loss: 6.5260 - val_mse: 160.8895\n",
      "Epoch 2/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.6949 - mse: 144.9729 - val_loss: 6.2672 - val_mse: 160.0657\n",
      "Epoch 3/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.2587 - mse: 143.0807 - val_loss: 5.4261 - val_mse: 159.7958\n",
      "Epoch 4/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.9488 - mse: 144.0050 - val_loss: 4.7635 - val_mse: 163.4550\n",
      "Epoch 5/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 3.6204 - mse: 141.7296 - val_loss: 4.3231 - val_mse: 168.5212\n",
      "Epoch 6/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 3.3751 - mse: 142.1566 - val_loss: 3.9867 - val_mse: 173.6995\n",
      "Epoch 7/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.1635 - mse: 140.4329 - val_loss: 3.6623 - val_mse: 177.8024\n",
      "Epoch 8/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 2.9606 - mse: 139.9059 - val_loss: 3.3320 - val_mse: 179.9217\n",
      "Epoch 9/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.7967 - mse: 138.3580 - val_loss: 3.0508 - val_mse: 180.1721\n",
      "Epoch 10/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.6228 - mse: 138.7807 - val_loss: 2.8344 - val_mse: 185.2098\n",
      "Epoch 11/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.4654 - mse: 137.8941 - val_loss: 2.6466 - val_mse: 190.6803\n",
      "Epoch 12/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3238 - mse: 138.7532 - val_loss: 2.4778 - val_mse: 195.4469\n",
      "Epoch 13/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.2395 - mse: 140.0488 - val_loss: 2.3381 - val_mse: 192.2414\n",
      "Epoch 14/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 2.0936 - mse: 138.5197 - val_loss: 2.2080 - val_mse: 189.5710\n",
      "Epoch 15/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 2.0090 - mse: 137.2853 - val_loss: 2.0359 - val_mse: 188.1472\n",
      "Epoch 16/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9180 - mse: 139.5173 - val_loss: 1.8900 - val_mse: 183.9194\n",
      "Epoch 17/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.8112 - mse: 130.7850 - val_loss: 1.7729 - val_mse: 182.2022\n",
      "Epoch 18/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.7071 - mse: 132.5072 - val_loss: 1.5833 - val_mse: 176.0710\n",
      "Epoch 19/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6195 - mse: 136.8943 - val_loss: 1.3556 - val_mse: 164.6342\n",
      "Epoch 20/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.4854 - mse: 134.8355 - val_loss: 1.1664 - val_mse: 155.4263\n",
      "Epoch 21/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.3447 - mse: 130.7427 - val_loss: 0.9848 - val_mse: 147.3292\n",
      "Epoch 22/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.2353 - mse: 130.1333 - val_loss: 0.8848 - val_mse: 146.4360\n",
      "Epoch 23/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.1668 - mse: 129.0214 - val_loss: 0.8106 - val_mse: 145.0834\n",
      "Epoch 24/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.1092 - mse: 129.4595 - val_loss: 0.7399 - val_mse: 142.3052\n",
      "Epoch 25/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.0447 - mse: 133.3148 - val_loss: 0.6949 - val_mse: 145.5688\n",
      "Epoch 26/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.9917 - mse: 129.2189 - val_loss: 0.6619 - val_mse: 151.2094\n",
      "Epoch 27/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.9652 - mse: 134.2055 - val_loss: 0.6387 - val_mse: 152.9165\n",
      "Epoch 28/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.9019 - mse: 128.7074 - val_loss: 0.6231 - val_mse: 161.9416\n",
      "Epoch 29/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.8768 - mse: 133.4810 - val_loss: 0.6395 - val_mse: 182.8426\n",
      "Epoch 30/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.8188 - mse: 127.5474 - val_loss: 0.6266 - val_mse: 181.2427\n",
      "Epoch 31/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.8123 - mse: 137.2303 - val_loss: 0.6075 - val_mse: 181.2144\n",
      "Epoch 32/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.8033 - mse: 126.9516 - val_loss: 0.6137 - val_mse: 190.6955\n",
      "Epoch 33/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.7474 - mse: 124.4262 - val_loss: 0.5873 - val_mse: 187.8248\n",
      "Epoch 34/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.7267 - mse: 133.0241 - val_loss: 0.5641 - val_mse: 178.5641\n",
      "Epoch 35/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.7352 - mse: 132.3488 - val_loss: 0.5264 - val_mse: 166.1654\n",
      "Epoch 36/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.6532 - mse: 131.0375 - val_loss: 0.5167 - val_mse: 156.1417\n",
      "Epoch 37/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.6555 - mse: 132.1213 - val_loss: 0.5092 - val_mse: 146.4625\n",
      "Epoch 38/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.6451 - mse: 135.1638 - val_loss: 0.5017 - val_mse: 139.9044\n",
      "Epoch 39/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.6297 - mse: 135.1959 - val_loss: 0.4970 - val_mse: 136.9172\n",
      "Epoch 40/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.6141 - mse: 127.3595 - val_loss: 0.4908 - val_mse: 136.7392\n",
      "Epoch 41/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.6080 - mse: 127.9472 - val_loss: 0.4852 - val_mse: 135.0512\n",
      "Epoch 42/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.5980 - mse: 137.5844 - val_loss: 0.4811 - val_mse: 133.5789\n",
      "Epoch 43/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.5992 - mse: 138.0484 - val_loss: 0.4768 - val_mse: 133.1650\n",
      "Epoch 44/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.5858 - mse: 132.9668 - val_loss: 0.4743 - val_mse: 134.1897\n",
      "Epoch 45/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.5897 - mse: 129.9218 - val_loss: 0.4751 - val_mse: 137.7310\n",
      "Epoch 46/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.5733 - mse: 140.4140 - val_loss: 0.4736 - val_mse: 136.9757\n",
      "Epoch 47/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.5735 - mse: 139.5517 - val_loss: 0.4713 - val_mse: 139.1378\n",
      "Epoch 48/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.5623 - mse: 139.2562 - val_loss: 0.4716 - val_mse: 123.3381\n",
      "Epoch 49/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.5592 - mse: 145.9628 - val_loss: 0.4700 - val_mse: 118.0738\n",
      "Epoch 50/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.5449 - mse: 136.5882 - val_loss: 0.4672 - val_mse: 115.0360\n",
      "Epoch 51/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.5020 - mse: 139.3815 - val_loss: 0.4478 - val_mse: 110.4999\n",
      "Epoch 52/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.4896 - mse: 127.4742 - val_loss: 0.3852 - val_mse: 102.1473\n",
      "Epoch 53/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.4143 - mse: 141.2847 - val_loss: 0.2751 - val_mse: 83.7356\n",
      "Epoch 54/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.3977 - mse: 121.9393 - val_loss: 0.1746 - val_mse: 76.9077\n",
      "Epoch 55/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.3095 - mse: 122.2310 - val_loss: 0.1638 - val_mse: 79.1342\n",
      "Epoch 56/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.3607 - mse: 119.5409 - val_loss: 0.1636 - val_mse: 83.7443\n",
      "Epoch 57/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.4037 - mse: 112.7032 - val_loss: 0.1634 - val_mse: 102.2783\n",
      "Epoch 58/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2540 - mse: 111.6150 - val_loss: 0.1643 - val_mse: 126.1845\n",
      "Epoch 59/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2563 - mse: 122.3966 - val_loss: 0.1637 - val_mse: 133.6089\n",
      "Epoch 60/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2496 - mse: 109.8816 - val_loss: 0.1612 - val_mse: 129.9646\n",
      "Epoch 61/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2455 - mse: 111.3245 - val_loss: 0.1585 - val_mse: 127.5355\n",
      "Epoch 62/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2404 - mse: 122.0578 - val_loss: 0.1576 - val_mse: 121.2216\n",
      "Epoch 63/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2518 - mse: 130.6911 - val_loss: 0.1561 - val_mse: 117.8836\n",
      "Epoch 64/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2207 - mse: 115.4968 - val_loss: 0.1545 - val_mse: 112.1181\n",
      "Epoch 65/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2275 - mse: 113.7654 - val_loss: 0.1536 - val_mse: 104.5980\n",
      "Epoch 66/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2169 - mse: 121.0418 - val_loss: 0.1527 - val_mse: 96.8877\n",
      "Epoch 67/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2096 - mse: 90.0222 - val_loss: 0.1510 - val_mse: 92.9525\n",
      "Epoch 68/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2647 - mse: 97.3160 - val_loss: 0.1497 - val_mse: 90.3127\n",
      "Epoch 69/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2212 - mse: 100.6845 - val_loss: 0.1491 - val_mse: 88.8681\n",
      "Epoch 70/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2060 - mse: 91.2250 - val_loss: 0.1478 - val_mse: 87.1738\n",
      "Epoch 71/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2285 - mse: 100.3406 - val_loss: 0.1461 - val_mse: 90.3349\n",
      "Epoch 72/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2112 - mse: 116.0543 - val_loss: 0.1449 - val_mse: 92.2259\n",
      "Epoch 73/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2470 - mse: 107.4272 - val_loss: 0.1435 - val_mse: 92.3456\n",
      "Epoch 74/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2060 - mse: 108.1868 - val_loss: 0.1424 - val_mse: 98.6059\n",
      "Epoch 75/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2018 - mse: 91.8499 - val_loss: 0.1406 - val_mse: 101.4579\n",
      "Epoch 76/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2047 - mse: 92.9140 - val_loss: 0.1398 - val_mse: 103.4672\n",
      "Epoch 77/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2447 - mse: 110.1689 - val_loss: 0.1393 - val_mse: 95.8969\n",
      "Epoch 78/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2498 - mse: 93.9592 - val_loss: 0.1391 - val_mse: 89.2346\n",
      "Epoch 79/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2097 - mse: 108.3575 - val_loss: 0.1392 - val_mse: 88.3206\n",
      "Epoch 80/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.2051 - mse: 108.7402 - val_loss: 0.1408 - val_mse: 71.4038\n",
      "Epoch 81/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2067 - mse: 77.2832 - val_loss: 0.1413 - val_mse: 63.7607\n",
      "Epoch 82/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.2209 - mse: 89.1223 - val_loss: 0.1409 - val_mse: 64.9393\n",
      "Epoch 83/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.1944 - mse: 75.6073 - val_loss: 0.1404 - val_mse: 65.6357\n",
      "Epoch 84/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2518 - mse: 80.6954 - val_loss: 0.1402 - val_mse: 69.7958\n",
      "Epoch 85/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2500 - mse: 69.5943 - val_loss: 0.1400 - val_mse: 75.3180\n",
      "Epoch 86/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.2813 - mse: 82.3773 - val_loss: 0.1404 - val_mse: 81.0786\n",
      "Epoch 87/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2106 - mse: 65.2932 - val_loss: 0.1405 - val_mse: 84.4656\n",
      "Epoch 88/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1977 - mse: 67.5391 - val_loss: 0.1394 - val_mse: 82.3438\n",
      "Epoch 89/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.2358 - mse: 84.5864 - val_loss: 0.1390 - val_mse: 77.9471\n",
      "Epoch 90/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1815 - mse: 67.9464 - val_loss: 0.1390 - val_mse: 60.0632\n",
      "Epoch 91/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2136 - mse: 68.6737 - val_loss: 0.1389 - val_mse: 57.4209\n",
      "Epoch 92/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1799 - mse: 68.9281 - val_loss: 0.1388 - val_mse: 46.6764\n",
      "Epoch 93/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.1929 - mse: 64.6105 - val_loss: 0.1392 - val_mse: 36.3540\n",
      "Epoch 94/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2185 - mse: 57.0174 - val_loss: 0.1395 - val_mse: 29.3297\n",
      "Epoch 95/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1999 - mse: 49.4830 - val_loss: 0.1398 - val_mse: 28.2702\n",
      "Epoch 96/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.2101 - mse: 53.0525 - val_loss: 0.1395 - val_mse: 23.8355\n",
      "Epoch 97/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.1949 - mse: 44.6030 - val_loss: 0.1389 - val_mse: 23.2392\n",
      "Epoch 98/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2105 - mse: 47.9379 - val_loss: 0.1381 - val_mse: 26.9765\n",
      "Epoch 99/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1610 - mse: 44.6258 - val_loss: 0.1386 - val_mse: 26.3312\n",
      "Epoch 100/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.2172 - mse: 49.1694 - val_loss: 0.1391 - val_mse: 21.3178\n",
      "Epoch 101/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1783 - mse: 36.5069 - val_loss: 0.1390 - val_mse: 16.5905\n",
      "Epoch 102/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1731 - mse: 32.6678 - val_loss: 0.1150 - val_mse: 11.4410\n",
      "Epoch 103/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.1700 - mse: 34.8741 - val_loss: 0.1024 - val_mse: 9.5842\n",
      "Epoch 104/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1523 - mse: 26.8324 - val_loss: 0.1015 - val_mse: 9.2604\n",
      "Epoch 105/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1622 - mse: 40.0002 - val_loss: 0.1045 - val_mse: 10.1025\n",
      "Epoch 106/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1791 - mse: 35.0556 - val_loss: 0.0819 - val_mse: 7.2887\n",
      "Epoch 107/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1559 - mse: 30.0359 - val_loss: 0.0436 - val_mse: 2.7554\n",
      "Epoch 108/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1218 - mse: 23.8564 - val_loss: 0.0226 - val_mse: 2.2887\n",
      "Epoch 109/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1638 - mse: 22.0323 - val_loss: 0.0153 - val_mse: 2.1161\n",
      "Epoch 110/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1280 - mse: 19.0866 - val_loss: 0.0129 - val_mse: 2.3749\n",
      "Epoch 111/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.1511 - mse: 21.3906 - val_loss: 0.0125 - val_mse: 2.4223\n",
      "Epoch 112/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1220 - mse: 16.0981 - val_loss: 0.0132 - val_mse: 2.3154\n",
      "Epoch 113/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0966 - mse: 15.4031 - val_loss: 0.0118 - val_mse: 2.5225\n",
      "Epoch 114/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.1052 - mse: 18.2014 - val_loss: 0.0118 - val_mse: 2.6156\n",
      "Epoch 115/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1104 - mse: 13.6508 - val_loss: 0.0124 - val_mse: 2.8844\n",
      "Epoch 116/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0820 - mse: 10.7712 - val_loss: 0.0119 - val_mse: 2.7708\n",
      "Epoch 117/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.1055 - mse: 12.9820 - val_loss: 0.0119 - val_mse: 2.7844\n",
      "Epoch 118/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.1167 - mse: 14.5795 - val_loss: 0.0135 - val_mse: 3.2121\n",
      "Epoch 119/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0640 - mse: 8.6980 - val_loss: 0.0124 - val_mse: 2.8477\n",
      "Epoch 120/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0658 - mse: 10.4711 - val_loss: 0.0116 - val_mse: 2.5871\n",
      "Epoch 121/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0669 - mse: 8.3603 - val_loss: 0.0122 - val_mse: 2.8473\n",
      "Epoch 122/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0639 - mse: 10.6917 - val_loss: 0.0126 - val_mse: 3.0357\n",
      "Epoch 123/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0515 - mse: 9.9939 - val_loss: 0.0119 - val_mse: 2.8453\n",
      "Epoch 124/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0535 - mse: 10.3815 - val_loss: 0.0105 - val_mse: 2.4270\n",
      "Epoch 125/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0562 - mse: 7.7365 - val_loss: 0.0135 - val_mse: 3.5721\n",
      "Epoch 126/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0606 - mse: 8.5794 - val_loss: 0.0147 - val_mse: 4.1369\n",
      "Epoch 127/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0490 - mse: 8.8688 - val_loss: 0.0143 - val_mse: 3.9833\n",
      "Epoch 128/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0442 - mse: 7.9718 - val_loss: 0.0144 - val_mse: 4.0588\n",
      "Epoch 129/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0613 - mse: 8.4532 - val_loss: 0.0143 - val_mse: 4.0537\n",
      "Epoch 130/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0548 - mse: 9.4822 - val_loss: 0.0139 - val_mse: 3.9079\n",
      "Epoch 131/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0587 - mse: 11.0835 - val_loss: 0.0131 - val_mse: 3.5831\n",
      "Epoch 132/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0593 - mse: 11.2264 - val_loss: 0.0129 - val_mse: 3.5241\n",
      "Epoch 133/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0504 - mse: 10.9340 - val_loss: 0.0124 - val_mse: 3.3479\n",
      "Epoch 134/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0423 - mse: 9.4745 - val_loss: 0.0122 - val_mse: 3.2648\n",
      "Epoch 135/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0456 - mse: 8.7862 - val_loss: 0.0113 - val_mse: 2.9303\n",
      "Epoch 136/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0387 - mse: 8.3744 - val_loss: 0.0110 - val_mse: 2.8609\n",
      "Epoch 137/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0469 - mse: 8.3086 - val_loss: 0.0109 - val_mse: 2.8213\n",
      "Epoch 138/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0709 - mse: 9.0264 - val_loss: 0.0109 - val_mse: 2.8411\n",
      "Epoch 139/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0348 - mse: 10.6105 - val_loss: 0.0107 - val_mse: 2.8014\n",
      "Epoch 140/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0431 - mse: 8.4844 - val_loss: 0.0117 - val_mse: 3.1961\n",
      "Epoch 141/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0495 - mse: 7.8280 - val_loss: 0.0125 - val_mse: 3.5758\n",
      "Epoch 142/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0370 - mse: 9.7304 - val_loss: 0.0119 - val_mse: 3.3350\n",
      "Epoch 143/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0604 - mse: 13.0405 - val_loss: 0.0124 - val_mse: 3.5411\n",
      "Epoch 144/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0402 - mse: 9.5067 - val_loss: 0.0129 - val_mse: 3.8378\n",
      "Epoch 145/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0516 - mse: 8.9030 - val_loss: 0.0131 - val_mse: 3.9111\n",
      "Epoch 146/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0484 - mse: 9.2385 - val_loss: 0.0132 - val_mse: 3.9975\n",
      "Epoch 147/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0503 - mse: 9.2340 - val_loss: 0.0127 - val_mse: 3.7885\n",
      "Epoch 148/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0433 - mse: 11.8816 - val_loss: 0.0119 - val_mse: 3.4252\n",
      "Epoch 149/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0389 - mse: 8.4748 - val_loss: 0.0118 - val_mse: 3.3994\n",
      "Epoch 150/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0572 - mse: 9.8258 - val_loss: 0.0134 - val_mse: 4.1194\n",
      "Epoch 151/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0416 - mse: 9.6989 - val_loss: 0.0138 - val_mse: 4.3184\n",
      "Epoch 152/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0444 - mse: 10.5837 - val_loss: 0.0141 - val_mse: 4.5050\n",
      "Epoch 153/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0390 - mse: 12.7675 - val_loss: 0.0150 - val_mse: 4.9335\n",
      "Epoch 154/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0497 - mse: 11.7148 - val_loss: 0.0162 - val_mse: 5.6009\n",
      "Epoch 155/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0406 - mse: 13.1442 - val_loss: 0.0161 - val_mse: 5.6109\n",
      "Epoch 156/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0439 - mse: 10.9759 - val_loss: 0.0177 - val_mse: 6.4962\n",
      "Epoch 157/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0377 - mse: 9.8493 - val_loss: 0.0189 - val_mse: 7.2498\n",
      "Epoch 158/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0468 - mse: 10.6748 - val_loss: 0.0195 - val_mse: 7.6585\n",
      "Epoch 159/2000\n",
      "1168/1168 [==============================] - 0s 36us/step - loss: 0.0423 - mse: 11.2096 - val_loss: 0.0209 - val_mse: 8.6375\n",
      "Epoch 160/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0477 - mse: 12.3804 - val_loss: 0.0206 - val_mse: 8.4195\n",
      "Epoch 161/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0593 - mse: 13.1097 - val_loss: 0.0203 - val_mse: 8.2458\n",
      "Epoch 162/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0432 - mse: 12.1427 - val_loss: 0.0195 - val_mse: 7.7687\n",
      "Epoch 163/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0381 - mse: 12.8461 - val_loss: 0.0183 - val_mse: 7.0165\n",
      "Epoch 164/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0418 - mse: 11.0602 - val_loss: 0.0167 - val_mse: 6.0618\n",
      "Epoch 165/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0448 - mse: 10.6003 - val_loss: 0.0157 - val_mse: 5.5171\n",
      "Epoch 166/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0419 - mse: 10.9759 - val_loss: 0.0149 - val_mse: 5.0850\n",
      "Epoch 167/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0390 - mse: 11.2119 - val_loss: 0.0147 - val_mse: 5.0164\n",
      "Epoch 168/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0427 - mse: 12.5283 - val_loss: 0.0136 - val_mse: 4.4321\n",
      "Epoch 169/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0416 - mse: 11.4580 - val_loss: 0.0129 - val_mse: 4.0930\n",
      "Epoch 170/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0410 - mse: 11.2677 - val_loss: 0.0120 - val_mse: 3.6744\n",
      "Epoch 171/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0405 - mse: 10.7143 - val_loss: 0.0116 - val_mse: 3.4783\n",
      "Epoch 172/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0405 - mse: 12.2853 - val_loss: 0.0111 - val_mse: 3.2702\n",
      "Epoch 173/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0383 - mse: 7.9604 - val_loss: 0.0104 - val_mse: 2.9769\n",
      "Epoch 174/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0340 - mse: 7.7395 - val_loss: 0.0097 - val_mse: 2.6755\n",
      "Epoch 175/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0545 - mse: 10.5449 - val_loss: 0.0089 - val_mse: 2.3637\n",
      "Epoch 176/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0448 - mse: 7.4182 - val_loss: 0.0079 - val_mse: 1.9979\n",
      "Epoch 177/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0390 - mse: 7.8321 - val_loss: 0.0073 - val_mse: 1.7667\n",
      "Epoch 178/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0464 - mse: 10.5995 - val_loss: 0.0092 - val_mse: 2.4839\n",
      "Epoch 179/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0397 - mse: 7.0281 - val_loss: 0.0093 - val_mse: 2.5140\n",
      "Epoch 180/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0528 - mse: 8.8018 - val_loss: 0.0091 - val_mse: 2.4537\n",
      "Epoch 181/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0291 - mse: 7.7438 - val_loss: 0.0086 - val_mse: 2.2508\n",
      "Epoch 182/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0360 - mse: 6.5246 - val_loss: 0.0103 - val_mse: 2.9080\n",
      "Epoch 183/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0325 - mse: 8.5145 - val_loss: 0.0110 - val_mse: 3.2032\n",
      "Epoch 184/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0340 - mse: 10.7786 - val_loss: 0.0110 - val_mse: 3.2354\n",
      "Epoch 185/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0426 - mse: 9.6529 - val_loss: 0.0108 - val_mse: 3.1428\n",
      "Epoch 186/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0327 - mse: 8.4304 - val_loss: 0.0108 - val_mse: 3.1485\n",
      "Epoch 187/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0374 - mse: 8.2543 - val_loss: 0.0111 - val_mse: 3.2718\n",
      "Epoch 188/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0352 - mse: 10.2270 - val_loss: 0.0112 - val_mse: 3.3339\n",
      "Epoch 189/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0268 - mse: 7.0726 - val_loss: 0.0111 - val_mse: 3.3042\n",
      "Epoch 190/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0400 - mse: 9.3422 - val_loss: 0.0112 - val_mse: 3.3353\n",
      "Epoch 191/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0300 - mse: 8.1402 - val_loss: 0.0108 - val_mse: 3.1577\n",
      "Epoch 192/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0297 - mse: 8.3394 - val_loss: 0.0104 - val_mse: 3.0110\n",
      "Epoch 193/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0295 - mse: 7.5693 - val_loss: 0.0102 - val_mse: 2.9206\n",
      "Epoch 194/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0285 - mse: 7.7487 - val_loss: 0.0106 - val_mse: 3.0768\n",
      "Epoch 195/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0444 - mse: 8.8171 - val_loss: 0.0109 - val_mse: 3.2626\n",
      "Epoch 196/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0302 - mse: 8.4285 - val_loss: 0.0109 - val_mse: 3.2456\n",
      "Epoch 197/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0313 - mse: 9.3598 - val_loss: 0.0108 - val_mse: 3.2082\n",
      "Epoch 198/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0385 - mse: 9.4823 - val_loss: 0.0107 - val_mse: 3.1635\n",
      "Epoch 199/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0388 - mse: 8.7779 - val_loss: 0.0102 - val_mse: 2.9569\n",
      "Epoch 200/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0316 - mse: 8.9763 - val_loss: 0.0097 - val_mse: 2.7304\n",
      "Epoch 201/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0433 - mse: 8.7214 - val_loss: 0.0095 - val_mse: 2.6715\n",
      "Epoch 202/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0367 - mse: 9.5676 - val_loss: 0.0091 - val_mse: 2.5236\n",
      "Epoch 203/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0355 - mse: 8.4218 - val_loss: 0.0088 - val_mse: 2.3733\n",
      "Epoch 204/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0342 - mse: 8.1348 - val_loss: 0.0083 - val_mse: 2.1864\n",
      "Epoch 205/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0272 - mse: 6.2215 - val_loss: 0.0076 - val_mse: 1.9394\n",
      "Epoch 206/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0417 - mse: 10.8390 - val_loss: 0.0077 - val_mse: 1.9416\n",
      "Epoch 207/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0364 - mse: 6.0751 - val_loss: 0.0077 - val_mse: 1.9619\n",
      "Epoch 208/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0387 - mse: 9.2241 - val_loss: 0.0072 - val_mse: 1.7868\n",
      "Epoch 209/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0280 - mse: 7.5091 - val_loss: 0.0066 - val_mse: 1.5645\n",
      "Epoch 210/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0382 - mse: 10.5170 - val_loss: 0.0063 - val_mse: 1.4832\n",
      "Epoch 211/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0341 - mse: 5.7351 - val_loss: 0.0064 - val_mse: 1.5032\n",
      "Epoch 212/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0322 - mse: 8.0730 - val_loss: 0.0067 - val_mse: 1.6259\n",
      "Epoch 213/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0466 - mse: 9.0030 - val_loss: 0.0066 - val_mse: 1.5823\n",
      "Epoch 214/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0348 - mse: 7.4124 - val_loss: 0.0064 - val_mse: 1.5080\n",
      "Epoch 215/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0307 - mse: 7.6146 - val_loss: 0.0065 - val_mse: 1.5496\n",
      "Epoch 216/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0274 - mse: 6.4727 - val_loss: 0.0067 - val_mse: 1.5980\n",
      "Epoch 217/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0293 - mse: 9.3509 - val_loss: 0.0065 - val_mse: 1.5484\n",
      "Epoch 218/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0444 - mse: 7.2394 - val_loss: 0.0061 - val_mse: 1.4217\n",
      "Epoch 219/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0411 - mse: 6.6035 - val_loss: 0.0060 - val_mse: 1.3762\n",
      "Epoch 220/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0321 - mse: 6.7861 - val_loss: 0.0059 - val_mse: 1.3386\n",
      "Epoch 221/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0339 - mse: 8.1747 - val_loss: 0.0060 - val_mse: 1.3749\n",
      "Epoch 222/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0296 - mse: 9.1188 - val_loss: 0.0072 - val_mse: 1.7605\n",
      "Epoch 223/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0337 - mse: 8.0425 - val_loss: 0.0072 - val_mse: 1.7822\n",
      "Epoch 224/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0365 - mse: 8.9964 - val_loss: 0.0072 - val_mse: 1.7660\n",
      "Epoch 225/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0289 - mse: 6.7355 - val_loss: 0.0070 - val_mse: 1.7040\n",
      "Epoch 226/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0442 - mse: 7.2946 - val_loss: 0.0085 - val_mse: 2.2497\n",
      "Epoch 227/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0258 - mse: 6.1949 - val_loss: 0.0093 - val_mse: 2.5342\n",
      "Epoch 228/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0418 - mse: 9.6926 - val_loss: 0.0093 - val_mse: 2.5513\n",
      "Epoch 229/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0303 - mse: 8.8847 - val_loss: 0.0097 - val_mse: 2.7100\n",
      "Epoch 230/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0294 - mse: 6.8843 - val_loss: 0.0094 - val_mse: 2.6046\n",
      "Epoch 231/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0308 - mse: 7.6994 - val_loss: 0.0092 - val_mse: 2.4956\n",
      "Epoch 232/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0279 - mse: 7.8411 - val_loss: 0.0083 - val_mse: 2.1526\n",
      "Epoch 233/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0243 - mse: 4.9742 - val_loss: 0.0078 - val_mse: 1.9785\n",
      "Epoch 234/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0444 - mse: 8.1178 - val_loss: 0.0074 - val_mse: 1.8492\n",
      "Epoch 235/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0283 - mse: 6.8235 - val_loss: 0.0072 - val_mse: 1.7619\n",
      "Epoch 236/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0357 - mse: 7.2124 - val_loss: 0.0072 - val_mse: 1.7611\n",
      "Epoch 237/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0346 - mse: 5.9369 - val_loss: 0.0067 - val_mse: 1.6026\n",
      "Epoch 238/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0286 - mse: 5.4924 - val_loss: 0.0064 - val_mse: 1.4823\n",
      "Epoch 239/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0324 - mse: 7.1917 - val_loss: 0.0062 - val_mse: 1.4220\n",
      "Epoch 240/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0388 - mse: 6.4950 - val_loss: 0.0058 - val_mse: 1.3006\n",
      "Epoch 241/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0304 - mse: 5.3441 - val_loss: 0.0056 - val_mse: 1.2480\n",
      "Epoch 242/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0257 - mse: 5.6541 - val_loss: 0.0053 - val_mse: 1.1323\n",
      "Epoch 243/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0361 - mse: 6.2641 - val_loss: 0.0050 - val_mse: 1.0445\n",
      "Epoch 244/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0214 - mse: 4.4234 - val_loss: 0.0048 - val_mse: 1.0044\n",
      "Epoch 245/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0231 - mse: 4.2307 - val_loss: 0.0046 - val_mse: 0.9475\n",
      "Epoch 246/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0294 - mse: 4.6691 - val_loss: 0.0047 - val_mse: 0.9570\n",
      "Epoch 247/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0453 - mse: 6.2299 - val_loss: 0.0044 - val_mse: 0.8938\n",
      "Epoch 248/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0349 - mse: 6.0356 - val_loss: 0.0041 - val_mse: 0.7991\n",
      "Epoch 249/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0443 - mse: 7.2273 - val_loss: 0.0042 - val_mse: 0.8287\n",
      "Epoch 250/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0495 - mse: 7.2600 - val_loss: 0.0044 - val_mse: 0.8808\n",
      "Epoch 251/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0440 - mse: 6.4682 - val_loss: 0.0046 - val_mse: 0.9462\n",
      "Epoch 252/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0299 - mse: 5.4775 - val_loss: 0.0054 - val_mse: 1.1911\n",
      "Epoch 253/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0249 - mse: 5.8743 - val_loss: 0.0058 - val_mse: 1.3094\n",
      "Epoch 254/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0270 - mse: 4.8941 - val_loss: 0.0057 - val_mse: 1.2784\n",
      "Epoch 255/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0322 - mse: 7.2674 - val_loss: 0.0052 - val_mse: 1.1217\n",
      "Epoch 256/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0247 - mse: 5.7173 - val_loss: 0.0052 - val_mse: 1.1179\n",
      "Epoch 257/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0305 - mse: 6.8656 - val_loss: 0.0055 - val_mse: 1.2072\n",
      "Epoch 258/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0322 - mse: 4.7201 - val_loss: 0.0060 - val_mse: 1.3726\n",
      "Epoch 259/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0227 - mse: 5.2357 - val_loss: 0.0060 - val_mse: 1.3598\n",
      "Epoch 260/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0417 - mse: 8.1692 - val_loss: 0.0059 - val_mse: 1.3556\n",
      "Epoch 261/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0249 - mse: 5.1944 - val_loss: 0.0061 - val_mse: 1.4095\n",
      "Epoch 262/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0397 - mse: 7.6753 - val_loss: 0.0067 - val_mse: 1.6079\n",
      "Epoch 263/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0269 - mse: 7.4829 - val_loss: 0.0070 - val_mse: 1.7164\n",
      "Epoch 264/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0321 - mse: 7.4372 - val_loss: 0.0067 - val_mse: 1.6098\n",
      "Epoch 265/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0433 - mse: 9.9660 - val_loss: 0.0070 - val_mse: 1.7224\n",
      "Epoch 266/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0279 - mse: 8.1766 - val_loss: 0.0066 - val_mse: 1.5916\n",
      "Epoch 267/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0280 - mse: 7.6840 - val_loss: 0.0061 - val_mse: 1.4032\n",
      "Epoch 268/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0377 - mse: 6.1626 - val_loss: 0.0057 - val_mse: 1.2850\n",
      "Epoch 269/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0338 - mse: 7.0191 - val_loss: 0.0056 - val_mse: 1.2496\n",
      "Epoch 270/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0261 - mse: 4.9701 - val_loss: 0.0055 - val_mse: 1.2211\n",
      "Epoch 271/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0236 - mse: 5.3255 - val_loss: 0.0054 - val_mse: 1.1982\n",
      "Epoch 272/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0307 - mse: 6.2105 - val_loss: 0.0049 - val_mse: 1.0344\n",
      "Epoch 273/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0263 - mse: 5.4699 - val_loss: 0.0047 - val_mse: 0.9766\n",
      "Epoch 274/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0431 - mse: 6.8443 - val_loss: 0.0046 - val_mse: 0.9421\n",
      "Epoch 275/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0268 - mse: 4.8513 - val_loss: 0.0045 - val_mse: 0.9169\n",
      "Epoch 276/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0436 - mse: 5.1006 - val_loss: 0.0056 - val_mse: 1.2361\n",
      "Epoch 277/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0339 - mse: 5.7982 - val_loss: 0.0066 - val_mse: 1.5863\n",
      "Epoch 278/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0313 - mse: 5.9020 - val_loss: 0.0067 - val_mse: 1.6237\n",
      "Epoch 279/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0299 - mse: 5.0973 - val_loss: 0.0068 - val_mse: 1.6572\n",
      "Epoch 280/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0332 - mse: 6.0781 - val_loss: 0.0072 - val_mse: 1.8072\n",
      "Epoch 281/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0285 - mse: 6.5321 - val_loss: 0.0080 - val_mse: 2.0869\n",
      "Epoch 282/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0342 - mse: 6.5104 - val_loss: 0.0081 - val_mse: 2.1369\n",
      "Epoch 283/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0428 - mse: 6.2401 - val_loss: 0.0082 - val_mse: 2.1492\n",
      "Epoch 284/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0336 - mse: 7.7825 - val_loss: 0.0083 - val_mse: 2.1881\n",
      "Epoch 285/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0249 - mse: 5.9979 - val_loss: 0.0077 - val_mse: 1.9816\n",
      "Epoch 286/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0280 - mse: 7.8588 - val_loss: 0.0070 - val_mse: 1.7343\n",
      "Epoch 287/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0234 - mse: 5.1358 - val_loss: 0.0065 - val_mse: 1.5462\n",
      "Epoch 288/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0422 - mse: 6.4905 - val_loss: 0.0061 - val_mse: 1.4319\n",
      "Epoch 289/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0260 - mse: 5.5362 - val_loss: 0.0065 - val_mse: 1.5736\n",
      "Epoch 290/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0253 - mse: 8.1286 - val_loss: 0.0066 - val_mse: 1.5863\n",
      "Epoch 291/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0263 - mse: 6.1101 - val_loss: 0.0063 - val_mse: 1.4932\n",
      "Epoch 292/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0272 - mse: 7.6462 - val_loss: 0.0060 - val_mse: 1.3888\n",
      "Epoch 293/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0394 - mse: 6.6217 - val_loss: 0.0058 - val_mse: 1.3508\n",
      "Epoch 294/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0301 - mse: 6.2951 - val_loss: 0.0070 - val_mse: 1.7494\n",
      "Epoch 295/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0256 - mse: 6.7826 - val_loss: 0.0083 - val_mse: 2.2349\n",
      "Epoch 296/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0262 - mse: 6.8743 - val_loss: 0.0085 - val_mse: 2.2808\n",
      "Epoch 297/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0265 - mse: 5.8524 - val_loss: 0.0085 - val_mse: 2.3040\n",
      "Epoch 298/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0283 - mse: 7.7619 - val_loss: 0.0086 - val_mse: 2.3369\n",
      "Epoch 299/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0266 - mse: 7.1937 - val_loss: 0.0080 - val_mse: 2.1062\n",
      "Epoch 300/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0375 - mse: 6.2391 - val_loss: 0.0076 - val_mse: 1.9397\n",
      "Epoch 301/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0297 - mse: 6.3606 - val_loss: 0.0074 - val_mse: 1.8628\n",
      "Epoch 302/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0303 - mse: 9.5750 - val_loss: 0.0068 - val_mse: 1.6507\n",
      "Epoch 303/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0215 - mse: 4.5710 - val_loss: 0.0063 - val_mse: 1.5002\n",
      "Epoch 304/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0254 - mse: 5.9343 - val_loss: 0.0062 - val_mse: 1.4603\n",
      "Epoch 305/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0241 - mse: 5.7251 - val_loss: 0.0061 - val_mse: 1.4324\n",
      "Epoch 306/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0363 - mse: 7.2274 - val_loss: 0.0069 - val_mse: 1.7119\n",
      "Epoch 307/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0304 - mse: 7.0378 - val_loss: 0.0071 - val_mse: 1.7838\n",
      "Epoch 308/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0307 - mse: 5.8835 - val_loss: 0.0071 - val_mse: 1.7541\n",
      "Epoch 309/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0356 - mse: 6.9400 - val_loss: 0.0067 - val_mse: 1.6427\n",
      "Epoch 310/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0272 - mse: 4.8352 - val_loss: 0.0062 - val_mse: 1.4447\n",
      "Epoch 311/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0253 - mse: 5.2887 - val_loss: 0.0057 - val_mse: 1.2838\n",
      "Epoch 312/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0341 - mse: 6.4499 - val_loss: 0.0058 - val_mse: 1.3122\n",
      "Epoch 313/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0212 - mse: 4.1471 - val_loss: 0.0063 - val_mse: 1.5019\n",
      "Epoch 314/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0369 - mse: 5.6448 - val_loss: 0.0066 - val_mse: 1.5891\n",
      "Epoch 315/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0343 - mse: 5.4676 - val_loss: 0.0067 - val_mse: 1.6285\n",
      "Epoch 316/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0268 - mse: 7.3556 - val_loss: 0.0061 - val_mse: 1.4271\n",
      "Epoch 317/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0339 - mse: 5.1311 - val_loss: 0.0056 - val_mse: 1.2559\n",
      "Epoch 318/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0302 - mse: 5.7398 - val_loss: 0.0052 - val_mse: 1.1256\n",
      "Epoch 319/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0233 - mse: 3.5168 - val_loss: 0.0052 - val_mse: 1.1232\n",
      "Epoch 320/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0370 - mse: 5.5783 - val_loss: 0.0058 - val_mse: 1.3132\n",
      "Epoch 321/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0278 - mse: 4.8854 - val_loss: 0.0058 - val_mse: 1.3331\n",
      "Epoch 322/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0271 - mse: 5.0693 - val_loss: 0.0059 - val_mse: 1.3701\n",
      "Epoch 323/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0353 - mse: 7.7363 - val_loss: 0.0060 - val_mse: 1.3860\n",
      "Epoch 324/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0258 - mse: 5.3099 - val_loss: 0.0061 - val_mse: 1.4059\n",
      "Epoch 325/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0312 - mse: 5.1204 - val_loss: 0.0060 - val_mse: 1.3800\n",
      "Epoch 326/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0229 - mse: 5.3446 - val_loss: 0.0058 - val_mse: 1.3316\n",
      "Epoch 327/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0302 - mse: 7.1557 - val_loss: 0.0054 - val_mse: 1.1985\n",
      "Epoch 328/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0253 - mse: 6.1912 - val_loss: 0.0050 - val_mse: 1.0712\n",
      "Epoch 329/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0253 - mse: 6.5516 - val_loss: 0.0044 - val_mse: 0.8952\n",
      "Epoch 330/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0233 - mse: 5.5259 - val_loss: 0.0037 - val_mse: 0.7212\n",
      "Epoch 331/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0321 - mse: 5.2386 - val_loss: 0.0038 - val_mse: 0.7288\n",
      "Epoch 332/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0335 - mse: 5.7325 - val_loss: 0.0040 - val_mse: 0.7847\n",
      "Epoch 333/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0262 - mse: 4.8920 - val_loss: 0.0039 - val_mse: 0.7750\n",
      "Epoch 334/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0414 - mse: 4.7221 - val_loss: 0.0052 - val_mse: 1.1330\n",
      "Epoch 335/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0298 - mse: 6.4307 - val_loss: 0.0054 - val_mse: 1.2039\n",
      "Epoch 336/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0257 - mse: 4.3149 - val_loss: 0.0052 - val_mse: 1.1259\n",
      "Epoch 337/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0238 - mse: 4.2853 - val_loss: 0.0052 - val_mse: 1.1527\n",
      "Epoch 338/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0269 - mse: 5.8843 - val_loss: 0.0053 - val_mse: 1.1837\n",
      "Epoch 339/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0364 - mse: 5.8032 - val_loss: 0.0053 - val_mse: 1.1794\n",
      "Epoch 340/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0291 - mse: 5.3103 - val_loss: 0.0054 - val_mse: 1.2145\n",
      "Epoch 341/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0255 - mse: 4.5155 - val_loss: 0.0054 - val_mse: 1.2026\n",
      "Epoch 342/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0282 - mse: 5.3087 - val_loss: 0.0069 - val_mse: 1.7134\n",
      "Epoch 343/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0234 - mse: 5.8203 - val_loss: 0.0073 - val_mse: 1.8431\n",
      "Epoch 344/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0291 - mse: 5.9643 - val_loss: 0.0074 - val_mse: 1.8869\n",
      "Epoch 345/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0326 - mse: 7.5373 - val_loss: 0.0070 - val_mse: 1.7350\n",
      "Epoch 346/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0251 - mse: 7.5118 - val_loss: 0.0064 - val_mse: 1.5480\n",
      "Epoch 347/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0310 - mse: 5.8102 - val_loss: 0.0059 - val_mse: 1.3800\n",
      "Epoch 348/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0280 - mse: 5.6568 - val_loss: 0.0058 - val_mse: 1.3284\n",
      "Epoch 349/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0235 - mse: 5.1457 - val_loss: 0.0056 - val_mse: 1.2841\n",
      "Epoch 350/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0344 - mse: 5.6121 - val_loss: 0.0054 - val_mse: 1.1975\n",
      "Epoch 351/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0307 - mse: 5.1279 - val_loss: 0.0057 - val_mse: 1.3130\n",
      "Epoch 352/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0288 - mse: 5.1088 - val_loss: 0.0059 - val_mse: 1.3779\n",
      "Epoch 353/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0293 - mse: 5.4464 - val_loss: 0.0060 - val_mse: 1.4201\n",
      "Epoch 354/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0321 - mse: 7.5046 - val_loss: 0.0060 - val_mse: 1.4126\n",
      "Epoch 355/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0285 - mse: 5.7212 - val_loss: 0.0056 - val_mse: 1.2865\n",
      "Epoch 356/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0302 - mse: 4.6646 - val_loss: 0.0058 - val_mse: 1.3545\n",
      "Epoch 357/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0235 - mse: 5.5853 - val_loss: 0.0059 - val_mse: 1.3928\n",
      "Epoch 358/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0301 - mse: 5.5360 - val_loss: 0.0056 - val_mse: 1.2906\n",
      "Epoch 359/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0380 - mse: 6.3044 - val_loss: 0.0057 - val_mse: 1.3062\n",
      "Epoch 360/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0288 - mse: 5.5265 - val_loss: 0.0063 - val_mse: 1.5270\n",
      "Epoch 361/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0274 - mse: 6.3104 - val_loss: 0.0064 - val_mse: 1.5607\n",
      "Epoch 362/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0400 - mse: 6.0005 - val_loss: 0.0083 - val_mse: 2.2226\n",
      "Epoch 363/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0275 - mse: 5.6135 - val_loss: 0.0100 - val_mse: 2.9192\n",
      "Epoch 364/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0291 - mse: 5.6974 - val_loss: 0.0098 - val_mse: 2.8431\n",
      "Epoch 365/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0237 - mse: 5.8344 - val_loss: 0.0094 - val_mse: 2.6501\n",
      "Epoch 366/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0333 - mse: 6.7209 - val_loss: 0.0089 - val_mse: 2.4462\n",
      "Epoch 367/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0263 - mse: 4.9773 - val_loss: 0.0087 - val_mse: 2.3946\n",
      "Epoch 368/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0321 - mse: 5.7256 - val_loss: 0.0087 - val_mse: 2.3909\n",
      "Epoch 369/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0222 - mse: 5.1795 - val_loss: 0.0086 - val_mse: 2.3682\n",
      "Epoch 370/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0279 - mse: 6.8372 - val_loss: 0.0083 - val_mse: 2.2443\n",
      "Epoch 371/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0239 - mse: 6.6292 - val_loss: 0.0078 - val_mse: 2.0644\n",
      "Epoch 372/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0283 - mse: 6.6309 - val_loss: 0.0075 - val_mse: 1.9578\n",
      "Epoch 373/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0276 - mse: 6.0891 - val_loss: 0.0076 - val_mse: 1.9778\n",
      "Epoch 374/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0231 - mse: 5.4874 - val_loss: 0.0073 - val_mse: 1.8758\n",
      "Epoch 375/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0259 - mse: 4.8390 - val_loss: 0.0071 - val_mse: 1.8020\n",
      "Epoch 376/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0245 - mse: 5.7273 - val_loss: 0.0068 - val_mse: 1.6855\n",
      "Epoch 377/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0224 - mse: 5.0971 - val_loss: 0.0063 - val_mse: 1.5158\n",
      "Epoch 378/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0279 - mse: 5.4151 - val_loss: 0.0059 - val_mse: 1.3789\n",
      "Epoch 379/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0245 - mse: 4.5877 - val_loss: 0.0060 - val_mse: 1.4136\n",
      "Epoch 380/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0238 - mse: 6.1220 - val_loss: 0.0057 - val_mse: 1.3200\n",
      "Epoch 381/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0284 - mse: 5.2177 - val_loss: 0.0054 - val_mse: 1.2151\n",
      "Epoch 382/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0349 - mse: 6.4529 - val_loss: 0.0053 - val_mse: 1.1947\n",
      "Epoch 383/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0229 - mse: 5.3008 - val_loss: 0.0050 - val_mse: 1.0996\n",
      "Epoch 384/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0209 - mse: 3.8457 - val_loss: 0.0048 - val_mse: 1.0471\n",
      "Epoch 385/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0285 - mse: 5.4175 - val_loss: 0.0048 - val_mse: 1.0313\n",
      "Epoch 386/2000\n",
      "1168/1168 [==============================] - 0s 48us/step - loss: 0.0241 - mse: 3.9282 - val_loss: 0.0046 - val_mse: 0.9930\n",
      "Epoch 387/2000\n",
      "1168/1168 [==============================] - 0s 48us/step - loss: 0.0324 - mse: 4.4834 - val_loss: 0.0044 - val_mse: 0.9201\n",
      "Epoch 388/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0280 - mse: 5.1886 - val_loss: 0.0041 - val_mse: 0.8417\n",
      "Epoch 389/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0298 - mse: 4.9464 - val_loss: 0.0042 - val_mse: 0.8556\n",
      "Epoch 390/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0225 - mse: 4.7267 - val_loss: 0.0040 - val_mse: 0.8078\n",
      "Epoch 391/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0271 - mse: 4.8508 - val_loss: 0.0037 - val_mse: 0.7291\n",
      "Epoch 392/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0266 - mse: 4.2787 - val_loss: 0.0041 - val_mse: 0.8483\n",
      "Epoch 393/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0232 - mse: 4.9427 - val_loss: 0.0042 - val_mse: 0.8736\n",
      "Epoch 394/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0233 - mse: 4.7219 - val_loss: 0.0041 - val_mse: 0.8373\n",
      "Epoch 395/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0225 - mse: 5.2141 - val_loss: 0.0041 - val_mse: 0.8551\n",
      "Epoch 396/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0200 - mse: 4.0830 - val_loss: 0.0041 - val_mse: 0.8407\n",
      "Epoch 397/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0272 - mse: 4.1134 - val_loss: 0.0040 - val_mse: 0.8299\n",
      "Epoch 398/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0223 - mse: 5.0574 - val_loss: 0.0040 - val_mse: 0.8165\n",
      "Epoch 399/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0314 - mse: 4.6223 - val_loss: 0.0039 - val_mse: 0.7968\n",
      "Epoch 400/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0260 - mse: 4.9582 - val_loss: 0.0042 - val_mse: 0.8879\n",
      "Epoch 401/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0322 - mse: 4.3332 - val_loss: 0.0044 - val_mse: 0.9352\n",
      "Epoch 402/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0259 - mse: 4.6261 - val_loss: 0.0048 - val_mse: 1.0698\n",
      "Epoch 403/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0219 - mse: 4.7236 - val_loss: 0.0046 - val_mse: 1.0079\n",
      "Epoch 404/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0288 - mse: 4.6754 - val_loss: 0.0052 - val_mse: 1.1983\n",
      "Epoch 405/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0267 - mse: 4.9501 - val_loss: 0.0059 - val_mse: 1.3992\n",
      "Epoch 406/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0333 - mse: 5.4978 - val_loss: 0.0057 - val_mse: 1.3556\n",
      "Epoch 407/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0206 - mse: 4.5351 - val_loss: 0.0055 - val_mse: 1.2714\n",
      "Epoch 408/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0279 - mse: 5.5078 - val_loss: 0.0051 - val_mse: 1.1586\n",
      "Epoch 409/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0236 - mse: 5.2281 - val_loss: 0.0048 - val_mse: 1.0735\n",
      "Epoch 410/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0228 - mse: 5.5112 - val_loss: 0.0047 - val_mse: 1.0176\n",
      "Epoch 411/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0213 - mse: 4.3588 - val_loss: 0.0045 - val_mse: 0.9799\n",
      "Epoch 412/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0201 - mse: 4.4517 - val_loss: 0.0040 - val_mse: 0.8352\n",
      "Epoch 413/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0246 - mse: 4.3383 - val_loss: 0.0039 - val_mse: 0.7990\n",
      "Epoch 414/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0224 - mse: 3.9155 - val_loss: 0.0041 - val_mse: 0.8443\n",
      "Epoch 415/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0254 - mse: 4.1142 - val_loss: 0.0041 - val_mse: 0.8657\n",
      "Epoch 416/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0223 - mse: 3.7906 - val_loss: 0.0041 - val_mse: 0.8534\n",
      "Epoch 417/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0223 - mse: 4.1405 - val_loss: 0.0043 - val_mse: 0.9264\n",
      "Epoch 418/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0208 - mse: 4.2936 - val_loss: 0.0044 - val_mse: 0.9380\n",
      "Epoch 419/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0215 - mse: 4.5679 - val_loss: 0.0042 - val_mse: 0.8906\n",
      "Epoch 420/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0195 - mse: 3.9572 - val_loss: 0.0037 - val_mse: 0.7530\n",
      "Epoch 421/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0216 - mse: 4.3623 - val_loss: 0.0034 - val_mse: 0.6689\n",
      "Epoch 422/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0196 - mse: 3.5100 - val_loss: 0.0032 - val_mse: 0.6104\n",
      "Epoch 423/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0230 - mse: 3.1713 - val_loss: 0.0030 - val_mse: 0.5656\n",
      "Epoch 424/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0256 - mse: 4.5641 - val_loss: 0.0028 - val_mse: 0.5045\n",
      "Epoch 425/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0265 - mse: 3.7764 - val_loss: 0.0028 - val_mse: 0.4963\n",
      "Epoch 426/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0270 - mse: 4.4368 - val_loss: 0.0027 - val_mse: 0.4890\n",
      "Epoch 427/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0212 - mse: 3.9287 - val_loss: 0.0028 - val_mse: 0.4977\n",
      "Epoch 428/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0240 - mse: 3.7075 - val_loss: 0.0027 - val_mse: 0.4867\n",
      "Epoch 429/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0182 - mse: 3.3477 - val_loss: 0.0025 - val_mse: 0.4380\n",
      "Epoch 430/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0327 - mse: 3.5865 - val_loss: 0.0025 - val_mse: 0.4409\n",
      "Epoch 431/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0198 - mse: 3.8248 - val_loss: 0.0028 - val_mse: 0.5124\n",
      "Epoch 432/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0254 - mse: 4.2411 - val_loss: 0.0032 - val_mse: 0.6169\n",
      "Epoch 433/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0177 - mse: 3.5032 - val_loss: 0.0032 - val_mse: 0.6256\n",
      "Epoch 434/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0199 - mse: 4.0054 - val_loss: 0.0031 - val_mse: 0.5914\n",
      "Epoch 435/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0198 - mse: 4.1631 - val_loss: 0.0031 - val_mse: 0.5749\n",
      "Epoch 436/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0239 - mse: 4.1183 - val_loss: 0.0029 - val_mse: 0.5461\n",
      "Epoch 437/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0218 - mse: 4.6398 - val_loss: 0.0028 - val_mse: 0.5168\n",
      "Epoch 438/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0197 - mse: 4.0283 - val_loss: 0.0026 - val_mse: 0.4666\n",
      "Epoch 439/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0184 - mse: 3.3894 - val_loss: 0.0024 - val_mse: 0.4031\n",
      "Epoch 440/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0257 - mse: 3.9425 - val_loss: 0.0024 - val_mse: 0.4070\n",
      "Epoch 441/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0299 - mse: 4.2732 - val_loss: 0.0025 - val_mse: 0.4479\n",
      "Epoch 442/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0221 - mse: 3.9809 - val_loss: 0.0029 - val_mse: 0.5390\n",
      "Epoch 443/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0195 - mse: 3.5065 - val_loss: 0.0031 - val_mse: 0.5791\n",
      "Epoch 444/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0177 - mse: 2.9942 - val_loss: 0.0032 - val_mse: 0.6021\n",
      "Epoch 445/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0185 - mse: 3.5676 - val_loss: 0.0032 - val_mse: 0.6001\n",
      "Epoch 446/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0273 - mse: 4.1347 - val_loss: 0.0031 - val_mse: 0.5813\n",
      "Epoch 447/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0281 - mse: 4.2207 - val_loss: 0.0036 - val_mse: 0.7297\n",
      "Epoch 448/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0275 - mse: 4.9634 - val_loss: 0.0040 - val_mse: 0.8350\n",
      "Epoch 449/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0219 - mse: 4.5258 - val_loss: 0.0039 - val_mse: 0.8151\n",
      "Epoch 450/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0238 - mse: 3.6820 - val_loss: 0.0038 - val_mse: 0.7861\n",
      "Epoch 451/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0188 - mse: 4.0235 - val_loss: 0.0035 - val_mse: 0.7149\n",
      "Epoch 452/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0259 - mse: 3.7214 - val_loss: 0.0034 - val_mse: 0.6846\n",
      "Epoch 453/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0253 - mse: 5.0445 - val_loss: 0.0033 - val_mse: 0.6438\n",
      "Epoch 454/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0232 - mse: 3.5414 - val_loss: 0.0030 - val_mse: 0.5729\n",
      "Epoch 455/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0206 - mse: 3.8325 - val_loss: 0.0030 - val_mse: 0.5736\n",
      "Epoch 456/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0168 - mse: 3.1309 - val_loss: 0.0030 - val_mse: 0.5685\n",
      "Epoch 457/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0170 - mse: 3.2400 - val_loss: 0.0028 - val_mse: 0.5155\n",
      "Epoch 458/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0200 - mse: 3.6397 - val_loss: 0.0028 - val_mse: 0.5204\n",
      "Epoch 459/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0213 - mse: 3.9145 - val_loss: 0.0028 - val_mse: 0.5222\n",
      "Epoch 460/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0294 - mse: 3.7275 - val_loss: 0.0043 - val_mse: 0.9221\n",
      "Epoch 461/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0273 - mse: 4.8661 - val_loss: 0.0045 - val_mse: 1.0016\n",
      "Epoch 462/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0212 - mse: 4.2870 - val_loss: 0.0044 - val_mse: 0.9567\n",
      "Epoch 463/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0201 - mse: 4.2504 - val_loss: 0.0041 - val_mse: 0.8633\n",
      "Epoch 464/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0226 - mse: 3.6363 - val_loss: 0.0037 - val_mse: 0.7553\n",
      "Epoch 465/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0271 - mse: 4.3075 - val_loss: 0.0044 - val_mse: 0.9578\n",
      "Epoch 466/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0239 - mse: 4.5392 - val_loss: 0.0049 - val_mse: 1.1137\n",
      "Epoch 467/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0196 - mse: 3.9727 - val_loss: 0.0049 - val_mse: 1.1085\n",
      "Epoch 468/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0261 - mse: 4.9675 - val_loss: 0.0053 - val_mse: 1.2365\n",
      "Epoch 469/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0207 - mse: 4.4306 - val_loss: 0.0055 - val_mse: 1.2887\n",
      "Epoch 470/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0208 - mse: 4.1445 - val_loss: 0.0051 - val_mse: 1.1817\n",
      "Epoch 471/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0174 - mse: 3.4179 - val_loss: 0.0048 - val_mse: 1.0859\n",
      "Epoch 472/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0201 - mse: 3.7095 - val_loss: 0.0045 - val_mse: 0.9722\n",
      "Epoch 473/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0196 - mse: 4.4227 - val_loss: 0.0039 - val_mse: 0.8159\n",
      "Epoch 474/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0204 - mse: 3.5407 - val_loss: 0.0037 - val_mse: 0.7522\n",
      "Epoch 475/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0290 - mse: 4.1569 - val_loss: 0.0039 - val_mse: 0.8180\n",
      "Epoch 476/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0239 - mse: 4.1834 - val_loss: 0.0041 - val_mse: 0.8692\n",
      "Epoch 477/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0208 - mse: 3.8820 - val_loss: 0.0040 - val_mse: 0.8418\n",
      "Epoch 478/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0213 - mse: 4.3789 - val_loss: 0.0040 - val_mse: 0.8468\n",
      "Epoch 479/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0207 - mse: 3.6322 - val_loss: 0.0040 - val_mse: 0.8496\n",
      "Epoch 480/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0194 - mse: 3.9187 - val_loss: 0.0039 - val_mse: 0.8074\n",
      "Epoch 481/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0182 - mse: 3.3236 - val_loss: 0.0036 - val_mse: 0.7229\n",
      "Epoch 482/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0199 - mse: 3.3589 - val_loss: 0.0036 - val_mse: 0.7309\n",
      "Epoch 483/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0210 - mse: 3.6222 - val_loss: 0.0035 - val_mse: 0.6996\n",
      "Epoch 484/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0337 - mse: 4.6450 - val_loss: 0.0035 - val_mse: 0.7012\n",
      "Epoch 485/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0231 - mse: 4.0467 - val_loss: 0.0033 - val_mse: 0.6630\n",
      "Epoch 486/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0255 - mse: 3.9495 - val_loss: 0.0031 - val_mse: 0.6062\n",
      "Epoch 487/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0183 - mse: 3.3637 - val_loss: 0.0030 - val_mse: 0.5610\n",
      "Epoch 488/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0180 - mse: 3.3069 - val_loss: 0.0026 - val_mse: 0.4752\n",
      "Epoch 489/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0187 - mse: 3.2601 - val_loss: 0.0024 - val_mse: 0.4204\n",
      "Epoch 490/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0210 - mse: 3.1502 - val_loss: 0.0027 - val_mse: 0.4971\n",
      "Epoch 491/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0201 - mse: 3.8026 - val_loss: 0.0027 - val_mse: 0.5100\n",
      "Epoch 492/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0251 - mse: 3.5724 - val_loss: 0.0031 - val_mse: 0.6047\n",
      "Epoch 493/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0184 - mse: 4.0792 - val_loss: 0.0033 - val_mse: 0.6588\n",
      "Epoch 494/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0180 - mse: 3.1665 - val_loss: 0.0034 - val_mse: 0.6748\n",
      "Epoch 495/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0214 - mse: 4.0929 - val_loss: 0.0033 - val_mse: 0.6482\n",
      "Epoch 496/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0246 - mse: 3.8525 - val_loss: 0.0029 - val_mse: 0.5555\n",
      "Epoch 497/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0170 - mse: 3.1762 - val_loss: 0.0026 - val_mse: 0.4776\n",
      "Epoch 498/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0189 - mse: 3.6408 - val_loss: 0.0024 - val_mse: 0.4354\n",
      "Epoch 499/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0236 - mse: 3.4253 - val_loss: 0.0024 - val_mse: 0.4194\n",
      "Epoch 500/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0170 - mse: 2.9455 - val_loss: 0.0023 - val_mse: 0.4023\n",
      "Epoch 501/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0178 - mse: 3.0694 - val_loss: 0.0022 - val_mse: 0.3752\n",
      "Epoch 502/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0218 - mse: 3.0947 - val_loss: 0.0021 - val_mse: 0.3509\n",
      "Epoch 503/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0184 - mse: 3.4236 - val_loss: 0.0021 - val_mse: 0.3529\n",
      "Epoch 504/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0233 - mse: 3.0725 - val_loss: 0.0020 - val_mse: 0.3350\n",
      "Epoch 505/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0160 - mse: 2.6709 - val_loss: 0.0020 - val_mse: 0.3273\n",
      "Epoch 506/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0249 - mse: 3.3124 - val_loss: 0.0019 - val_mse: 0.3116\n",
      "Epoch 507/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0180 - mse: 3.3850 - val_loss: 0.0018 - val_mse: 0.2933\n",
      "Epoch 508/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0217 - mse: 2.9123 - val_loss: 0.0020 - val_mse: 0.3398\n",
      "Epoch 509/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0251 - mse: 3.5728 - val_loss: 0.0022 - val_mse: 0.3824\n",
      "Epoch 510/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0183 - mse: 3.3051 - val_loss: 0.0023 - val_mse: 0.4054\n",
      "Epoch 511/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0248 - mse: 2.9713 - val_loss: 0.0023 - val_mse: 0.4159\n",
      "Epoch 512/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0227 - mse: 3.0121 - val_loss: 0.0024 - val_mse: 0.4234\n",
      "Epoch 513/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0178 - mse: 2.9055 - val_loss: 0.0024 - val_mse: 0.4223\n",
      "Epoch 514/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0245 - mse: 3.7776 - val_loss: 0.0023 - val_mse: 0.4127\n",
      "Epoch 515/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0229 - mse: 3.2165 - val_loss: 0.0021 - val_mse: 0.3641\n",
      "Epoch 516/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0218 - mse: 2.8807 - val_loss: 0.0019 - val_mse: 0.3235\n",
      "Epoch 517/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0220 - mse: 2.6589 - val_loss: 0.0019 - val_mse: 0.3258\n",
      "Epoch 518/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0200 - mse: 3.3580 - val_loss: 0.0022 - val_mse: 0.3774\n",
      "Epoch 519/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0182 - mse: 2.9638 - val_loss: 0.0022 - val_mse: 0.3852\n",
      "Epoch 520/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0178 - mse: 3.3116 - val_loss: 0.0023 - val_mse: 0.3977\n",
      "Epoch 521/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0167 - mse: 2.8245 - val_loss: 0.0022 - val_mse: 0.3762\n",
      "Epoch 522/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0203 - mse: 3.3191 - val_loss: 0.0023 - val_mse: 0.3989\n",
      "Epoch 523/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0237 - mse: 3.7006 - val_loss: 0.0022 - val_mse: 0.3892\n",
      "Epoch 524/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0165 - mse: 2.9859 - val_loss: 0.0020 - val_mse: 0.3456\n",
      "Epoch 525/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0184 - mse: 3.6008 - val_loss: 0.0018 - val_mse: 0.2991\n",
      "Epoch 526/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0158 - mse: 2.7370 - val_loss: 0.0016 - val_mse: 0.2550\n",
      "Epoch 527/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0169 - mse: 2.8545 - val_loss: 0.0015 - val_mse: 0.2236\n",
      "Epoch 528/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0159 - mse: 2.5588 - val_loss: 0.0014 - val_mse: 0.2145\n",
      "Epoch 529/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0158 - mse: 2.7059 - val_loss: 0.0013 - val_mse: 0.1952\n",
      "Epoch 530/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0187 - mse: 2.8001 - val_loss: 0.0014 - val_mse: 0.2166\n",
      "Epoch 531/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0169 - mse: 2.8408 - val_loss: 0.0015 - val_mse: 0.2315\n",
      "Epoch 532/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0186 - mse: 2.7625 - val_loss: 0.0017 - val_mse: 0.2736\n",
      "Epoch 533/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0181 - mse: 3.2640 - val_loss: 0.0019 - val_mse: 0.3074\n",
      "Epoch 534/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0167 - mse: 2.7300 - val_loss: 0.0019 - val_mse: 0.3268\n",
      "Epoch 535/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0183 - mse: 3.1804 - val_loss: 0.0020 - val_mse: 0.3527\n",
      "Epoch 536/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0197 - mse: 2.9018 - val_loss: 0.0027 - val_mse: 0.5216\n",
      "Epoch 537/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0165 - mse: 3.1985 - val_loss: 0.0028 - val_mse: 0.5265\n",
      "Epoch 538/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0217 - mse: 4.1836 - val_loss: 0.0030 - val_mse: 0.5938\n",
      "Epoch 539/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0176 - mse: 3.3953 - val_loss: 0.0030 - val_mse: 0.5920\n",
      "Epoch 540/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0170 - mse: 3.0557 - val_loss: 0.0028 - val_mse: 0.5479\n",
      "Epoch 541/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0189 - mse: 3.3848 - val_loss: 0.0029 - val_mse: 0.5608\n",
      "Epoch 542/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0194 - mse: 3.5963 - val_loss: 0.0028 - val_mse: 0.5314\n",
      "Epoch 543/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0179 - mse: 3.3140 - val_loss: 0.0025 - val_mse: 0.4744\n",
      "Epoch 544/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0244 - mse: 3.0511 - val_loss: 0.0026 - val_mse: 0.4834\n",
      "Epoch 545/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0178 - mse: 3.1351 - val_loss: 0.0027 - val_mse: 0.5251\n",
      "Epoch 546/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0223 - mse: 3.1762 - val_loss: 0.0030 - val_mse: 0.6105\n",
      "Epoch 547/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0184 - mse: 3.6767 - val_loss: 0.0035 - val_mse: 0.7233\n",
      "Epoch 548/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0180 - mse: 3.5018 - val_loss: 0.0034 - val_mse: 0.6959\n",
      "Epoch 549/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0172 - mse: 2.9289 - val_loss: 0.0032 - val_mse: 0.6636\n",
      "Epoch 550/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0181 - mse: 3.5733 - val_loss: 0.0030 - val_mse: 0.6091\n",
      "Epoch 551/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0180 - mse: 3.6182 - val_loss: 0.0027 - val_mse: 0.5311\n",
      "Epoch 552/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0209 - mse: 3.1393 - val_loss: 0.0027 - val_mse: 0.5259\n",
      "Epoch 553/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0201 - mse: 3.4567 - val_loss: 0.0028 - val_mse: 0.5359\n",
      "Epoch 554/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0160 - mse: 2.7616 - val_loss: 0.0026 - val_mse: 0.5026\n",
      "Epoch 555/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0190 - mse: 3.5626 - val_loss: 0.0026 - val_mse: 0.4894\n",
      "Epoch 556/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0177 - mse: 3.5038 - val_loss: 0.0026 - val_mse: 0.4899\n",
      "Epoch 557/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0169 - mse: 3.2373 - val_loss: 0.0024 - val_mse: 0.4365\n",
      "Epoch 558/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0179 - mse: 3.1624 - val_loss: 0.0022 - val_mse: 0.4058\n",
      "Epoch 559/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0197 - mse: 3.2954 - val_loss: 0.0022 - val_mse: 0.3999\n",
      "Epoch 560/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0164 - mse: 2.9145 - val_loss: 0.0021 - val_mse: 0.3666\n",
      "Epoch 561/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0185 - mse: 3.1290 - val_loss: 0.0019 - val_mse: 0.3234\n",
      "Epoch 562/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0156 - mse: 2.7773 - val_loss: 0.0017 - val_mse: 0.2871\n",
      "Epoch 563/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0167 - mse: 2.6186 - val_loss: 0.0018 - val_mse: 0.3036\n",
      "Epoch 564/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0154 - mse: 2.8524 - val_loss: 0.0018 - val_mse: 0.3071\n",
      "Epoch 565/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0203 - mse: 2.7078 - val_loss: 0.0018 - val_mse: 0.3011\n",
      "Epoch 566/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0174 - mse: 2.7854 - val_loss: 0.0019 - val_mse: 0.3305\n",
      "Epoch 567/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0175 - mse: 3.3287 - val_loss: 0.0018 - val_mse: 0.3105\n",
      "Epoch 568/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0154 - mse: 2.7038 - val_loss: 0.0017 - val_mse: 0.2769\n",
      "Epoch 569/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0165 - mse: 2.9131 - val_loss: 0.0015 - val_mse: 0.2476\n",
      "Epoch 570/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0220 - mse: 2.8358 - val_loss: 0.0014 - val_mse: 0.2294\n",
      "Epoch 571/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0209 - mse: 3.0847 - val_loss: 0.0016 - val_mse: 0.2621\n",
      "Epoch 572/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0161 - mse: 2.8518 - val_loss: 0.0016 - val_mse: 0.2595\n",
      "Epoch 573/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0182 - mse: 3.0283 - val_loss: 0.0016 - val_mse: 0.2567\n",
      "Epoch 574/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0168 - mse: 2.8346 - val_loss: 0.0016 - val_mse: 0.2672\n",
      "Epoch 575/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0237 - mse: 3.1822 - val_loss: 0.0016 - val_mse: 0.2652\n",
      "Epoch 576/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0168 - mse: 2.7544 - val_loss: 0.0016 - val_mse: 0.2564\n",
      "Epoch 577/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0247 - mse: 3.1754 - val_loss: 0.0017 - val_mse: 0.2802\n",
      "Epoch 578/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0181 - mse: 3.2469 - val_loss: 0.0018 - val_mse: 0.3005\n",
      "Epoch 579/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0212 - mse: 2.8567 - val_loss: 0.0018 - val_mse: 0.2967\n",
      "Epoch 580/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0181 - mse: 2.9525 - val_loss: 0.0017 - val_mse: 0.2936\n",
      "Epoch 581/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0166 - mse: 2.9689 - val_loss: 0.0017 - val_mse: 0.2787\n",
      "Epoch 582/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0154 - mse: 2.5546 - val_loss: 0.0015 - val_mse: 0.2501\n",
      "Epoch 583/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0168 - mse: 2.5418 - val_loss: 0.0015 - val_mse: 0.2454\n",
      "Epoch 584/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0161 - mse: 2.8057 - val_loss: 0.0015 - val_mse: 0.2473\n",
      "Epoch 585/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0215 - mse: 3.0311 - val_loss: 0.0014 - val_mse: 0.2293\n",
      "Epoch 586/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0149 - mse: 2.6526 - val_loss: 0.0013 - val_mse: 0.2068\n",
      "Epoch 587/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0196 - mse: 2.9180 - val_loss: 0.0016 - val_mse: 0.2682\n",
      "Epoch 588/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0166 - mse: 2.6531 - val_loss: 0.0019 - val_mse: 0.3407\n",
      "Epoch 589/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0155 - mse: 2.7060 - val_loss: 0.0021 - val_mse: 0.3809\n",
      "Epoch 590/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0189 - mse: 3.2613 - val_loss: 0.0021 - val_mse: 0.3862\n",
      "Epoch 591/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0167 - mse: 2.8338 - val_loss: 0.0020 - val_mse: 0.3627\n",
      "Epoch 592/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0165 - mse: 3.1070 - val_loss: 0.0019 - val_mse: 0.3287\n",
      "Epoch 593/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0206 - mse: 2.7672 - val_loss: 0.0017 - val_mse: 0.2872\n",
      "Epoch 594/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0173 - mse: 2.7672 - val_loss: 0.0016 - val_mse: 0.2619\n",
      "Epoch 595/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0154 - mse: 2.8580 - val_loss: 0.0014 - val_mse: 0.2323\n",
      "Epoch 596/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0200 - mse: 2.8877 - val_loss: 0.0016 - val_mse: 0.2672\n",
      "Epoch 597/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0167 - mse: 2.8480 - val_loss: 0.0017 - val_mse: 0.2836\n",
      "Epoch 598/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0155 - mse: 2.6873 - val_loss: 0.0016 - val_mse: 0.2612\n",
      "Epoch 599/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0156 - mse: 2.6956 - val_loss: 0.0015 - val_mse: 0.2348\n",
      "Epoch 600/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0166 - mse: 2.8947 - val_loss: 0.0014 - val_mse: 0.2190\n",
      "Epoch 601/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0186 - mse: 2.7773 - val_loss: 0.0016 - val_mse: 0.2663\n",
      "Epoch 602/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0243 - mse: 2.9088 - val_loss: 0.0018 - val_mse: 0.3069\n",
      "Epoch 603/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0162 - mse: 2.6942 - val_loss: 0.0020 - val_mse: 0.3522\n",
      "Epoch 604/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0162 - mse: 2.8445 - val_loss: 0.0020 - val_mse: 0.3489\n",
      "Epoch 605/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0145 - mse: 2.4121 - val_loss: 0.0018 - val_mse: 0.3225\n",
      "Epoch 606/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0154 - mse: 2.7670 - val_loss: 0.0017 - val_mse: 0.2848\n",
      "Epoch 607/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0152 - mse: 2.5141 - val_loss: 0.0015 - val_mse: 0.2373\n",
      "Epoch 608/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0156 - mse: 2.5819 - val_loss: 0.0013 - val_mse: 0.1950\n",
      "Epoch 609/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0202 - mse: 2.4996 - val_loss: 0.0012 - val_mse: 0.1807\n",
      "Epoch 610/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0143 - mse: 2.4062 - val_loss: 0.0011 - val_mse: 0.1692\n",
      "Epoch 611/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0178 - mse: 2.6745 - val_loss: 0.0013 - val_mse: 0.1981\n",
      "Epoch 612/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0167 - mse: 2.6674 - val_loss: 0.0013 - val_mse: 0.1987\n",
      "Epoch 613/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0161 - mse: 2.6538 - val_loss: 0.0013 - val_mse: 0.2012\n",
      "Epoch 614/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0164 - mse: 2.8052 - val_loss: 0.0013 - val_mse: 0.2044\n",
      "Epoch 615/2000\n",
      "1168/1168 [==============================] - 0s 53us/step - loss: 0.0149 - mse: 2.6916 - val_loss: 0.0013 - val_mse: 0.2033\n",
      "Epoch 616/2000\n",
      "1168/1168 [==============================] - 0s 47us/step - loss: 0.0137 - mse: 2.3786 - val_loss: 0.0012 - val_mse: 0.1914\n",
      "Epoch 617/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0220 - mse: 2.7470 - val_loss: 0.0012 - val_mse: 0.1912\n",
      "Epoch 618/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0149 - mse: 2.5087 - val_loss: 0.0012 - val_mse: 0.1791\n",
      "Epoch 619/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0152 - mse: 2.4547 - val_loss: 0.0011 - val_mse: 0.1626\n",
      "Epoch 620/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0146 - mse: 2.3639 - val_loss: 0.0011 - val_mse: 0.1640\n",
      "Epoch 621/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0196 - mse: 2.4286 - val_loss: 0.0011 - val_mse: 0.1675\n",
      "Epoch 622/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0198 - mse: 2.6896 - val_loss: 0.0011 - val_mse: 0.1581\n",
      "Epoch 623/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0156 - mse: 2.4109 - val_loss: 0.0011 - val_mse: 0.1603\n",
      "Epoch 624/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0150 - mse: 2.5917 - val_loss: 9.9665e-04 - val_mse: 0.1443\n",
      "Epoch 625/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0170 - mse: 2.3542 - val_loss: 0.0012 - val_mse: 0.1830\n",
      "Epoch 626/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0153 - mse: 2.5008 - val_loss: 0.0013 - val_mse: 0.1965\n",
      "Epoch 627/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0136 - mse: 2.2971 - val_loss: 0.0012 - val_mse: 0.1865\n",
      "Epoch 628/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0144 - mse: 2.4031 - val_loss: 0.0012 - val_mse: 0.1835\n",
      "Epoch 629/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0154 - mse: 2.6786 - val_loss: 0.0012 - val_mse: 0.1763\n",
      "Epoch 630/2000\n",
      "1168/1168 [==============================] - 0s 46us/step - loss: 0.0138 - mse: 2.3788 - val_loss: 0.0010 - val_mse: 0.1535\n",
      "Epoch 631/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0169 - mse: 2.5191 - val_loss: 0.0010 - val_mse: 0.1499\n",
      "Epoch 632/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0145 - mse: 2.4270 - val_loss: 0.0010 - val_mse: 0.1512\n",
      "Epoch 633/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0143 - mse: 2.4607 - val_loss: 0.0011 - val_mse: 0.1569\n",
      "Epoch 634/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0156 - mse: 2.6435 - val_loss: 0.0011 - val_mse: 0.1665\n",
      "Epoch 635/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0168 - mse: 2.6084 - val_loss: 0.0012 - val_mse: 0.1779\n",
      "Epoch 636/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0143 - mse: 2.4361 - val_loss: 0.0011 - val_mse: 0.1707\n",
      "Epoch 637/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0162 - mse: 2.6023 - val_loss: 0.0011 - val_mse: 0.1684\n",
      "Epoch 638/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0165 - mse: 2.4415 - val_loss: 0.0011 - val_mse: 0.1663\n",
      "Epoch 639/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0148 - mse: 2.4358 - val_loss: 0.0012 - val_mse: 0.1954\n",
      "Epoch 640/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0140 - mse: 2.3448 - val_loss: 0.0012 - val_mse: 0.1901\n",
      "Epoch 641/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0179 - mse: 2.5348 - val_loss: 0.0017 - val_mse: 0.2914\n",
      "Epoch 642/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0215 - mse: 2.8219 - val_loss: 0.0018 - val_mse: 0.3192\n",
      "Epoch 643/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0148 - mse: 2.6143 - val_loss: 0.0018 - val_mse: 0.3104\n",
      "Epoch 644/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0175 - mse: 2.5722 - val_loss: 0.0017 - val_mse: 0.3053\n",
      "Epoch 645/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0191 - mse: 2.4006 - val_loss: 0.0019 - val_mse: 0.3525\n",
      "Epoch 646/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0145 - mse: 2.5070 - val_loss: 0.0019 - val_mse: 0.3504\n",
      "Epoch 647/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0163 - mse: 2.7863 - val_loss: 0.0017 - val_mse: 0.3019\n",
      "Epoch 648/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0134 - mse: 2.2402 - val_loss: 0.0015 - val_mse: 0.2551\n",
      "Epoch 649/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0196 - mse: 2.4299 - val_loss: 0.0014 - val_mse: 0.2282\n",
      "Epoch 650/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0135 - mse: 2.3191 - val_loss: 0.0013 - val_mse: 0.2020\n",
      "Epoch 651/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0156 - mse: 2.7662 - val_loss: 0.0011 - val_mse: 0.1806\n",
      "Epoch 652/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0156 - mse: 2.3824 - val_loss: 0.0012 - val_mse: 0.1895\n",
      "Epoch 653/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0157 - mse: 2.3341 - val_loss: 0.0014 - val_mse: 0.2287\n",
      "Epoch 654/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0145 - mse: 2.3823 - val_loss: 0.0014 - val_mse: 0.2354\n",
      "Epoch 655/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0154 - mse: 2.6384 - val_loss: 0.0014 - val_mse: 0.2294\n",
      "Epoch 656/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0147 - mse: 2.3259 - val_loss: 0.0014 - val_mse: 0.2214\n",
      "Epoch 657/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0159 - mse: 2.5775 - val_loss: 0.0014 - val_mse: 0.2234\n",
      "Epoch 658/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0191 - mse: 2.6261 - val_loss: 0.0019 - val_mse: 0.3507\n",
      "Epoch 659/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0144 - mse: 2.4263 - val_loss: 0.0020 - val_mse: 0.3706\n",
      "Epoch 660/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0154 - mse: 2.9396 - val_loss: 0.0018 - val_mse: 0.3328\n",
      "Epoch 661/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0211 - mse: 2.9148 - val_loss: 0.0016 - val_mse: 0.2740\n",
      "Epoch 662/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0154 - mse: 2.6236 - val_loss: 0.0015 - val_mse: 0.2512\n",
      "Epoch 663/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0146 - mse: 2.3099 - val_loss: 0.0015 - val_mse: 0.2562\n",
      "Epoch 664/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0151 - mse: 2.6553 - val_loss: 0.0014 - val_mse: 0.2241\n",
      "Epoch 665/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0149 - mse: 2.5897 - val_loss: 0.0011 - val_mse: 0.1825\n",
      "Epoch 666/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0136 - mse: 2.1818 - val_loss: 0.0011 - val_mse: 0.1631\n",
      "Epoch 667/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0137 - mse: 2.2368 - val_loss: 0.0010 - val_mse: 0.1563\n",
      "Epoch 668/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0143 - mse: 2.2837 - val_loss: 9.6073e-04 - val_mse: 0.1450\n",
      "Epoch 669/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0136 - mse: 2.1773 - val_loss: 8.9772e-04 - val_mse: 0.1331\n",
      "Epoch 670/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0149 - mse: 2.4919 - val_loss: 8.5498e-04 - val_mse: 0.1247\n",
      "Epoch 671/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0149 - mse: 2.3722 - val_loss: 8.3105e-04 - val_mse: 0.1196\n",
      "Epoch 672/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0157 - mse: 1.9473 - val_loss: 9.4144e-04 - val_mse: 0.1413\n",
      "Epoch 673/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0145 - mse: 2.4811 - val_loss: 0.0011 - val_mse: 0.1807\n",
      "Epoch 674/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0156 - mse: 2.3510 - val_loss: 0.0012 - val_mse: 0.2003\n",
      "Epoch 675/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0166 - mse: 2.3832 - val_loss: 0.0014 - val_mse: 0.2398\n",
      "Epoch 676/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0150 - mse: 2.6413 - val_loss: 0.0015 - val_mse: 0.2576\n",
      "Epoch 677/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0145 - mse: 2.6195 - val_loss: 0.0014 - val_mse: 0.2374\n",
      "Epoch 678/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0141 - mse: 2.5200 - val_loss: 0.0012 - val_mse: 0.2048\n",
      "Epoch 679/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0128 - mse: 2.1161 - val_loss: 0.0011 - val_mse: 0.1766\n",
      "Epoch 680/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0149 - mse: 2.2564 - val_loss: 0.0011 - val_mse: 0.1763\n",
      "Epoch 681/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0141 - mse: 2.2319 - val_loss: 0.0011 - val_mse: 0.1690\n",
      "Epoch 682/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0124 - mse: 1.9722 - val_loss: 0.0011 - val_mse: 0.1750\n",
      "Epoch 683/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0135 - mse: 2.2182 - val_loss: 0.0011 - val_mse: 0.1810\n",
      "Epoch 684/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0137 - mse: 2.2337 - val_loss: 0.0011 - val_mse: 0.1759\n",
      "Epoch 685/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0130 - mse: 2.1644 - val_loss: 0.0011 - val_mse: 0.1737\n",
      "Epoch 686/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0140 - mse: 2.2683 - val_loss: 0.0011 - val_mse: 0.1727\n",
      "Epoch 687/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0128 - mse: 2.0774 - val_loss: 0.0010 - val_mse: 0.1655\n",
      "Epoch 688/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0116 - mse: 1.9717 - val_loss: 9.1772e-04 - val_mse: 0.1397\n",
      "Epoch 689/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0159 - mse: 2.2246 - val_loss: 9.6832e-04 - val_mse: 0.1503\n",
      "Epoch 690/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0138 - mse: 2.2678 - val_loss: 9.8730e-04 - val_mse: 0.1545\n",
      "Epoch 691/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0126 - mse: 2.0544 - val_loss: 9.7211e-04 - val_mse: 0.1516\n",
      "Epoch 692/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0129 - mse: 2.0835 - val_loss: 9.0720e-04 - val_mse: 0.1390\n",
      "Epoch 693/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0143 - mse: 2.3085 - val_loss: 8.2991e-04 - val_mse: 0.1240\n",
      "Epoch 694/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0135 - mse: 2.1554 - val_loss: 7.8712e-04 - val_mse: 0.1152\n",
      "Epoch 695/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0121 - mse: 1.9885 - val_loss: 7.4577e-04 - val_mse: 0.1071\n",
      "Epoch 696/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0134 - mse: 2.1042 - val_loss: 7.2784e-04 - val_mse: 0.1037\n",
      "Epoch 697/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0153 - mse: 2.2585 - val_loss: 8.0829e-04 - val_mse: 0.1192\n",
      "Epoch 698/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0152 - mse: 2.1715 - val_loss: 0.0011 - val_mse: 0.1714\n",
      "Epoch 699/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0136 - mse: 2.2675 - val_loss: 0.0012 - val_mse: 0.1965\n",
      "Epoch 700/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0154 - mse: 2.4578 - val_loss: 0.0012 - val_mse: 0.1928\n",
      "Epoch 701/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0124 - mse: 2.0129 - val_loss: 0.0011 - val_mse: 0.1783\n",
      "Epoch 702/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0126 - mse: 2.0014 - val_loss: 0.0010 - val_mse: 0.1594\n",
      "Epoch 703/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0131 - mse: 2.1512 - val_loss: 9.5788e-04 - val_mse: 0.1497\n",
      "Epoch 704/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0131 - mse: 2.1593 - val_loss: 8.7673e-04 - val_mse: 0.1339\n",
      "Epoch 705/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0126 - mse: 2.0550 - val_loss: 8.3906e-04 - val_mse: 0.1266\n",
      "Epoch 706/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0126 - mse: 1.9947 - val_loss: 8.0720e-04 - val_mse: 0.1208\n",
      "Epoch 707/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0170 - mse: 2.3794 - val_loss: 9.2013e-04 - val_mse: 0.1431\n",
      "Epoch 708/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0131 - mse: 2.0699 - val_loss: 9.6215e-04 - val_mse: 0.1518\n",
      "Epoch 709/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0126 - mse: 2.0899 - val_loss: 9.1653e-04 - val_mse: 0.1429\n",
      "Epoch 710/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0128 - mse: 2.1326 - val_loss: 8.3610e-04 - val_mse: 0.1272\n",
      "Epoch 711/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0146 - mse: 2.2972 - val_loss: 7.9200e-04 - val_mse: 0.1182\n",
      "Epoch 712/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0157 - mse: 2.3927 - val_loss: 8.1666e-04 - val_mse: 0.1235\n",
      "Epoch 713/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0127 - mse: 2.1022 - val_loss: 8.0770e-04 - val_mse: 0.1221\n",
      "Epoch 714/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0127 - mse: 2.0458 - val_loss: 7.5828e-04 - val_mse: 0.1126\n",
      "Epoch 715/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0134 - mse: 2.1534 - val_loss: 7.4019e-04 - val_mse: 0.1087\n",
      "Epoch 716/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0160 - mse: 2.2955 - val_loss: 7.1718e-04 - val_mse: 0.1051\n",
      "Epoch 717/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0127 - mse: 2.0955 - val_loss: 7.6037e-04 - val_mse: 0.1133\n",
      "Epoch 718/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0126 - mse: 2.1171 - val_loss: 7.3939e-04 - val_mse: 0.1096\n",
      "Epoch 719/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0124 - mse: 2.0846 - val_loss: 7.0728e-04 - val_mse: 0.1037\n",
      "Epoch 720/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0123 - mse: 1.9426 - val_loss: 6.8111e-04 - val_mse: 0.0989\n",
      "Epoch 721/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0123 - mse: 2.0020 - val_loss: 6.6371e-04 - val_mse: 0.0959\n",
      "Epoch 722/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0137 - mse: 2.1329 - val_loss: 6.8415e-04 - val_mse: 0.0990\n",
      "Epoch 723/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0118 - mse: 1.9497 - val_loss: 6.8003e-04 - val_mse: 0.0981\n",
      "Epoch 724/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0112 - mse: 1.8745 - val_loss: 6.1669e-04 - val_mse: 0.0871\n",
      "Epoch 725/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0118 - mse: 1.8643 - val_loss: 5.6742e-04 - val_mse: 0.0788\n",
      "Epoch 726/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0176 - mse: 2.1983 - val_loss: 7.7352e-04 - val_mse: 0.1180\n",
      "Epoch 727/2000\n",
      "1168/1168 [==============================] - 0s 47us/step - loss: 0.0161 - mse: 2.2620 - val_loss: 0.0011 - val_mse: 0.1796\n",
      "Epoch 728/2000\n",
      "1168/1168 [==============================] - 0s 51us/step - loss: 0.0126 - mse: 2.1760 - val_loss: 0.0012 - val_mse: 0.1996\n",
      "Epoch 729/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0124 - mse: 2.0750 - val_loss: 0.0011 - val_mse: 0.1916\n",
      "Epoch 730/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0124 - mse: 2.0841 - val_loss: 0.0011 - val_mse: 0.1765\n",
      "Epoch 731/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0143 - mse: 2.3637 - val_loss: 9.8130e-04 - val_mse: 0.1602\n",
      "Epoch 732/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0127 - mse: 1.9762 - val_loss: 9.0344e-04 - val_mse: 0.1454\n",
      "Epoch 733/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0124 - mse: 1.9924 - val_loss: 8.8975e-04 - val_mse: 0.1429\n",
      "Epoch 734/2000\n",
      "1168/1168 [==============================] - 0s 50us/step - loss: 0.0128 - mse: 2.0796 - val_loss: 8.1699e-04 - val_mse: 0.1286\n",
      "Epoch 735/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0124 - mse: 2.0146 - val_loss: 7.4915e-04 - val_mse: 0.1153\n",
      "Epoch 736/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0142 - mse: 2.2292 - val_loss: 6.9735e-04 - val_mse: 0.1053\n",
      "Epoch 737/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0124 - mse: 1.9931 - val_loss: 6.5795e-04 - val_mse: 0.0979\n",
      "Epoch 738/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0130 - mse: 2.0801 - val_loss: 6.3382e-04 - val_mse: 0.0934\n",
      "Epoch 739/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0129 - mse: 2.0438 - val_loss: 6.1037e-04 - val_mse: 0.0893\n",
      "Epoch 740/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0115 - mse: 1.8660 - val_loss: 6.1198e-04 - val_mse: 0.0897\n",
      "Epoch 741/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0119 - mse: 1.9702 - val_loss: 6.2653e-04 - val_mse: 0.0920\n",
      "Epoch 742/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0132 - mse: 2.0902 - val_loss: 5.8094e-04 - val_mse: 0.0842\n",
      "Epoch 743/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0133 - mse: 2.0622 - val_loss: 5.9662e-04 - val_mse: 0.0870\n",
      "Epoch 744/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0135 - mse: 2.1122 - val_loss: 6.2798e-04 - val_mse: 0.0925\n",
      "Epoch 745/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0124 - mse: 2.0177 - val_loss: 6.5527e-04 - val_mse: 0.0970\n",
      "Epoch 746/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0116 - mse: 1.9142 - val_loss: 6.6796e-04 - val_mse: 0.0989\n",
      "Epoch 747/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0117 - mse: 1.9646 - val_loss: 6.1468e-04 - val_mse: 0.0897\n",
      "Epoch 748/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0124 - mse: 1.9894 - val_loss: 5.3604e-04 - val_mse: 0.0763\n",
      "Epoch 749/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0120 - mse: 1.9181 - val_loss: 5.0555e-04 - val_mse: 0.0711\n",
      "Epoch 750/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0121 - mse: 1.9837 - val_loss: 4.9527e-04 - val_mse: 0.0694\n",
      "Epoch 751/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0114 - mse: 1.8252 - val_loss: 4.9364e-04 - val_mse: 0.0690\n",
      "Epoch 752/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0120 - mse: 1.9205 - val_loss: 4.9334e-04 - val_mse: 0.0690\n",
      "Epoch 753/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0107 - mse: 1.7592 - val_loss: 4.7678e-04 - val_mse: 0.0663\n",
      "Epoch 754/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0121 - mse: 1.8994 - val_loss: 4.7333e-04 - val_mse: 0.0658\n",
      "Epoch 755/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0126 - mse: 1.9686 - val_loss: 4.7841e-04 - val_mse: 0.0668\n",
      "Epoch 756/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0109 - mse: 1.7568 - val_loss: 4.9280e-04 - val_mse: 0.0694\n",
      "Epoch 757/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0115 - mse: 1.8904 - val_loss: 4.9943e-04 - val_mse: 0.0705\n",
      "Epoch 758/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0119 - mse: 1.9446 - val_loss: 4.8925e-04 - val_mse: 0.0688\n",
      "Epoch 759/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0109 - mse: 1.7636 - val_loss: 4.6156e-04 - val_mse: 0.0641\n",
      "Epoch 760/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0120 - mse: 1.8956 - val_loss: 4.5348e-04 - val_mse: 0.0629\n",
      "Epoch 761/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0123 - mse: 1.8973 - val_loss: 4.5053e-04 - val_mse: 0.0628\n",
      "Epoch 762/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0119 - mse: 1.8471 - val_loss: 4.6025e-04 - val_mse: 0.0646\n",
      "Epoch 763/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0118 - mse: 1.8076 - val_loss: 4.7549e-04 - val_mse: 0.0673\n",
      "Epoch 764/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0107 - mse: 1.7449 - val_loss: 4.8955e-04 - val_mse: 0.0700\n",
      "Epoch 765/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0117 - mse: 1.9017 - val_loss: 4.8632e-04 - val_mse: 0.0696\n",
      "Epoch 766/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0107 - mse: 1.7461 - val_loss: 4.5751e-04 - val_mse: 0.0645\n",
      "Epoch 767/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0113 - mse: 1.7841 - val_loss: 4.3971e-04 - val_mse: 0.0614\n",
      "Epoch 768/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0115 - mse: 1.8236 - val_loss: 4.3431e-04 - val_mse: 0.0606\n",
      "Epoch 769/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0108 - mse: 1.7329 - val_loss: 4.4021e-04 - val_mse: 0.0618\n",
      "Epoch 770/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0115 - mse: 1.8055 - val_loss: 4.4991e-04 - val_mse: 0.0637\n",
      "Epoch 771/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0121 - mse: 1.8875 - val_loss: 4.3932e-04 - val_mse: 0.0618\n",
      "Epoch 772/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0115 - mse: 1.8541 - val_loss: 4.3106e-04 - val_mse: 0.0603\n",
      "Epoch 773/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0111 - mse: 1.7862 - val_loss: 4.2269e-04 - val_mse: 0.0589\n",
      "Epoch 774/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0111 - mse: 1.7825 - val_loss: 4.3282e-04 - val_mse: 0.0607\n",
      "Epoch 775/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0112 - mse: 1.7853 - val_loss: 4.5226e-04 - val_mse: 0.0640\n",
      "Epoch 776/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0116 - mse: 1.8232 - val_loss: 4.2668e-04 - val_mse: 0.0602\n",
      "Epoch 777/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0123 - mse: 1.9376 - val_loss: 4.1713e-04 - val_mse: 0.0585\n",
      "Epoch 778/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0106 - mse: 1.6717 - val_loss: 4.2065e-04 - val_mse: 0.0592\n",
      "Epoch 779/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0126 - mse: 1.8970 - val_loss: 4.4310e-04 - val_mse: 0.0633\n",
      "Epoch 780/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0109 - mse: 1.7580 - val_loss: 4.4876e-04 - val_mse: 0.0645\n",
      "Epoch 781/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0119 - mse: 1.8494 - val_loss: 4.7376e-04 - val_mse: 0.0687\n",
      "Epoch 782/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0113 - mse: 1.7638 - val_loss: 4.7034e-04 - val_mse: 0.0685\n",
      "Epoch 783/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0115 - mse: 1.8257 - val_loss: 4.6854e-04 - val_mse: 0.0684\n",
      "Epoch 784/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0102 - mse: 1.6565 - val_loss: 4.5023e-04 - val_mse: 0.0653\n",
      "Epoch 785/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0119 - mse: 1.8408 - val_loss: 4.4467e-04 - val_mse: 0.0644\n",
      "Epoch 786/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0118 - mse: 1.8001 - val_loss: 4.3433e-04 - val_mse: 0.0627\n",
      "Epoch 787/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0111 - mse: 1.7807 - val_loss: 4.1895e-04 - val_mse: 0.0601\n",
      "Epoch 788/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0129 - mse: 1.9411 - val_loss: 4.1720e-04 - val_mse: 0.0598\n",
      "Epoch 789/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0110 - mse: 1.7663 - val_loss: 4.2147e-04 - val_mse: 0.0603\n",
      "Epoch 790/2000\n",
      "1168/1168 [==============================] - 0s 36us/step - loss: 0.0123 - mse: 1.9094 - val_loss: 4.1575e-04 - val_mse: 0.0594\n",
      "Epoch 791/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0114 - mse: 1.7942 - val_loss: 4.0475e-04 - val_mse: 0.0578\n",
      "Epoch 792/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0105 - mse: 1.7305 - val_loss: 3.9689e-04 - val_mse: 0.0565\n",
      "Epoch 793/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0106 - mse: 1.6713 - val_loss: 3.7849e-04 - val_mse: 0.0534\n",
      "Epoch 794/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0109 - mse: 1.7469 - val_loss: 3.6585e-04 - val_mse: 0.0515\n",
      "Epoch 795/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0111 - mse: 1.7298 - val_loss: 3.5239e-04 - val_mse: 0.0490\n",
      "Epoch 796/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0112 - mse: 1.7850 - val_loss: 3.6863e-04 - val_mse: 0.0516\n",
      "Epoch 797/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0103 - mse: 1.6814 - val_loss: 3.5498e-04 - val_mse: 0.0494\n",
      "Epoch 798/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0116 - mse: 1.8047 - val_loss: 3.4282e-04 - val_mse: 0.0476\n",
      "Epoch 799/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0120 - mse: 1.8692 - val_loss: 3.4800e-04 - val_mse: 0.0485\n",
      "Epoch 800/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0102 - mse: 1.6253 - val_loss: 3.4807e-04 - val_mse: 0.0486\n",
      "Epoch 801/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0107 - mse: 1.7313 - val_loss: 3.4790e-04 - val_mse: 0.0486\n",
      "Epoch 802/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0106 - mse: 1.6807 - val_loss: 3.4234e-04 - val_mse: 0.0479\n",
      "Epoch 803/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0108 - mse: 1.7297 - val_loss: 3.4462e-04 - val_mse: 0.0485\n",
      "Epoch 804/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0098 - mse: 1.5943 - val_loss: 3.5765e-04 - val_mse: 0.0509\n",
      "Epoch 805/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0112 - mse: 1.7380 - val_loss: 3.5375e-04 - val_mse: 0.0503\n",
      "Epoch 806/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0107 - mse: 1.6614 - val_loss: 3.4154e-04 - val_mse: 0.0480\n",
      "Epoch 807/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0100 - mse: 1.5901 - val_loss: 3.6959e-04 - val_mse: 0.0526\n",
      "Epoch 808/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0104 - mse: 1.7146 - val_loss: 3.7338e-04 - val_mse: 0.0532\n",
      "Epoch 809/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0112 - mse: 1.7971 - val_loss: 3.6138e-04 - val_mse: 0.0513\n",
      "Epoch 810/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0111 - mse: 1.7578 - val_loss: 3.5034e-04 - val_mse: 0.0498\n",
      "Epoch 811/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0104 - mse: 1.6904 - val_loss: 3.6021e-04 - val_mse: 0.0518\n",
      "Epoch 812/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0104 - mse: 1.6480 - val_loss: 3.5371e-04 - val_mse: 0.0505\n",
      "Epoch 813/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0101 - mse: 1.6298 - val_loss: 3.5688e-04 - val_mse: 0.0510\n",
      "Epoch 814/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0099 - mse: 1.6152 - val_loss: 3.4554e-04 - val_mse: 0.0492\n",
      "Epoch 815/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0120 - mse: 1.8181 - val_loss: 3.5373e-04 - val_mse: 0.0509\n",
      "Epoch 816/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0107 - mse: 1.6072 - val_loss: 3.6466e-04 - val_mse: 0.0527\n",
      "Epoch 817/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0106 - mse: 1.6987 - val_loss: 3.8804e-04 - val_mse: 0.0567\n",
      "Epoch 818/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0109 - mse: 1.7557 - val_loss: 3.6534e-04 - val_mse: 0.0529\n",
      "Epoch 819/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0110 - mse: 1.7385 - val_loss: 3.5335e-04 - val_mse: 0.0510\n",
      "Epoch 820/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0104 - mse: 1.6517 - val_loss: 3.5309e-04 - val_mse: 0.0511\n",
      "Epoch 821/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0097 - mse: 1.5586 - val_loss: 3.5936e-04 - val_mse: 0.0524\n",
      "Epoch 822/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0103 - mse: 1.6419 - val_loss: 3.3757e-04 - val_mse: 0.0487\n",
      "Epoch 823/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0116 - mse: 1.7709 - val_loss: 3.2253e-04 - val_mse: 0.0459\n",
      "Epoch 824/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0104 - mse: 1.6742 - val_loss: 3.2480e-04 - val_mse: 0.0461\n",
      "Epoch 825/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0114 - mse: 1.7602 - val_loss: 3.2820e-04 - val_mse: 0.0468\n",
      "Epoch 826/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0103 - mse: 1.6621 - val_loss: 3.3204e-04 - val_mse: 0.0475\n",
      "Epoch 827/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0102 - mse: 1.6370 - val_loss: 3.1790e-04 - val_mse: 0.0455\n",
      "Epoch 828/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0107 - mse: 1.7079 - val_loss: 3.1504e-04 - val_mse: 0.0452\n",
      "Epoch 829/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0105 - mse: 1.6124 - val_loss: 3.2339e-04 - val_mse: 0.0467\n",
      "Epoch 830/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0102 - mse: 1.6529 - val_loss: 3.4556e-04 - val_mse: 0.0502\n",
      "Epoch 831/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0104 - mse: 1.6791 - val_loss: 3.1506e-04 - val_mse: 0.0455\n",
      "Epoch 832/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0101 - mse: 1.5972 - val_loss: 3.1280e-04 - val_mse: 0.0454\n",
      "Epoch 833/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0097 - mse: 1.5522 - val_loss: 3.1066e-04 - val_mse: 0.0451\n",
      "Epoch 834/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0104 - mse: 1.6121 - val_loss: 3.0381e-04 - val_mse: 0.0439\n",
      "Epoch 835/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0108 - mse: 1.7062 - val_loss: 3.1727e-04 - val_mse: 0.0459\n",
      "Epoch 836/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0108 - mse: 1.7683 - val_loss: 3.1490e-04 - val_mse: 0.0456\n",
      "Epoch 837/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0107 - mse: 1.7018 - val_loss: 3.0059e-04 - val_mse: 0.0436\n",
      "Epoch 838/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0104 - mse: 1.6284 - val_loss: 3.0639e-04 - val_mse: 0.0447\n",
      "Epoch 839/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0099 - mse: 1.5845 - val_loss: 3.2106e-04 - val_mse: 0.0474\n",
      "Epoch 840/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0109 - mse: 1.6993 - val_loss: 3.2155e-04 - val_mse: 0.0474\n",
      "Epoch 841/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0095 - mse: 1.5338 - val_loss: 3.2020e-04 - val_mse: 0.0472\n",
      "Epoch 842/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0109 - mse: 1.7029 - val_loss: 3.3076e-04 - val_mse: 0.0490\n",
      "Epoch 843/2000\n",
      "1168/1168 [==============================] - 0s 49us/step - loss: 0.0099 - mse: 1.6056 - val_loss: 3.8418e-04 - val_mse: 0.0579\n",
      "Epoch 844/2000\n",
      "1168/1168 [==============================] - 0s 47us/step - loss: 0.0105 - mse: 1.6899 - val_loss: 3.4676e-04 - val_mse: 0.0517\n",
      "Epoch 845/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0105 - mse: 1.6551 - val_loss: 3.2405e-04 - val_mse: 0.0480\n",
      "Epoch 846/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0104 - mse: 1.6177 - val_loss: 3.2018e-04 - val_mse: 0.0473\n",
      "Epoch 847/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0114 - mse: 1.7474 - val_loss: 3.2050e-04 - val_mse: 0.0474\n",
      "Epoch 848/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0093 - mse: 1.4808 - val_loss: 3.1782e-04 - val_mse: 0.0471\n",
      "Epoch 849/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0101 - mse: 1.6121 - val_loss: 3.1415e-04 - val_mse: 0.0465\n",
      "Epoch 850/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0103 - mse: 1.6499 - val_loss: 3.1686e-04 - val_mse: 0.0472\n",
      "Epoch 851/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0101 - mse: 1.5896 - val_loss: 3.0803e-04 - val_mse: 0.0456\n",
      "Epoch 852/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0098 - mse: 1.5608 - val_loss: 3.1945e-04 - val_mse: 0.0474\n",
      "Epoch 853/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0097 - mse: 1.5745 - val_loss: 3.3601e-04 - val_mse: 0.0503\n",
      "Epoch 854/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0094 - mse: 1.5563 - val_loss: 3.2162e-04 - val_mse: 0.0479\n",
      "Epoch 855/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0097 - mse: 1.5342 - val_loss: 3.0992e-04 - val_mse: 0.0460\n",
      "Epoch 856/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0096 - mse: 1.5463 - val_loss: 2.9475e-04 - val_mse: 0.0436\n",
      "Epoch 857/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0102 - mse: 1.6359 - val_loss: 2.9492e-04 - val_mse: 0.0437\n",
      "Epoch 858/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0094 - mse: 1.5148 - val_loss: 2.9298e-04 - val_mse: 0.0435\n",
      "Epoch 859/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0107 - mse: 1.6575 - val_loss: 2.9433e-04 - val_mse: 0.0436\n",
      "Epoch 860/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0095 - mse: 1.5432 - val_loss: 3.2648e-04 - val_mse: 0.0489\n",
      "Epoch 861/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0096 - mse: 1.5637 - val_loss: 3.1666e-04 - val_mse: 0.0473\n",
      "Epoch 862/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0101 - mse: 1.6113 - val_loss: 3.1612e-04 - val_mse: 0.0472\n",
      "Epoch 863/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0101 - mse: 1.5737 - val_loss: 2.9383e-04 - val_mse: 0.0435\n",
      "Epoch 864/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0099 - mse: 1.5776 - val_loss: 2.9726e-04 - val_mse: 0.0441\n",
      "Epoch 865/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0089 - mse: 1.4897 - val_loss: 2.9395e-04 - val_mse: 0.0436\n",
      "Epoch 866/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0089 - mse: 1.4405 - val_loss: 2.8131e-04 - val_mse: 0.0418\n",
      "Epoch 867/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0094 - mse: 1.4808 - val_loss: 2.9050e-04 - val_mse: 0.0431\n",
      "Epoch 868/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0102 - mse: 1.6083 - val_loss: 2.8174e-04 - val_mse: 0.0418\n",
      "Epoch 869/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0094 - mse: 1.5209 - val_loss: 2.7447e-04 - val_mse: 0.0407\n",
      "Epoch 870/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0102 - mse: 1.6125 - val_loss: 2.8349e-04 - val_mse: 0.0425\n",
      "Epoch 871/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0099 - mse: 1.5649 - val_loss: 2.7519e-04 - val_mse: 0.0410\n",
      "Epoch 872/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0093 - mse: 1.5004 - val_loss: 2.7738e-04 - val_mse: 0.0415\n",
      "Epoch 873/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0095 - mse: 1.5315 - val_loss: 2.9181e-04 - val_mse: 0.0442\n",
      "Epoch 874/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0096 - mse: 1.4878 - val_loss: 2.8753e-04 - val_mse: 0.0435\n",
      "Epoch 875/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0088 - mse: 1.4103 - val_loss: 2.8309e-04 - val_mse: 0.0428\n",
      "Epoch 876/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0102 - mse: 1.5932 - val_loss: 2.6881e-04 - val_mse: 0.0401\n",
      "Epoch 877/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0093 - mse: 1.4906 - val_loss: 2.7006e-04 - val_mse: 0.0403\n",
      "Epoch 878/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0100 - mse: 1.5967 - val_loss: 2.7626e-04 - val_mse: 0.0413\n",
      "Epoch 879/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0098 - mse: 1.5774 - val_loss: 2.6886e-04 - val_mse: 0.0403\n",
      "Epoch 880/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0093 - mse: 1.4763 - val_loss: 2.7738e-04 - val_mse: 0.0420\n",
      "Epoch 881/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0092 - mse: 1.4401 - val_loss: 2.8120e-04 - val_mse: 0.0427\n",
      "Epoch 882/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0094 - mse: 1.5070 - val_loss: 2.8110e-04 - val_mse: 0.0423\n",
      "Epoch 883/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0096 - mse: 1.5389 - val_loss: 2.9066e-04 - val_mse: 0.0439\n",
      "Epoch 884/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0097 - mse: 1.5568 - val_loss: 2.9022e-04 - val_mse: 0.0439\n",
      "Epoch 885/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0092 - mse: 1.4912 - val_loss: 2.8084e-04 - val_mse: 0.0424\n",
      "Epoch 886/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0098 - mse: 1.5167 - val_loss: 2.7373e-04 - val_mse: 0.0415\n",
      "Epoch 887/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0099 - mse: 1.5647 - val_loss: 2.7590e-04 - val_mse: 0.0417\n",
      "Epoch 888/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0101 - mse: 1.5629 - val_loss: 2.9202e-04 - val_mse: 0.0443\n",
      "Epoch 889/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0082 - mse: 1.3274 - val_loss: 2.9260e-04 - val_mse: 0.0445\n",
      "Epoch 890/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0084 - mse: 1.3842 - val_loss: 2.8179e-04 - val_mse: 0.0431\n",
      "Epoch 891/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0097 - mse: 1.5242 - val_loss: 2.8820e-04 - val_mse: 0.0441\n",
      "Epoch 892/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0088 - mse: 1.4079 - val_loss: 2.9872e-04 - val_mse: 0.0458\n",
      "Epoch 893/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0091 - mse: 1.4998 - val_loss: 2.9115e-04 - val_mse: 0.0448\n",
      "Epoch 894/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0087 - mse: 1.3863 - val_loss: 2.8560e-04 - val_mse: 0.0437\n",
      "Epoch 895/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0090 - mse: 1.4810 - val_loss: 2.7633e-04 - val_mse: 0.0421\n",
      "Epoch 896/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0089 - mse: 1.4271 - val_loss: 2.6869e-04 - val_mse: 0.0411\n",
      "Epoch 897/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0093 - mse: 1.4746 - val_loss: 2.8001e-04 - val_mse: 0.0434\n",
      "Epoch 898/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0085 - mse: 1.3651 - val_loss: 2.7882e-04 - val_mse: 0.0432\n",
      "Epoch 899/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0091 - mse: 1.4514 - val_loss: 2.6027e-04 - val_mse: 0.0399\n",
      "Epoch 900/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0094 - mse: 1.4904 - val_loss: 2.9282e-04 - val_mse: 0.0449\n",
      "Epoch 901/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0090 - mse: 1.4752 - val_loss: 2.6302e-04 - val_mse: 0.0402\n",
      "Epoch 902/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0092 - mse: 1.4598 - val_loss: 2.6425e-04 - val_mse: 0.0408\n",
      "Epoch 903/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0083 - mse: 1.3307 - val_loss: 2.7092e-04 - val_mse: 0.0420\n",
      "Epoch 904/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0094 - mse: 1.4678 - val_loss: 2.6123e-04 - val_mse: 0.0400\n",
      "Epoch 905/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0092 - mse: 1.4845 - val_loss: 2.9494e-04 - val_mse: 0.0455\n",
      "Epoch 906/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0088 - mse: 1.4453 - val_loss: 2.5696e-04 - val_mse: 0.0396\n",
      "Epoch 907/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0088 - mse: 1.4315 - val_loss: 2.6243e-04 - val_mse: 0.0406\n",
      "Epoch 908/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0089 - mse: 1.4084 - val_loss: 2.6544e-04 - val_mse: 0.0412\n",
      "Epoch 909/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0092 - mse: 1.4487 - val_loss: 2.7384e-04 - val_mse: 0.0424\n",
      "Epoch 910/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0086 - mse: 1.3849 - val_loss: 2.9233e-04 - val_mse: 0.0455\n",
      "Epoch 911/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0087 - mse: 1.4263 - val_loss: 2.6067e-04 - val_mse: 0.0404\n",
      "Epoch 912/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0099 - mse: 1.5675 - val_loss: 2.5858e-04 - val_mse: 0.0401\n",
      "Epoch 913/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0090 - mse: 1.4416 - val_loss: 2.7550e-04 - val_mse: 0.0426\n",
      "Epoch 914/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0088 - mse: 1.4257 - val_loss: 2.8460e-04 - val_mse: 0.0441\n",
      "Epoch 915/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0091 - mse: 1.4838 - val_loss: 2.7497e-04 - val_mse: 0.0426\n",
      "Epoch 916/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0091 - mse: 1.4690 - val_loss: 2.7241e-04 - val_mse: 0.0423\n",
      "Epoch 917/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0096 - mse: 1.4902 - val_loss: 2.6608e-04 - val_mse: 0.0416\n",
      "Epoch 918/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0085 - mse: 1.3567 - val_loss: 2.6952e-04 - val_mse: 0.0423\n",
      "Epoch 919/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0084 - mse: 1.3641 - val_loss: 2.7694e-04 - val_mse: 0.0437\n",
      "Epoch 920/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0085 - mse: 1.3724 - val_loss: 2.7389e-04 - val_mse: 0.0432\n",
      "Epoch 921/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0087 - mse: 1.3976 - val_loss: 2.6064e-04 - val_mse: 0.0409\n",
      "Epoch 922/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0075 - mse: 1.2263 - val_loss: 2.9564e-04 - val_mse: 0.0471\n",
      "Epoch 923/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0093 - mse: 1.4495 - val_loss: 2.6519e-04 - val_mse: 0.0418\n",
      "Epoch 924/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0093 - mse: 1.4760 - val_loss: 2.7932e-04 - val_mse: 0.0440\n",
      "Epoch 925/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0091 - mse: 1.4687 - val_loss: 2.7503e-04 - val_mse: 0.0434\n",
      "Epoch 926/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0081 - mse: 1.3048 - val_loss: 2.8964e-04 - val_mse: 0.0458\n",
      "Epoch 927/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0086 - mse: 1.4151 - val_loss: 2.6551e-04 - val_mse: 0.0418\n",
      "Epoch 928/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0087 - mse: 1.4038 - val_loss: 2.6093e-04 - val_mse: 0.0413\n",
      "Epoch 929/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0080 - mse: 1.2608 - val_loss: 2.5782e-04 - val_mse: 0.0407\n",
      "Epoch 930/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0080 - mse: 1.2976 - val_loss: 2.6671e-04 - val_mse: 0.0424\n",
      "Epoch 931/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0084 - mse: 1.3282 - val_loss: 2.5910e-04 - val_mse: 0.0411\n",
      "Epoch 932/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0081 - mse: 1.3015 - val_loss: 2.5646e-04 - val_mse: 0.0405\n",
      "Epoch 933/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0084 - mse: 1.3457 - val_loss: 2.7165e-04 - val_mse: 0.0429\n",
      "Epoch 934/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0085 - mse: 1.4077 - val_loss: 2.4536e-04 - val_mse: 0.0385\n",
      "Epoch 935/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0090 - mse: 1.4013 - val_loss: 2.4791e-04 - val_mse: 0.0393\n",
      "Epoch 936/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0082 - mse: 1.3005 - val_loss: 2.3882e-04 - val_mse: 0.0375\n",
      "Epoch 937/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0085 - mse: 1.3642 - val_loss: 2.4265e-04 - val_mse: 0.0381\n",
      "Epoch 938/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0086 - mse: 1.4078 - val_loss: 2.4614e-04 - val_mse: 0.0387\n",
      "Epoch 939/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0089 - mse: 1.4265 - val_loss: 2.4819e-04 - val_mse: 0.0395\n",
      "Epoch 940/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0080 - mse: 1.2788 - val_loss: 3.3280e-04 - val_mse: 0.0541\n",
      "Epoch 941/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0091 - mse: 1.4085 - val_loss: 2.6710e-04 - val_mse: 0.0429\n",
      "Epoch 942/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0089 - mse: 1.3846 - val_loss: 2.4255e-04 - val_mse: 0.0384\n",
      "Epoch 943/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0091 - mse: 1.4672 - val_loss: 2.5367e-04 - val_mse: 0.0402\n",
      "Epoch 944/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0080 - mse: 1.3095 - val_loss: 2.4512e-04 - val_mse: 0.0391\n",
      "Epoch 945/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0075 - mse: 1.2206 - val_loss: 3.0163e-04 - val_mse: 0.0490\n",
      "Epoch 946/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0078 - mse: 1.2575 - val_loss: 2.4807e-04 - val_mse: 0.0397\n",
      "Epoch 947/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0077 - mse: 1.2572 - val_loss: 2.5673e-04 - val_mse: 0.0411\n",
      "Epoch 948/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0087 - mse: 1.4043 - val_loss: 2.4401e-04 - val_mse: 0.0390\n",
      "Epoch 949/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0079 - mse: 1.2833 - val_loss: 2.3776e-04 - val_mse: 0.0379\n",
      "Epoch 950/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0078 - mse: 1.2374 - val_loss: 2.6075e-04 - val_mse: 0.0421\n",
      "Epoch 951/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0088 - mse: 1.3712 - val_loss: 2.3932e-04 - val_mse: 0.0382\n",
      "Epoch 952/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0088 - mse: 1.4001 - val_loss: 2.4999e-04 - val_mse: 0.0399\n",
      "Epoch 953/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0078 - mse: 1.2737 - val_loss: 2.4574e-04 - val_mse: 0.0392\n",
      "Epoch 954/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0082 - mse: 1.3092 - val_loss: 2.3892e-04 - val_mse: 0.0384\n",
      "Epoch 955/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0075 - mse: 1.2139 - val_loss: 2.3464e-04 - val_mse: 0.0376\n",
      "Epoch 956/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0081 - mse: 1.2844 - val_loss: 2.3192e-04 - val_mse: 0.0372\n",
      "Epoch 957/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0083 - mse: 1.3334 - val_loss: 2.3011e-04 - val_mse: 0.0369\n",
      "Epoch 958/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0081 - mse: 1.2955 - val_loss: 2.3026e-04 - val_mse: 0.0370\n",
      "Epoch 959/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0070 - mse: 1.1456 - val_loss: 2.3145e-04 - val_mse: 0.0372\n",
      "Epoch 960/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0082 - mse: 1.3124 - val_loss: 2.3546e-04 - val_mse: 0.0380\n",
      "Epoch 961/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0081 - mse: 1.2878 - val_loss: 2.3143e-04 - val_mse: 0.0372\n",
      "Epoch 962/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0083 - mse: 1.3328 - val_loss: 2.3127e-04 - val_mse: 0.0372\n",
      "Epoch 963/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0081 - mse: 1.2863 - val_loss: 2.3343e-04 - val_mse: 0.0377\n",
      "Epoch 964/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0081 - mse: 1.2958 - val_loss: 2.3259e-04 - val_mse: 0.0375\n",
      "Epoch 965/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0080 - mse: 1.2910 - val_loss: 2.3376e-04 - val_mse: 0.0379\n",
      "Epoch 966/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0080 - mse: 1.2592 - val_loss: 2.2981e-04 - val_mse: 0.0370\n",
      "Epoch 967/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0074 - mse: 1.2129 - val_loss: 2.2814e-04 - val_mse: 0.0368\n",
      "Epoch 968/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0079 - mse: 1.2857 - val_loss: 2.2805e-04 - val_mse: 0.0367\n",
      "Epoch 969/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0078 - mse: 1.2549 - val_loss: 2.3074e-04 - val_mse: 0.0372\n",
      "Epoch 970/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0075 - mse: 1.2058 - val_loss: 2.2924e-04 - val_mse: 0.0372\n",
      "Epoch 971/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0074 - mse: 1.1886 - val_loss: 2.4383e-04 - val_mse: 0.0398\n",
      "Epoch 972/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0071 - mse: 1.1483 - val_loss: 2.4182e-04 - val_mse: 0.0395\n",
      "Epoch 973/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0076 - mse: 1.2015 - val_loss: 2.2639e-04 - val_mse: 0.0366\n",
      "Epoch 974/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0080 - mse: 1.2916 - val_loss: 2.4430e-04 - val_mse: 0.0395\n",
      "Epoch 975/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0080 - mse: 1.2997 - val_loss: 2.3789e-04 - val_mse: 0.0385\n",
      "Epoch 976/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0073 - mse: 1.1850 - val_loss: 2.3641e-04 - val_mse: 0.0386\n",
      "Epoch 977/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0076 - mse: 1.2359 - val_loss: 2.3093e-04 - val_mse: 0.0376\n",
      "Epoch 978/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0074 - mse: 1.1994 - val_loss: 2.6699e-04 - val_mse: 0.0441\n",
      "Epoch 979/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0074 - mse: 1.1659 - val_loss: 2.2874e-04 - val_mse: 0.0372\n",
      "Epoch 980/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0077 - mse: 1.2383 - val_loss: 2.4935e-04 - val_mse: 0.0404\n",
      "Epoch 981/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0077 - mse: 1.2599 - val_loss: 2.2573e-04 - val_mse: 0.0367\n",
      "Epoch 982/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0069 - mse: 1.1188 - val_loss: 2.4224e-04 - val_mse: 0.0399\n",
      "Epoch 983/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0074 - mse: 1.1972 - val_loss: 2.2450e-04 - val_mse: 0.0366\n",
      "Epoch 984/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0078 - mse: 1.2393 - val_loss: 2.5799e-04 - val_mse: 0.0419\n",
      "Epoch 985/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0081 - mse: 1.3318 - val_loss: 2.9478e-04 - val_mse: 0.0481\n",
      "Epoch 986/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0070 - mse: 1.1451 - val_loss: 2.2561e-04 - val_mse: 0.0368\n",
      "Epoch 987/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0069 - mse: 1.1169 - val_loss: 2.6107e-04 - val_mse: 0.0432\n",
      "Epoch 988/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0078 - mse: 1.2333 - val_loss: 2.3835e-04 - val_mse: 0.0393\n",
      "Epoch 989/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0073 - mse: 1.1750 - val_loss: 2.2445e-04 - val_mse: 0.0367\n",
      "Epoch 990/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0070 - mse: 1.1422 - val_loss: 2.2992e-04 - val_mse: 0.0378\n",
      "Epoch 991/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0074 - mse: 1.1831 - val_loss: 2.1696e-04 - val_mse: 0.0355\n",
      "Epoch 992/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0080 - mse: 1.2609 - val_loss: 2.2696e-04 - val_mse: 0.0371\n",
      "Epoch 993/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0069 - mse: 1.1190 - val_loss: 2.2584e-04 - val_mse: 0.0369\n",
      "Epoch 994/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0070 - mse: 1.1538 - val_loss: 2.1618e-04 - val_mse: 0.0354\n",
      "Epoch 995/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0072 - mse: 1.1589 - val_loss: 2.4674e-04 - val_mse: 0.0409\n",
      "Epoch 996/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0071 - mse: 1.1464 - val_loss: 2.1393e-04 - val_mse: 0.0351\n",
      "Epoch 997/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0068 - mse: 1.1313 - val_loss: 2.1413e-04 - val_mse: 0.0351\n",
      "Epoch 998/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0073 - mse: 1.1812 - val_loss: 2.1396e-04 - val_mse: 0.0351\n",
      "Epoch 999/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0077 - mse: 1.2440 - val_loss: 2.1669e-04 - val_mse: 0.0354\n",
      "Epoch 1000/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0073 - mse: 1.1747 - val_loss: 2.2802e-04 - val_mse: 0.0377\n",
      "Epoch 1001/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0073 - mse: 1.1644 - val_loss: 2.1728e-04 - val_mse: 0.0357\n",
      "Epoch 1002/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0072 - mse: 1.1722 - val_loss: 2.7691e-04 - val_mse: 0.0453\n",
      "Epoch 1003/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0076 - mse: 1.2449 - val_loss: 2.3014e-04 - val_mse: 0.0376\n",
      "Epoch 1004/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0072 - mse: 1.1614 - val_loss: 2.3673e-04 - val_mse: 0.0393\n",
      "Epoch 1005/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0072 - mse: 1.1365 - val_loss: 2.4101e-04 - val_mse: 0.0401\n",
      "Epoch 1006/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0069 - mse: 1.1014 - val_loss: 2.1776e-04 - val_mse: 0.0359\n",
      "Epoch 1007/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0074 - mse: 1.1719 - val_loss: 2.2253e-04 - val_mse: 0.0364\n",
      "Epoch 1008/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0078 - mse: 1.2608 - val_loss: 2.6658e-04 - val_mse: 0.0437\n",
      "Epoch 1009/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0074 - mse: 1.2168 - val_loss: 2.4522e-04 - val_mse: 0.0401\n",
      "Epoch 1010/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0075 - mse: 1.2046 - val_loss: 2.1405e-04 - val_mse: 0.0353\n",
      "Epoch 1011/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0065 - mse: 1.0630 - val_loss: 2.4330e-04 - val_mse: 0.0407\n",
      "Epoch 1012/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0068 - mse: 1.1013 - val_loss: 2.4890e-04 - val_mse: 0.0416\n",
      "Epoch 1013/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0077 - mse: 1.2119 - val_loss: 2.2739e-04 - val_mse: 0.0379\n",
      "Epoch 1014/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0073 - mse: 1.1720 - val_loss: 2.2117e-04 - val_mse: 0.0363\n",
      "Epoch 1015/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0069 - mse: 1.1083 - val_loss: 2.1357e-04 - val_mse: 0.0354\n",
      "Epoch 1016/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0067 - mse: 1.0984 - val_loss: 2.1732e-04 - val_mse: 0.0361\n",
      "Epoch 1017/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0070 - mse: 1.1452 - val_loss: 2.3076e-04 - val_mse: 0.0386\n",
      "Epoch 1018/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0068 - mse: 1.0874 - val_loss: 2.2111e-04 - val_mse: 0.0368\n",
      "Epoch 1019/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0065 - mse: 1.0474 - val_loss: 2.4023e-04 - val_mse: 0.0402\n",
      "Epoch 1020/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0070 - mse: 1.1035 - val_loss: 2.1275e-04 - val_mse: 0.0352\n",
      "Epoch 1021/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0066 - mse: 1.0935 - val_loss: 2.1255e-04 - val_mse: 0.0353\n",
      "Epoch 1022/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0069 - mse: 1.0863 - val_loss: 2.3362e-04 - val_mse: 0.0391\n",
      "Epoch 1023/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0062 - mse: 0.9957 - val_loss: 2.1149e-04 - val_mse: 0.0351\n",
      "Epoch 1024/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0076 - mse: 1.2077 - val_loss: 2.9809e-04 - val_mse: 0.0495\n",
      "Epoch 1025/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0073 - mse: 1.2086 - val_loss: 2.2251e-04 - val_mse: 0.0368\n",
      "Epoch 1026/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0070 - mse: 1.1299 - val_loss: 2.5633e-04 - val_mse: 0.0431\n",
      "Epoch 1027/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0068 - mse: 1.0840 - val_loss: 2.1200e-04 - val_mse: 0.0353\n",
      "Epoch 1028/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0065 - mse: 1.0380 - val_loss: 2.2555e-04 - val_mse: 0.0373\n",
      "Epoch 1029/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0063 - mse: 1.0448 - val_loss: 2.1529e-04 - val_mse: 0.0359\n",
      "Epoch 1030/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0068 - mse: 1.0846 - val_loss: 2.1505e-04 - val_mse: 0.0359\n",
      "Epoch 1031/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0066 - mse: 1.0828 - val_loss: 2.2835e-04 - val_mse: 0.0383\n",
      "Epoch 1032/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0067 - mse: 1.0535 - val_loss: 2.3429e-04 - val_mse: 0.0394\n",
      "Epoch 1033/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0070 - mse: 1.1150 - val_loss: 2.1224e-04 - val_mse: 0.0354\n",
      "Epoch 1034/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0068 - mse: 1.1030 - val_loss: 2.2131e-04 - val_mse: 0.0371\n",
      "Epoch 1035/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0061 - mse: 0.9746 - val_loss: 2.1977e-04 - val_mse: 0.0369\n",
      "Epoch 1036/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0062 - mse: 1.0003 - val_loss: 2.0696e-04 - val_mse: 0.0345\n",
      "Epoch 1037/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0066 - mse: 1.0601 - val_loss: 2.0903e-04 - val_mse: 0.0350\n",
      "Epoch 1038/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0066 - mse: 1.0617 - val_loss: 2.1849e-04 - val_mse: 0.0367\n",
      "Epoch 1039/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0065 - mse: 1.0489 - val_loss: 2.0250e-04 - val_mse: 0.0338\n",
      "Epoch 1040/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0064 - mse: 1.0450 - val_loss: 2.0771e-04 - val_mse: 0.0349\n",
      "Epoch 1041/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0068 - mse: 1.0956 - val_loss: 2.1415e-04 - val_mse: 0.0360\n",
      "Epoch 1042/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0065 - mse: 1.0414 - val_loss: 1.9876e-04 - val_mse: 0.0332\n",
      "Epoch 1043/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0063 - mse: 1.0140 - val_loss: 1.9813e-04 - val_mse: 0.0332\n",
      "Epoch 1044/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0065 - mse: 1.0678 - val_loss: 1.9985e-04 - val_mse: 0.0335\n",
      "Epoch 1045/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0063 - mse: 1.0262 - val_loss: 2.3153e-04 - val_mse: 0.0391\n",
      "Epoch 1046/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0066 - mse: 1.0474 - val_loss: 1.9946e-04 - val_mse: 0.0333\n",
      "Epoch 1047/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0066 - mse: 1.0833 - val_loss: 1.9955e-04 - val_mse: 0.0333\n",
      "Epoch 1048/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0066 - mse: 1.0766 - val_loss: 1.9545e-04 - val_mse: 0.0327\n",
      "Epoch 1049/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0065 - mse: 1.0557 - val_loss: 1.9928e-04 - val_mse: 0.0335\n",
      "Epoch 1050/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0062 - mse: 1.0072 - val_loss: 2.7009e-04 - val_mse: 0.0457\n",
      "Epoch 1051/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0060 - mse: 0.9756 - val_loss: 2.0428e-04 - val_mse: 0.0344\n",
      "Epoch 1052/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0064 - mse: 1.0266 - val_loss: 2.0112e-04 - val_mse: 0.0335\n",
      "Epoch 1053/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0059 - mse: 0.9620 - val_loss: 1.9695e-04 - val_mse: 0.0329\n",
      "Epoch 1054/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0057 - mse: 0.9410 - val_loss: 2.1992e-04 - val_mse: 0.0373\n",
      "Epoch 1055/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0065 - mse: 1.0401 - val_loss: 2.4239e-04 - val_mse: 0.0412\n",
      "Epoch 1056/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0061 - mse: 0.9830 - val_loss: 2.1527e-04 - val_mse: 0.0365\n",
      "Epoch 1057/2000\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 0.0064 - mse: 1.0203 - val_loss: 1.9310e-04 - val_mse: 0.0326\n",
      "Epoch 1058/2000\n",
      "1168/1168 [==============================] - 0s 52us/step - loss: 0.0066 - mse: 1.0844 - val_loss: 2.0429e-04 - val_mse: 0.0344\n",
      "Epoch 1059/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0063 - mse: 1.0275 - val_loss: 1.9947e-04 - val_mse: 0.0337\n",
      "Epoch 1060/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0066 - mse: 1.0605 - val_loss: 2.0495e-04 - val_mse: 0.0347\n",
      "Epoch 1061/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0060 - mse: 0.9914 - val_loss: 2.2536e-04 - val_mse: 0.0381\n",
      "Epoch 1062/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0061 - mse: 1.0017 - val_loss: 2.1342e-04 - val_mse: 0.0363\n",
      "Epoch 1063/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0063 - mse: 1.0054 - val_loss: 2.0074e-04 - val_mse: 0.0340\n",
      "Epoch 1064/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0066 - mse: 1.0803 - val_loss: 2.1446e-04 - val_mse: 0.0360\n",
      "Epoch 1065/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0063 - mse: 1.0325 - val_loss: 1.9782e-04 - val_mse: 0.0333\n",
      "Epoch 1066/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0064 - mse: 1.0276 - val_loss: 1.9577e-04 - val_mse: 0.0331\n",
      "Epoch 1067/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0062 - mse: 0.9991 - val_loss: 1.9479e-04 - val_mse: 0.0328\n",
      "Epoch 1068/2000\n",
      "1168/1168 [==============================] - 0s 46us/step - loss: 0.0060 - mse: 0.9702 - val_loss: 1.9730e-04 - val_mse: 0.0334\n",
      "Epoch 1069/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0055 - mse: 0.9090 - val_loss: 1.9434e-04 - val_mse: 0.0329\n",
      "Epoch 1070/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0060 - mse: 0.9639 - val_loss: 1.9595e-04 - val_mse: 0.0332\n",
      "Epoch 1071/2000\n",
      "1168/1168 [==============================] - 0s 46us/step - loss: 0.0057 - mse: 0.9186 - val_loss: 2.2692e-04 - val_mse: 0.0380\n",
      "Epoch 1072/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0060 - mse: 1.0069 - val_loss: 1.9410e-04 - val_mse: 0.0327\n",
      "Epoch 1073/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0059 - mse: 0.9498 - val_loss: 1.9831e-04 - val_mse: 0.0337\n",
      "Epoch 1074/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0058 - mse: 0.9388 - val_loss: 1.9270e-04 - val_mse: 0.0325\n",
      "Epoch 1075/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0056 - mse: 0.9302 - val_loss: 1.9663e-04 - val_mse: 0.0331\n",
      "Epoch 1076/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0063 - mse: 1.0193 - val_loss: 2.2837e-04 - val_mse: 0.0390\n",
      "Epoch 1077/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0061 - mse: 0.9688 - val_loss: 2.2190e-04 - val_mse: 0.0379\n",
      "Epoch 1078/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0062 - mse: 1.0054 - val_loss: 1.9090e-04 - val_mse: 0.0323\n",
      "Epoch 1079/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0063 - mse: 1.0169 - val_loss: 1.9359e-04 - val_mse: 0.0329\n",
      "Epoch 1080/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0062 - mse: 1.0133 - val_loss: 1.9217e-04 - val_mse: 0.0325\n",
      "Epoch 1081/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0061 - mse: 0.9895 - val_loss: 1.9257e-04 - val_mse: 0.0326\n",
      "Epoch 1082/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0054 - mse: 0.8855 - val_loss: 2.0084e-04 - val_mse: 0.0338\n",
      "Epoch 1083/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0060 - mse: 0.9737 - val_loss: 1.8895e-04 - val_mse: 0.0320\n",
      "Epoch 1084/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0059 - mse: 0.9574 - val_loss: 2.1464e-04 - val_mse: 0.0367\n",
      "Epoch 1085/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0058 - mse: 0.9350 - val_loss: 2.1728e-04 - val_mse: 0.0372\n",
      "Epoch 1086/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0061 - mse: 0.9816 - val_loss: 2.1520e-04 - val_mse: 0.0369\n",
      "Epoch 1087/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0059 - mse: 0.9448 - val_loss: 1.9146e-04 - val_mse: 0.0326\n",
      "Epoch 1088/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0055 - mse: 0.9069 - val_loss: 1.8706e-04 - val_mse: 0.0317\n",
      "Epoch 1089/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0053 - mse: 0.8683 - val_loss: 1.9486e-04 - val_mse: 0.0333\n",
      "Epoch 1090/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0058 - mse: 0.9332 - val_loss: 1.8621e-04 - val_mse: 0.0317\n",
      "Epoch 1091/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0056 - mse: 0.8948 - val_loss: 1.8861e-04 - val_mse: 0.0321\n",
      "Epoch 1092/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0056 - mse: 0.9134 - val_loss: 1.9632e-04 - val_mse: 0.0335\n",
      "Epoch 1093/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0060 - mse: 0.9722 - val_loss: 1.9123e-04 - val_mse: 0.0326\n",
      "Epoch 1094/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0059 - mse: 0.9535 - val_loss: 1.9516e-04 - val_mse: 0.0330\n",
      "Epoch 1095/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0058 - mse: 0.9401 - val_loss: 2.0818e-04 - val_mse: 0.0356\n",
      "Epoch 1096/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0056 - mse: 0.8882 - val_loss: 1.9683e-04 - val_mse: 0.0336\n",
      "Epoch 1097/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0054 - mse: 0.8872 - val_loss: 1.9229e-04 - val_mse: 0.0328\n",
      "Epoch 1098/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0057 - mse: 0.9199 - val_loss: 1.9268e-04 - val_mse: 0.0329\n",
      "Epoch 1099/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0056 - mse: 0.9116 - val_loss: 1.9700e-04 - val_mse: 0.0335\n",
      "Epoch 1100/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0059 - mse: 0.9565 - val_loss: 1.9155e-04 - val_mse: 0.0326\n",
      "Epoch 1101/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0057 - mse: 0.9296 - val_loss: 1.8696e-04 - val_mse: 0.0320\n",
      "Epoch 1102/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0057 - mse: 0.9260 - val_loss: 1.8450e-04 - val_mse: 0.0314\n",
      "Epoch 1103/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0054 - mse: 0.8919 - val_loss: 1.8782e-04 - val_mse: 0.0321\n",
      "Epoch 1104/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0052 - mse: 0.8511 - val_loss: 1.9747e-04 - val_mse: 0.0338\n",
      "Epoch 1105/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0058 - mse: 0.9377 - val_loss: 2.1870e-04 - val_mse: 0.0375\n",
      "Epoch 1106/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0056 - mse: 0.9088 - val_loss: 2.0167e-04 - val_mse: 0.0346\n",
      "Epoch 1107/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0052 - mse: 0.8464 - val_loss: 2.3001e-04 - val_mse: 0.0395\n",
      "Epoch 1108/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0053 - mse: 0.8680 - val_loss: 1.8768e-04 - val_mse: 0.0322\n",
      "Epoch 1109/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0056 - mse: 0.9007 - val_loss: 2.1069e-04 - val_mse: 0.0358\n",
      "Epoch 1110/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0053 - mse: 0.8748 - val_loss: 1.8349e-04 - val_mse: 0.0313\n",
      "Epoch 1111/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0055 - mse: 0.8839 - val_loss: 1.9967e-04 - val_mse: 0.0343\n",
      "Epoch 1112/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0057 - mse: 0.9271 - val_loss: 1.8333e-04 - val_mse: 0.0313\n",
      "Epoch 1113/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0054 - mse: 0.8876 - val_loss: 1.8225e-04 - val_mse: 0.0312\n",
      "Epoch 1114/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0057 - mse: 0.9227 - val_loss: 1.8886e-04 - val_mse: 0.0324\n",
      "Epoch 1115/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0053 - mse: 0.8558 - val_loss: 1.8022e-04 - val_mse: 0.0307\n",
      "Epoch 1116/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0052 - mse: 0.8551 - val_loss: 1.8947e-04 - val_mse: 0.0325\n",
      "Epoch 1117/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0057 - mse: 0.9049 - val_loss: 1.8099e-04 - val_mse: 0.0309\n",
      "Epoch 1118/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0053 - mse: 0.8570 - val_loss: 1.9225e-04 - val_mse: 0.0326\n",
      "Epoch 1119/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0053 - mse: 0.8729 - val_loss: 1.8922e-04 - val_mse: 0.0325\n",
      "Epoch 1120/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0056 - mse: 0.8984 - val_loss: 1.8287e-04 - val_mse: 0.0312\n",
      "Epoch 1121/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0052 - mse: 0.8456 - val_loss: 1.8598e-04 - val_mse: 0.0317\n",
      "Epoch 1122/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0052 - mse: 0.8549 - val_loss: 2.1515e-04 - val_mse: 0.0370\n",
      "Epoch 1123/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0052 - mse: 0.8362 - val_loss: 1.9789e-04 - val_mse: 0.0340\n",
      "Epoch 1124/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0050 - mse: 0.8134 - val_loss: 1.9045e-04 - val_mse: 0.0324\n",
      "Epoch 1125/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0049 - mse: 0.8105 - val_loss: 1.8809e-04 - val_mse: 0.0322\n",
      "Epoch 1126/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0056 - mse: 0.9040 - val_loss: 1.8724e-04 - val_mse: 0.0321\n",
      "Epoch 1127/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0055 - mse: 0.8868 - val_loss: 1.9568e-04 - val_mse: 0.0335\n",
      "Epoch 1128/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0051 - mse: 0.8374 - val_loss: 1.9151e-04 - val_mse: 0.0329\n",
      "Epoch 1129/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0049 - mse: 0.7959 - val_loss: 2.0088e-04 - val_mse: 0.0346\n",
      "Epoch 1130/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0052 - mse: 0.8513 - val_loss: 1.9271e-04 - val_mse: 0.0331\n",
      "Epoch 1131/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0054 - mse: 0.8666 - val_loss: 1.8881e-04 - val_mse: 0.0324\n",
      "Epoch 1132/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0051 - mse: 0.8276 - val_loss: 1.8444e-04 - val_mse: 0.0315\n",
      "Epoch 1133/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0048 - mse: 0.7981 - val_loss: 1.9135e-04 - val_mse: 0.0329\n",
      "Epoch 1134/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0051 - mse: 0.8252 - val_loss: 2.1829e-04 - val_mse: 0.0377\n",
      "Epoch 1135/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0052 - mse: 0.8410 - val_loss: 1.8731e-04 - val_mse: 0.0321\n",
      "Epoch 1136/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0054 - mse: 0.8734 - val_loss: 1.8423e-04 - val_mse: 0.0314\n",
      "Epoch 1137/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0049 - mse: 0.7961 - val_loss: 2.0963e-04 - val_mse: 0.0361\n",
      "Epoch 1138/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0051 - mse: 0.8127 - val_loss: 2.8490e-04 - val_mse: 0.0491\n",
      "Epoch 1139/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0049 - mse: 0.7931 - val_loss: 1.8414e-04 - val_mse: 0.0314\n",
      "Epoch 1140/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0050 - mse: 0.8358 - val_loss: 1.8416e-04 - val_mse: 0.0313\n",
      "Epoch 1141/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0048 - mse: 0.7809 - val_loss: 2.0469e-04 - val_mse: 0.0353\n",
      "Epoch 1142/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0049 - mse: 0.7911 - val_loss: 1.7905e-04 - val_mse: 0.0306\n",
      "Epoch 1143/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0048 - mse: 0.7893 - val_loss: 1.8122e-04 - val_mse: 0.0308\n",
      "Epoch 1144/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0052 - mse: 0.8492 - val_loss: 1.8482e-04 - val_mse: 0.0318\n",
      "Epoch 1145/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0044 - mse: 0.7241 - val_loss: 2.0216e-04 - val_mse: 0.0348\n",
      "Epoch 1146/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0050 - mse: 0.7996 - val_loss: 1.7486e-04 - val_mse: 0.0300\n",
      "Epoch 1147/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0046 - mse: 0.7512 - val_loss: 1.7957e-04 - val_mse: 0.0307\n",
      "Epoch 1148/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0046 - mse: 0.7518 - val_loss: 1.7639e-04 - val_mse: 0.0301\n",
      "Epoch 1149/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0047 - mse: 0.7638 - val_loss: 1.7684e-04 - val_mse: 0.0302\n",
      "Epoch 1150/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0048 - mse: 0.7848 - val_loss: 1.7738e-04 - val_mse: 0.0303\n",
      "Epoch 1151/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0047 - mse: 0.7662 - val_loss: 2.1286e-04 - val_mse: 0.0367\n",
      "Epoch 1152/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0057 - mse: 0.8945 - val_loss: 1.7449e-04 - val_mse: 0.0299\n",
      "Epoch 1153/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0047 - mse: 0.7892 - val_loss: 1.9225e-04 - val_mse: 0.0329\n",
      "Epoch 1154/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0047 - mse: 0.7712 - val_loss: 2.1446e-04 - val_mse: 0.0369\n",
      "Epoch 1155/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0047 - mse: 0.7582 - val_loss: 1.8455e-04 - val_mse: 0.0318\n",
      "Epoch 1156/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0046 - mse: 0.7503 - val_loss: 1.7597e-04 - val_mse: 0.0303\n",
      "Epoch 1157/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0043 - mse: 0.7097 - val_loss: 1.8523e-04 - val_mse: 0.0319\n",
      "Epoch 1158/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0045 - mse: 0.7290 - val_loss: 1.8099e-04 - val_mse: 0.0311\n",
      "Epoch 1159/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0049 - mse: 0.7943 - val_loss: 1.7447e-04 - val_mse: 0.0300\n",
      "Epoch 1160/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0046 - mse: 0.7631 - val_loss: 1.7109e-04 - val_mse: 0.0293\n",
      "Epoch 1161/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0049 - mse: 0.7957 - val_loss: 1.7293e-04 - val_mse: 0.0295\n",
      "Epoch 1162/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0047 - mse: 0.7742 - val_loss: 1.8053e-04 - val_mse: 0.0311\n",
      "Epoch 1163/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0048 - mse: 0.7665 - val_loss: 2.2449e-04 - val_mse: 0.0388\n",
      "Epoch 1164/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0044 - mse: 0.7165 - val_loss: 1.7479e-04 - val_mse: 0.0298\n",
      "Epoch 1165/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0044 - mse: 0.7385 - val_loss: 1.7296e-04 - val_mse: 0.0296\n",
      "Epoch 1166/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0041 - mse: 0.6632 - val_loss: 1.7845e-04 - val_mse: 0.0307\n",
      "Epoch 1167/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0045 - mse: 0.7302 - val_loss: 1.7609e-04 - val_mse: 0.0303\n",
      "Epoch 1168/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0047 - mse: 0.7659 - val_loss: 1.9000e-04 - val_mse: 0.0327\n",
      "Epoch 1169/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0043 - mse: 0.7061 - val_loss: 1.8082e-04 - val_mse: 0.0311\n",
      "Epoch 1170/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0044 - mse: 0.7231 - val_loss: 1.7713e-04 - val_mse: 0.0304\n",
      "Epoch 1171/2000\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 0.0044 - mse: 0.7367 - val_loss: 1.7737e-04 - val_mse: 0.0304\n",
      "Epoch 1172/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0043 - mse: 0.6976 - val_loss: 1.8734e-04 - val_mse: 0.0323\n",
      "Epoch 1173/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0043 - mse: 0.6993 - val_loss: 1.7952e-04 - val_mse: 0.0309\n",
      "Epoch 1174/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0043 - mse: 0.7068 - val_loss: 1.8414e-04 - val_mse: 0.0317\n",
      "Epoch 1175/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0046 - mse: 0.7459 - val_loss: 1.8389e-04 - val_mse: 0.0316\n",
      "Epoch 1176/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0044 - mse: 0.7151 - val_loss: 2.0653e-04 - val_mse: 0.0356\n",
      "Epoch 1177/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0046 - mse: 0.7549 - val_loss: 1.9400e-04 - val_mse: 0.0334\n",
      "Epoch 1178/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0043 - mse: 0.6973 - val_loss: 1.8334e-04 - val_mse: 0.0315\n",
      "Epoch 1179/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0043 - mse: 0.7056 - val_loss: 2.0583e-04 - val_mse: 0.0356\n",
      "Epoch 1180/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0046 - mse: 0.7234 - val_loss: 2.0973e-04 - val_mse: 0.0363\n",
      "Epoch 1181/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0043 - mse: 0.7002 - val_loss: 1.8300e-04 - val_mse: 0.0312\n",
      "Epoch 1182/2000\n",
      "1168/1168 [==============================] - 0s 47us/step - loss: 0.0041 - mse: 0.6855 - val_loss: 1.7933e-04 - val_mse: 0.0307\n",
      "Epoch 1183/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0043 - mse: 0.7065 - val_loss: 2.2724e-04 - val_mse: 0.0393\n",
      "Epoch 1184/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0043 - mse: 0.7028 - val_loss: 1.8139e-04 - val_mse: 0.0311\n",
      "Epoch 1185/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0041 - mse: 0.6723 - val_loss: 1.8462e-04 - val_mse: 0.0317\n",
      "Epoch 1186/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0045 - mse: 0.7325 - val_loss: 1.8878e-04 - val_mse: 0.0325\n",
      "Epoch 1187/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0042 - mse: 0.6893 - val_loss: 1.9399e-04 - val_mse: 0.0334\n",
      "Epoch 1188/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0041 - mse: 0.6662 - val_loss: 1.8944e-04 - val_mse: 0.0326\n",
      "Epoch 1189/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0041 - mse: 0.6816 - val_loss: 1.8807e-04 - val_mse: 0.0323\n",
      "Epoch 1190/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0045 - mse: 0.7297 - val_loss: 2.0744e-04 - val_mse: 0.0358\n",
      "Epoch 1191/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0040 - mse: 0.6619 - val_loss: 1.8967e-04 - val_mse: 0.0324\n",
      "Epoch 1192/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0043 - mse: 0.7019 - val_loss: 1.8712e-04 - val_mse: 0.0320\n",
      "Epoch 1193/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0044 - mse: 0.7203 - val_loss: 1.9185e-04 - val_mse: 0.0330\n",
      "Epoch 1194/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0040 - mse: 0.6591 - val_loss: 2.0472e-04 - val_mse: 0.0353\n",
      "Epoch 1195/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0041 - mse: 0.6702 - val_loss: 1.8477e-04 - val_mse: 0.0317\n",
      "Epoch 1196/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0042 - mse: 0.6921 - val_loss: 1.8519e-04 - val_mse: 0.0318\n",
      "Epoch 1197/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0039 - mse: 0.6440 - val_loss: 1.8789e-04 - val_mse: 0.0323\n",
      "Epoch 1198/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0043 - mse: 0.7003 - val_loss: 1.8779e-04 - val_mse: 0.0323\n",
      "Epoch 1199/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0040 - mse: 0.6522 - val_loss: 2.0930e-04 - val_mse: 0.0362\n",
      "Epoch 1200/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0040 - mse: 0.6527 - val_loss: 1.9584e-04 - val_mse: 0.0338\n",
      "Epoch 1201/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0044 - mse: 0.7148 - val_loss: 1.7959e-04 - val_mse: 0.0308\n",
      "Epoch 1202/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0041 - mse: 0.6743 - val_loss: 1.8484e-04 - val_mse: 0.0319\n",
      "Epoch 1203/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0043 - mse: 0.7003 - val_loss: 2.1417e-04 - val_mse: 0.0371\n",
      "Epoch 1204/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0039 - mse: 0.6398 - val_loss: 1.8414e-04 - val_mse: 0.0318\n",
      "Epoch 1205/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0042 - mse: 0.6893 - val_loss: 1.8523e-04 - val_mse: 0.0316\n",
      "Epoch 1206/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0039 - mse: 0.6498 - val_loss: 1.7843e-04 - val_mse: 0.0308\n",
      "Epoch 1207/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0038 - mse: 0.6290 - val_loss: 2.1016e-04 - val_mse: 0.0364\n",
      "Epoch 1208/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0041 - mse: 0.6704 - val_loss: 1.7216e-04 - val_mse: 0.0296\n",
      "Epoch 1209/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0039 - mse: 0.6286 - val_loss: 1.7306e-04 - val_mse: 0.0297\n",
      "Epoch 1210/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0041 - mse: 0.6700 - val_loss: 1.7806e-04 - val_mse: 0.0307\n",
      "Epoch 1211/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0038 - mse: 0.6232 - val_loss: 1.9410e-04 - val_mse: 0.0336\n",
      "Epoch 1212/2000\n",
      "1168/1168 [==============================] - 0s 49us/step - loss: 0.0038 - mse: 0.6287 - val_loss: 1.6972e-04 - val_mse: 0.0292\n",
      "Epoch 1213/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0039 - mse: 0.6380 - val_loss: 1.6880e-04 - val_mse: 0.0290\n",
      "Epoch 1214/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0040 - mse: 0.6563 - val_loss: 1.8902e-04 - val_mse: 0.0327\n",
      "Epoch 1215/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0041 - mse: 0.6652 - val_loss: 1.6960e-04 - val_mse: 0.0290\n",
      "Epoch 1216/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0039 - mse: 0.6443 - val_loss: 1.6870e-04 - val_mse: 0.0290\n",
      "Epoch 1217/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0038 - mse: 0.6294 - val_loss: 1.8229e-04 - val_mse: 0.0315\n",
      "Epoch 1218/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0036 - mse: 0.5852 - val_loss: 1.7221e-04 - val_mse: 0.0297\n",
      "Epoch 1219/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0036 - mse: 0.5977 - val_loss: 1.7939e-04 - val_mse: 0.0310\n",
      "Epoch 1220/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0038 - mse: 0.6202 - val_loss: 1.7259e-04 - val_mse: 0.0297\n",
      "Epoch 1221/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0040 - mse: 0.6479 - val_loss: 1.8213e-04 - val_mse: 0.0312\n",
      "Epoch 1222/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0039 - mse: 0.6415 - val_loss: 1.9132e-04 - val_mse: 0.0331\n",
      "Epoch 1223/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0037 - mse: 0.6102 - val_loss: 1.8071e-04 - val_mse: 0.0313\n",
      "Epoch 1224/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.6016 - val_loss: 1.7504e-04 - val_mse: 0.0302\n",
      "Epoch 1225/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0038 - mse: 0.6239 - val_loss: 1.7825e-04 - val_mse: 0.0308\n",
      "Epoch 1226/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0037 - mse: 0.6040 - val_loss: 1.7028e-04 - val_mse: 0.0293\n",
      "Epoch 1227/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0035 - mse: 0.5839 - val_loss: 1.7593e-04 - val_mse: 0.0304\n",
      "Epoch 1228/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0038 - mse: 0.6207 - val_loss: 1.7198e-04 - val_mse: 0.0297\n",
      "Epoch 1229/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0040 - mse: 0.6559 - val_loss: 1.8417e-04 - val_mse: 0.0319\n",
      "Epoch 1230/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0039 - mse: 0.6307 - val_loss: 1.6971e-04 - val_mse: 0.0293\n",
      "Epoch 1231/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0039 - mse: 0.6503 - val_loss: 1.8076e-04 - val_mse: 0.0309\n",
      "Epoch 1232/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0036 - mse: 0.6041 - val_loss: 1.7053e-04 - val_mse: 0.0294\n",
      "Epoch 1233/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0038 - mse: 0.6258 - val_loss: 1.8861e-04 - val_mse: 0.0327\n",
      "Epoch 1234/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0036 - mse: 0.5799 - val_loss: 1.8838e-04 - val_mse: 0.0326\n",
      "Epoch 1235/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0040 - mse: 0.6562 - val_loss: 1.8799e-04 - val_mse: 0.0323\n",
      "Epoch 1236/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.5983 - val_loss: 1.7598e-04 - val_mse: 0.0303\n",
      "Epoch 1237/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.5898 - val_loss: 1.7388e-04 - val_mse: 0.0299\n",
      "Epoch 1238/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0037 - mse: 0.6046 - val_loss: 1.9395e-04 - val_mse: 0.0336\n",
      "Epoch 1239/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.5800 - val_loss: 1.6994e-04 - val_mse: 0.0292\n",
      "Epoch 1240/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.5840 - val_loss: 1.7323e-04 - val_mse: 0.0299\n",
      "Epoch 1241/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0037 - mse: 0.6021 - val_loss: 1.7851e-04 - val_mse: 0.0309\n",
      "Epoch 1242/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0038 - mse: 0.6235 - val_loss: 1.6822e-04 - val_mse: 0.0289\n",
      "Epoch 1243/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0035 - mse: 0.5855 - val_loss: 1.9260e-04 - val_mse: 0.0333\n",
      "Epoch 1244/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0033 - mse: 0.5345 - val_loss: 2.0215e-04 - val_mse: 0.0350\n",
      "Epoch 1245/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0037 - mse: 0.5998 - val_loss: 1.6908e-04 - val_mse: 0.0291\n",
      "Epoch 1246/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0037 - mse: 0.6099 - val_loss: 1.6919e-04 - val_mse: 0.0291\n",
      "Epoch 1247/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0035 - mse: 0.5802 - val_loss: 2.1131e-04 - val_mse: 0.0365\n",
      "Epoch 1248/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0037 - mse: 0.5938 - val_loss: 1.9715e-04 - val_mse: 0.0341\n",
      "Epoch 1249/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0034 - mse: 0.5598 - val_loss: 1.6935e-04 - val_mse: 0.0292\n",
      "Epoch 1250/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0032 - mse: 0.5390 - val_loss: 1.7896e-04 - val_mse: 0.0310\n",
      "Epoch 1251/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0034 - mse: 0.5492 - val_loss: 2.4764e-04 - val_mse: 0.0428\n",
      "Epoch 1252/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0033 - mse: 0.5309 - val_loss: 1.7235e-04 - val_mse: 0.0295\n",
      "Epoch 1253/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0034 - mse: 0.5628 - val_loss: 1.6707e-04 - val_mse: 0.0287\n",
      "Epoch 1254/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0036 - mse: 0.5800 - val_loss: 1.9676e-04 - val_mse: 0.0341\n",
      "Epoch 1255/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0034 - mse: 0.5463 - val_loss: 1.7591e-04 - val_mse: 0.0304\n",
      "Epoch 1256/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0030 - mse: 0.5072 - val_loss: 1.6931e-04 - val_mse: 0.0292\n",
      "Epoch 1257/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0035 - mse: 0.5650 - val_loss: 1.7113e-04 - val_mse: 0.0295\n",
      "Epoch 1258/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.6007 - val_loss: 1.6802e-04 - val_mse: 0.0289\n",
      "Epoch 1259/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0034 - mse: 0.5599 - val_loss: 2.1012e-04 - val_mse: 0.0364\n",
      "Epoch 1260/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0033 - mse: 0.5360 - val_loss: 1.7797e-04 - val_mse: 0.0308\n",
      "Epoch 1261/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0034 - mse: 0.5637 - val_loss: 1.6925e-04 - val_mse: 0.0290\n",
      "Epoch 1262/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0033 - mse: 0.5393 - val_loss: 1.7117e-04 - val_mse: 0.0295\n",
      "Epoch 1263/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0033 - mse: 0.5515 - val_loss: 1.7359e-04 - val_mse: 0.0297\n",
      "Epoch 1264/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0032 - mse: 0.5325 - val_loss: 1.6528e-04 - val_mse: 0.0285\n",
      "Epoch 1265/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0033 - mse: 0.5455 - val_loss: 1.8410e-04 - val_mse: 0.0319\n",
      "Epoch 1266/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0032 - mse: 0.5209 - val_loss: 1.6549e-04 - val_mse: 0.0286\n",
      "Epoch 1267/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0032 - mse: 0.5341 - val_loss: 1.6729e-04 - val_mse: 0.0289\n",
      "Epoch 1268/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0032 - mse: 0.5246 - val_loss: 1.6387e-04 - val_mse: 0.0283\n",
      "Epoch 1269/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0034 - mse: 0.5648 - val_loss: 1.6483e-04 - val_mse: 0.0284\n",
      "Epoch 1270/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0032 - mse: 0.5256 - val_loss: 1.9218e-04 - val_mse: 0.0333\n",
      "Epoch 1271/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0032 - mse: 0.5197 - val_loss: 2.2968e-04 - val_mse: 0.0398\n",
      "Epoch 1272/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0031 - mse: 0.5090 - val_loss: 1.7119e-04 - val_mse: 0.0293\n",
      "Epoch 1273/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0035 - mse: 0.5763 - val_loss: 1.6772e-04 - val_mse: 0.0290\n",
      "Epoch 1274/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0033 - mse: 0.5297 - val_loss: 1.8486e-04 - val_mse: 0.0320\n",
      "Epoch 1275/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0029 - mse: 0.4889 - val_loss: 1.6656e-04 - val_mse: 0.0288\n",
      "Epoch 1276/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0030 - mse: 0.4995 - val_loss: 1.7452e-04 - val_mse: 0.0302\n",
      "Epoch 1277/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0033 - mse: 0.5349 - val_loss: 1.6572e-04 - val_mse: 0.0286\n",
      "Epoch 1278/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0029 - mse: 0.4874 - val_loss: 1.6603e-04 - val_mse: 0.0286\n",
      "Epoch 1279/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0030 - mse: 0.4987 - val_loss: 1.6667e-04 - val_mse: 0.0288\n",
      "Epoch 1280/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0032 - mse: 0.5283 - val_loss: 1.6608e-04 - val_mse: 0.0286\n",
      "Epoch 1281/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0030 - mse: 0.4920 - val_loss: 1.7819e-04 - val_mse: 0.0309\n",
      "Epoch 1282/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0030 - mse: 0.5018 - val_loss: 1.8827e-04 - val_mse: 0.0326\n",
      "Epoch 1283/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0028 - mse: 0.4675 - val_loss: 1.9933e-04 - val_mse: 0.0345\n",
      "Epoch 1284/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0029 - mse: 0.4815 - val_loss: 1.8885e-04 - val_mse: 0.0327\n",
      "Epoch 1285/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0030 - mse: 0.4944 - val_loss: 1.6773e-04 - val_mse: 0.0288\n",
      "Epoch 1286/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0029 - mse: 0.4780 - val_loss: 1.6663e-04 - val_mse: 0.0288\n",
      "Epoch 1287/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0031 - mse: 0.5003 - val_loss: 2.3144e-04 - val_mse: 0.0400\n",
      "Epoch 1288/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0032 - mse: 0.5283 - val_loss: 1.7184e-04 - val_mse: 0.0296\n",
      "Epoch 1289/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0030 - mse: 0.5046 - val_loss: 1.7191e-04 - val_mse: 0.0296\n",
      "Epoch 1290/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0031 - mse: 0.5111 - val_loss: 2.1683e-04 - val_mse: 0.0375\n",
      "Epoch 1291/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0031 - mse: 0.5035 - val_loss: 1.6602e-04 - val_mse: 0.0287\n",
      "Epoch 1292/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0030 - mse: 0.4879 - val_loss: 1.7773e-04 - val_mse: 0.0304\n",
      "Epoch 1293/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0028 - mse: 0.4643 - val_loss: 1.7836e-04 - val_mse: 0.0309\n",
      "Epoch 1294/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0030 - mse: 0.4946 - val_loss: 2.0420e-04 - val_mse: 0.0354\n",
      "Epoch 1295/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0028 - mse: 0.4625 - val_loss: 1.8296e-04 - val_mse: 0.0313\n",
      "Epoch 1296/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0029 - mse: 0.4800 - val_loss: 1.6610e-04 - val_mse: 0.0287\n",
      "Epoch 1297/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0030 - mse: 0.4861 - val_loss: 1.9977e-04 - val_mse: 0.0346\n",
      "Epoch 1298/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0030 - mse: 0.4867 - val_loss: 1.7185e-04 - val_mse: 0.0298\n",
      "Epoch 1299/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0030 - mse: 0.4959 - val_loss: 1.6283e-04 - val_mse: 0.0281\n",
      "Epoch 1300/2000\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 0.0030 - mse: 0.4907 - val_loss: 1.6169e-04 - val_mse: 0.0280\n",
      "Epoch 1301/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0027 - mse: 0.4539 - val_loss: 1.9883e-04 - val_mse: 0.0345\n",
      "Epoch 1302/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0031 - mse: 0.5093 - val_loss: 1.6092e-04 - val_mse: 0.0278\n",
      "Epoch 1303/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0030 - mse: 0.4992 - val_loss: 1.6157e-04 - val_mse: 0.0279\n",
      "Epoch 1304/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0029 - mse: 0.4755 - val_loss: 1.6734e-04 - val_mse: 0.0290\n",
      "Epoch 1305/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0029 - mse: 0.4832 - val_loss: 1.6523e-04 - val_mse: 0.0286\n",
      "Epoch 1306/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0027 - mse: 0.4476 - val_loss: 1.6257e-04 - val_mse: 0.0281\n",
      "Epoch 1307/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0029 - mse: 0.4703 - val_loss: 1.6500e-04 - val_mse: 0.0283\n",
      "Epoch 1308/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0027 - mse: 0.4470 - val_loss: 1.6119e-04 - val_mse: 0.0279\n",
      "Epoch 1309/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0028 - mse: 0.4626 - val_loss: 1.6227e-04 - val_mse: 0.0279\n",
      "Epoch 1310/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0025 - mse: 0.4260 - val_loss: 1.6396e-04 - val_mse: 0.0282\n",
      "Epoch 1311/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0026 - mse: 0.4373 - val_loss: 2.1611e-04 - val_mse: 0.0374\n",
      "Epoch 1312/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0029 - mse: 0.4689 - val_loss: 1.7468e-04 - val_mse: 0.0303\n",
      "Epoch 1313/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0031 - mse: 0.5061 - val_loss: 1.5634e-04 - val_mse: 0.0270\n",
      "Epoch 1314/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0026 - mse: 0.4307 - val_loss: 1.7355e-04 - val_mse: 0.0301\n",
      "Epoch 1315/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0029 - mse: 0.4733 - val_loss: 1.6535e-04 - val_mse: 0.0286\n",
      "Epoch 1316/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4352 - val_loss: 1.5817e-04 - val_mse: 0.0274\n",
      "Epoch 1317/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0028 - mse: 0.4573 - val_loss: 1.5781e-04 - val_mse: 0.0273\n",
      "Epoch 1318/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0029 - mse: 0.4754 - val_loss: 1.5555e-04 - val_mse: 0.0269\n",
      "Epoch 1319/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0029 - mse: 0.4757 - val_loss: 1.6339e-04 - val_mse: 0.0283\n",
      "Epoch 1320/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0026 - mse: 0.4342 - val_loss: 1.6433e-04 - val_mse: 0.0285\n",
      "Epoch 1321/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4402 - val_loss: 1.6726e-04 - val_mse: 0.0290\n",
      "Epoch 1322/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0029 - mse: 0.4734 - val_loss: 1.8803e-04 - val_mse: 0.0327\n",
      "Epoch 1323/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0027 - mse: 0.4484 - val_loss: 1.6483e-04 - val_mse: 0.0286\n",
      "Epoch 1324/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0028 - mse: 0.4738 - val_loss: 1.5898e-04 - val_mse: 0.0274\n",
      "Epoch 1325/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0026 - mse: 0.4267 - val_loss: 1.7129e-04 - val_mse: 0.0297\n",
      "Epoch 1326/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0024 - mse: 0.4041 - val_loss: 1.6111e-04 - val_mse: 0.0279\n",
      "Epoch 1327/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0025 - mse: 0.4234 - val_loss: 1.6100e-04 - val_mse: 0.0279\n",
      "Epoch 1328/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0026 - mse: 0.4306 - val_loss: 1.7288e-04 - val_mse: 0.0300\n",
      "Epoch 1329/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4293 - val_loss: 1.5507e-04 - val_mse: 0.0268\n",
      "Epoch 1330/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4400 - val_loss: 1.5838e-04 - val_mse: 0.0275\n",
      "Epoch 1331/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0028 - mse: 0.4585 - val_loss: 2.2066e-04 - val_mse: 0.0383\n",
      "Epoch 1332/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0028 - mse: 0.4587 - val_loss: 1.5719e-04 - val_mse: 0.0270\n",
      "Epoch 1333/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4328 - val_loss: 1.5615e-04 - val_mse: 0.0270\n",
      "Epoch 1334/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0026 - mse: 0.4211 - val_loss: 2.1219e-04 - val_mse: 0.0369\n",
      "Epoch 1335/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0026 - mse: 0.4256 - val_loss: 1.5864e-04 - val_mse: 0.0274\n",
      "Epoch 1336/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0026 - mse: 0.4350 - val_loss: 1.5991e-04 - val_mse: 0.0274\n",
      "Epoch 1337/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0025 - mse: 0.4191 - val_loss: 1.7696e-04 - val_mse: 0.0307\n",
      "Epoch 1338/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0023 - mse: 0.3771 - val_loss: 1.7990e-04 - val_mse: 0.0312\n",
      "Epoch 1339/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0024 - mse: 0.3936 - val_loss: 2.0491e-04 - val_mse: 0.0356\n",
      "Epoch 1340/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0025 - mse: 0.4016 - val_loss: 1.8774e-04 - val_mse: 0.0326\n",
      "Epoch 1341/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0026 - mse: 0.4202 - val_loss: 1.5596e-04 - val_mse: 0.0268\n",
      "Epoch 1342/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0024 - mse: 0.4081 - val_loss: 1.5726e-04 - val_mse: 0.0272\n",
      "Epoch 1343/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0025 - mse: 0.4081 - val_loss: 1.8400e-04 - val_mse: 0.0319\n",
      "Epoch 1344/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0025 - mse: 0.4045 - val_loss: 1.6907e-04 - val_mse: 0.0293\n",
      "Epoch 1345/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0025 - mse: 0.4159 - val_loss: 1.6947e-04 - val_mse: 0.0293\n",
      "Epoch 1346/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0023 - mse: 0.3888 - val_loss: 1.6119e-04 - val_mse: 0.0278\n",
      "Epoch 1347/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0025 - mse: 0.4185 - val_loss: 1.6780e-04 - val_mse: 0.0290\n",
      "Epoch 1348/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0022 - mse: 0.3727 - val_loss: 1.6394e-04 - val_mse: 0.0284\n",
      "Epoch 1349/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0022 - mse: 0.3605 - val_loss: 1.6433e-04 - val_mse: 0.0284\n",
      "Epoch 1350/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0023 - mse: 0.3821 - val_loss: 1.7684e-04 - val_mse: 0.0306\n",
      "Epoch 1351/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0024 - mse: 0.3941 - val_loss: 1.8454e-04 - val_mse: 0.0319\n",
      "Epoch 1352/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0024 - mse: 0.4054 - val_loss: 1.5869e-04 - val_mse: 0.0272\n",
      "Epoch 1353/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0024 - mse: 0.4042 - val_loss: 1.6103e-04 - val_mse: 0.0278\n",
      "Epoch 1354/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0023 - mse: 0.3777 - val_loss: 1.6803e-04 - val_mse: 0.0291\n",
      "Epoch 1355/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0023 - mse: 0.3849 - val_loss: 1.5513e-04 - val_mse: 0.0266\n",
      "Epoch 1356/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0021 - mse: 0.3593 - val_loss: 1.5731e-04 - val_mse: 0.0271\n",
      "Epoch 1357/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0024 - mse: 0.3913 - val_loss: 1.5802e-04 - val_mse: 0.0272\n",
      "Epoch 1358/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0021 - mse: 0.3470 - val_loss: 1.6592e-04 - val_mse: 0.0286\n",
      "Epoch 1359/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0023 - mse: 0.3820 - val_loss: 1.7622e-04 - val_mse: 0.0304\n",
      "Epoch 1360/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0024 - mse: 0.4041 - val_loss: 1.5838e-04 - val_mse: 0.0273\n",
      "Epoch 1361/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0022 - mse: 0.3587 - val_loss: 1.7325e-04 - val_mse: 0.0299\n",
      "Epoch 1362/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0024 - mse: 0.3954 - val_loss: 1.6012e-04 - val_mse: 0.0277\n",
      "Epoch 1363/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0025 - mse: 0.4103 - val_loss: 1.5872e-04 - val_mse: 0.0274\n",
      "Epoch 1364/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0022 - mse: 0.3614 - val_loss: 1.5353e-04 - val_mse: 0.0264\n",
      "Epoch 1365/2000\n",
      "1168/1168 [==============================] - 0s 36us/step - loss: 0.0023 - mse: 0.3774 - val_loss: 1.6206e-04 - val_mse: 0.0280\n",
      "Epoch 1366/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0021 - mse: 0.3552 - val_loss: 1.6904e-04 - val_mse: 0.0293\n",
      "Epoch 1367/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0023 - mse: 0.3751 - val_loss: 1.5631e-04 - val_mse: 0.0270\n",
      "Epoch 1368/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0021 - mse: 0.3448 - val_loss: 1.8412e-04 - val_mse: 0.0319\n",
      "Epoch 1369/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3508 - val_loss: 1.5356e-04 - val_mse: 0.0265\n",
      "Epoch 1370/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3531 - val_loss: 1.6933e-04 - val_mse: 0.0293\n",
      "Epoch 1371/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0023 - mse: 0.3834 - val_loss: 1.7000e-04 - val_mse: 0.0294\n",
      "Epoch 1372/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0022 - mse: 0.3653 - val_loss: 1.5805e-04 - val_mse: 0.0271\n",
      "Epoch 1373/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0023 - mse: 0.3755 - val_loss: 1.5278e-04 - val_mse: 0.0263\n",
      "Epoch 1374/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3489 - val_loss: 1.5786e-04 - val_mse: 0.0273\n",
      "Epoch 1375/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0023 - mse: 0.3741 - val_loss: 1.5116e-04 - val_mse: 0.0260\n",
      "Epoch 1376/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0024 - mse: 0.3877 - val_loss: 1.5865e-04 - val_mse: 0.0275\n",
      "Epoch 1377/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3398 - val_loss: 1.5045e-04 - val_mse: 0.0260\n",
      "Epoch 1378/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0022 - mse: 0.3674 - val_loss: 1.4977e-04 - val_mse: 0.0258\n",
      "Epoch 1379/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3453 - val_loss: 1.7618e-04 - val_mse: 0.0305\n",
      "Epoch 1380/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3148 - val_loss: 1.7342e-04 - val_mse: 0.0300\n",
      "Epoch 1381/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0020 - mse: 0.3341 - val_loss: 1.9086e-04 - val_mse: 0.0330\n",
      "Epoch 1382/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0022 - mse: 0.3660 - val_loss: 1.5209e-04 - val_mse: 0.0262\n",
      "Epoch 1383/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0021 - mse: 0.3523 - val_loss: 1.5222e-04 - val_mse: 0.0263\n",
      "Epoch 1384/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0021 - mse: 0.3486 - val_loss: 1.9415e-04 - val_mse: 0.0337\n",
      "Epoch 1385/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0021 - mse: 0.3507 - val_loss: 1.5928e-04 - val_mse: 0.0276\n",
      "Epoch 1386/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0020 - mse: 0.3291 - val_loss: 1.6271e-04 - val_mse: 0.0282\n",
      "Epoch 1387/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0023 - mse: 0.3851 - val_loss: 1.5287e-04 - val_mse: 0.0264\n",
      "Epoch 1388/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3092 - val_loss: 1.5450e-04 - val_mse: 0.0268\n",
      "Epoch 1389/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3113 - val_loss: 1.5499e-04 - val_mse: 0.0268\n",
      "Epoch 1390/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0020 - mse: 0.3250 - val_loss: 1.5542e-04 - val_mse: 0.0269\n",
      "Epoch 1391/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0020 - mse: 0.3323 - val_loss: 1.5935e-04 - val_mse: 0.0276\n",
      "Epoch 1392/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3436 - val_loss: 1.5954e-04 - val_mse: 0.0277\n",
      "Epoch 1393/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0019 - mse: 0.3198 - val_loss: 1.6064e-04 - val_mse: 0.0279\n",
      "Epoch 1394/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0022 - mse: 0.3654 - val_loss: 1.6362e-04 - val_mse: 0.0285\n",
      "Epoch 1395/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3165 - val_loss: 1.6744e-04 - val_mse: 0.0291\n",
      "Epoch 1396/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0021 - mse: 0.3464 - val_loss: 1.5971e-04 - val_mse: 0.0277\n",
      "Epoch 1397/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3177 - val_loss: 1.5621e-04 - val_mse: 0.0271\n",
      "Epoch 1398/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0019 - mse: 0.3095 - val_loss: 1.8617e-04 - val_mse: 0.0324\n",
      "Epoch 1399/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3140 - val_loss: 1.7835e-04 - val_mse: 0.0310\n",
      "Epoch 1400/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3199 - val_loss: 1.5470e-04 - val_mse: 0.0269\n",
      "Epoch 1401/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3213 - val_loss: 1.5636e-04 - val_mse: 0.0272\n",
      "Epoch 1402/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3108 - val_loss: 1.5407e-04 - val_mse: 0.0267\n",
      "Epoch 1403/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0019 - mse: 0.3142 - val_loss: 1.7046e-04 - val_mse: 0.0296\n",
      "Epoch 1404/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0018 - mse: 0.2983 - val_loss: 1.7563e-04 - val_mse: 0.0305\n",
      "Epoch 1405/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2854 - val_loss: 1.5431e-04 - val_mse: 0.0267\n",
      "Epoch 1406/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3085 - val_loss: 1.8255e-04 - val_mse: 0.0317\n",
      "Epoch 1407/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3153 - val_loss: 1.5665e-04 - val_mse: 0.0272\n",
      "Epoch 1408/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3078 - val_loss: 1.5849e-04 - val_mse: 0.0275\n",
      "Epoch 1409/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0020 - mse: 0.3309 - val_loss: 1.5413e-04 - val_mse: 0.0267\n",
      "Epoch 1410/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3197 - val_loss: 1.5407e-04 - val_mse: 0.0267\n",
      "Epoch 1411/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0020 - mse: 0.3251 - val_loss: 1.5206e-04 - val_mse: 0.0264\n",
      "Epoch 1412/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0018 - mse: 0.3067 - val_loss: 1.5359e-04 - val_mse: 0.0267\n",
      "Epoch 1413/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3146 - val_loss: 1.7574e-04 - val_mse: 0.0305\n",
      "Epoch 1414/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3080 - val_loss: 1.5945e-04 - val_mse: 0.0277\n",
      "Epoch 1415/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0017 - mse: 0.2885 - val_loss: 1.5702e-04 - val_mse: 0.0273\n",
      "Epoch 1416/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3120 - val_loss: 1.9194e-04 - val_mse: 0.0333\n",
      "Epoch 1417/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0019 - mse: 0.3046 - val_loss: 1.9662e-04 - val_mse: 0.0341\n",
      "Epoch 1418/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0017 - mse: 0.2815 - val_loss: 1.5211e-04 - val_mse: 0.0263\n",
      "Epoch 1419/2000\n",
      "1168/1168 [==============================] - 0s 48us/step - loss: 0.0018 - mse: 0.2993 - val_loss: 1.5780e-04 - val_mse: 0.0274\n",
      "Epoch 1420/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0019 - mse: 0.3131 - val_loss: 1.5267e-04 - val_mse: 0.0264\n",
      "Epoch 1421/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0019 - mse: 0.3133 - val_loss: 1.6943e-04 - val_mse: 0.0294\n",
      "Epoch 1422/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0017 - mse: 0.2862 - val_loss: 1.5769e-04 - val_mse: 0.0273\n",
      "Epoch 1423/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2804 - val_loss: 1.5486e-04 - val_mse: 0.0268\n",
      "Epoch 1424/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0017 - mse: 0.2769 - val_loss: 1.6488e-04 - val_mse: 0.0286\n",
      "Epoch 1425/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0017 - mse: 0.2801 - val_loss: 1.5219e-04 - val_mse: 0.0264\n",
      "Epoch 1426/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0018 - mse: 0.2929 - val_loss: 1.6561e-04 - val_mse: 0.0288\n",
      "Epoch 1427/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0017 - mse: 0.2881 - val_loss: 1.6820e-04 - val_mse: 0.0292\n",
      "Epoch 1428/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0017 - mse: 0.2870 - val_loss: 1.5567e-04 - val_mse: 0.0270\n",
      "Epoch 1429/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0019 - mse: 0.3079 - val_loss: 1.6356e-04 - val_mse: 0.0284\n",
      "Epoch 1430/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 0.0017 - mse: 0.2820 - val_loss: 1.5674e-04 - val_mse: 0.0272\n",
      "Epoch 1431/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2785 - val_loss: 1.6006e-04 - val_mse: 0.0279\n",
      "Epoch 1432/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0018 - mse: 0.2949 - val_loss: 1.6148e-04 - val_mse: 0.0282\n",
      "Epoch 1433/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2855 - val_loss: 1.6537e-04 - val_mse: 0.0287\n",
      "Epoch 1434/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0017 - mse: 0.2774 - val_loss: 1.5602e-04 - val_mse: 0.0270\n",
      "Epoch 1435/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 0.0017 - mse: 0.2827 - val_loss: 1.7487e-04 - val_mse: 0.0304\n",
      "Epoch 1436/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2864 - val_loss: 1.5304e-04 - val_mse: 0.0265\n",
      "Epoch 1437/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0017 - mse: 0.2903 - val_loss: 1.5171e-04 - val_mse: 0.0262\n",
      "Epoch 1438/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0017 - mse: 0.2840 - val_loss: 1.6705e-04 - val_mse: 0.0290\n",
      "Epoch 1439/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0018 - mse: 0.2950 - val_loss: 1.5944e-04 - val_mse: 0.0277\n",
      "Epoch 1440/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2583 - val_loss: 1.5631e-04 - val_mse: 0.0270\n",
      "Epoch 1441/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0015 - mse: 0.2602 - val_loss: 1.6012e-04 - val_mse: 0.0278\n",
      "Epoch 1442/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0017 - mse: 0.2859 - val_loss: 1.9946e-04 - val_mse: 0.0346\n",
      "Epoch 1443/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0017 - mse: 0.2760 - val_loss: 1.6481e-04 - val_mse: 0.0285\n",
      "Epoch 1444/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0016 - mse: 0.2731 - val_loss: 1.6430e-04 - val_mse: 0.0285\n",
      "Epoch 1445/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0014 - mse: 0.2400 - val_loss: 1.8553e-04 - val_mse: 0.0322\n",
      "Epoch 1446/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0015 - mse: 0.2506 - val_loss: 1.6355e-04 - val_mse: 0.0284\n",
      "Epoch 1447/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0016 - mse: 0.2711 - val_loss: 1.5481e-04 - val_mse: 0.0267\n",
      "Epoch 1448/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0018 - mse: 0.2942 - val_loss: 1.5727e-04 - val_mse: 0.0272\n",
      "Epoch 1449/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0016 - mse: 0.2677 - val_loss: 1.6911e-04 - val_mse: 0.0293\n",
      "Epoch 1450/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2493 - val_loss: 1.6660e-04 - val_mse: 0.0289\n",
      "Epoch 1451/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0017 - mse: 0.2835 - val_loss: 1.5826e-04 - val_mse: 0.0274\n",
      "Epoch 1452/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2560 - val_loss: 1.9157e-04 - val_mse: 0.0333\n",
      "Epoch 1453/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0017 - mse: 0.2809 - val_loss: 1.5199e-04 - val_mse: 0.0264\n",
      "Epoch 1454/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0016 - mse: 0.2622 - val_loss: 1.4899e-04 - val_mse: 0.0259\n",
      "Epoch 1455/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0016 - mse: 0.2591 - val_loss: 1.6156e-04 - val_mse: 0.0282\n",
      "Epoch 1456/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0014 - mse: 0.2371 - val_loss: 1.5791e-04 - val_mse: 0.0275\n",
      "Epoch 1457/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 0.0014 - mse: 0.2354 - val_loss: 1.5049e-04 - val_mse: 0.0262\n",
      "Epoch 1458/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0015 - mse: 0.2566 - val_loss: 1.5204e-04 - val_mse: 0.0265\n",
      "Epoch 1459/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2422 - val_loss: 1.7337e-04 - val_mse: 0.0302\n",
      "Epoch 1460/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0016 - mse: 0.2630 - val_loss: 1.5348e-04 - val_mse: 0.0266\n",
      "Epoch 1461/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2492 - val_loss: 1.5585e-04 - val_mse: 0.0271\n",
      "Epoch 1462/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0016 - mse: 0.2656 - val_loss: 1.6662e-04 - val_mse: 0.0290\n",
      "Epoch 1463/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0015 - mse: 0.2446 - val_loss: 1.5998e-04 - val_mse: 0.0276\n",
      "Epoch 1464/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2459 - val_loss: 1.5694e-04 - val_mse: 0.0272\n",
      "Epoch 1465/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0014 - mse: 0.2401 - val_loss: 1.7646e-04 - val_mse: 0.0308\n",
      "Epoch 1466/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0015 - mse: 0.2453 - val_loss: 1.5329e-04 - val_mse: 0.0266\n",
      "Epoch 1467/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0014 - mse: 0.2338 - val_loss: 1.5711e-04 - val_mse: 0.0274\n",
      "Epoch 1468/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0015 - mse: 0.2431 - val_loss: 1.7401e-04 - val_mse: 0.0304\n",
      "Epoch 1469/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0015 - mse: 0.2472 - val_loss: 1.5386e-04 - val_mse: 0.0268\n",
      "Epoch 1470/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0015 - mse: 0.2550 - val_loss: 1.5444e-04 - val_mse: 0.0269\n",
      "Epoch 1471/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0016 - mse: 0.2642 - val_loss: 1.5122e-04 - val_mse: 0.0263\n",
      "Epoch 1472/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2470 - val_loss: 1.5082e-04 - val_mse: 0.0262\n",
      "Epoch 1473/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0014 - mse: 0.2320 - val_loss: 1.8095e-04 - val_mse: 0.0315\n",
      "Epoch 1474/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2149 - val_loss: 1.6108e-04 - val_mse: 0.0281\n",
      "Epoch 1475/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0014 - mse: 0.2419 - val_loss: 1.5063e-04 - val_mse: 0.0262\n",
      "Epoch 1476/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2175 - val_loss: 1.4764e-04 - val_mse: 0.0257\n",
      "Epoch 1477/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0014 - mse: 0.2307 - val_loss: 1.5069e-04 - val_mse: 0.0262\n",
      "Epoch 1478/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0014 - mse: 0.2312 - val_loss: 1.4962e-04 - val_mse: 0.0260\n",
      "Epoch 1479/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2126 - val_loss: 1.5204e-04 - val_mse: 0.0264\n",
      "Epoch 1480/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0015 - mse: 0.2428 - val_loss: 1.6173e-04 - val_mse: 0.0281\n",
      "Epoch 1481/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0014 - mse: 0.2284 - val_loss: 1.5709e-04 - val_mse: 0.0273\n",
      "Epoch 1482/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0014 - mse: 0.2257 - val_loss: 1.5700e-04 - val_mse: 0.0273\n",
      "Epoch 1483/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0014 - mse: 0.2298 - val_loss: 1.5294e-04 - val_mse: 0.0267\n",
      "Epoch 1484/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0013 - mse: 0.2253 - val_loss: 1.7563e-04 - val_mse: 0.0306\n",
      "Epoch 1485/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0014 - mse: 0.2285 - val_loss: 1.5516e-04 - val_mse: 0.0272\n",
      "Epoch 1486/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0013 - mse: 0.2165 - val_loss: 1.6045e-04 - val_mse: 0.0280\n",
      "Epoch 1487/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0013 - mse: 0.2138 - val_loss: 1.5247e-04 - val_mse: 0.0265\n",
      "Epoch 1488/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.2016 - val_loss: 1.6483e-04 - val_mse: 0.0287\n",
      "Epoch 1489/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0012 - mse: 0.2059 - val_loss: 1.5035e-04 - val_mse: 0.0261\n",
      "Epoch 1490/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2197 - val_loss: 1.5065e-04 - val_mse: 0.0261\n",
      "Epoch 1491/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0013 - mse: 0.2182 - val_loss: 1.5386e-04 - val_mse: 0.0268\n",
      "Epoch 1492/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2119 - val_loss: 1.6394e-04 - val_mse: 0.0286\n",
      "Epoch 1493/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.1956 - val_loss: 1.6403e-04 - val_mse: 0.0286\n",
      "Epoch 1494/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.2001 - val_loss: 1.6577e-04 - val_mse: 0.0290\n",
      "Epoch 1495/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.2059 - val_loss: 1.5562e-04 - val_mse: 0.0272\n",
      "Epoch 1496/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0013 - mse: 0.2160 - val_loss: 1.5864e-04 - val_mse: 0.0278\n",
      "Epoch 1497/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0014 - mse: 0.2272 - val_loss: 1.7945e-04 - val_mse: 0.0313\n",
      "Epoch 1498/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.1945 - val_loss: 1.7081e-04 - val_mse: 0.0298\n",
      "Epoch 1499/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0012 - mse: 0.2027 - val_loss: 1.5005e-04 - val_mse: 0.0261\n",
      "Epoch 1500/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2103 - val_loss: 1.4992e-04 - val_mse: 0.0260\n",
      "Epoch 1501/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0013 - mse: 0.2145 - val_loss: 1.5877e-04 - val_mse: 0.0277\n",
      "Epoch 1502/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0013 - mse: 0.2138 - val_loss: 1.4922e-04 - val_mse: 0.0260\n",
      "Epoch 1503/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.2058 - val_loss: 1.5409e-04 - val_mse: 0.0269\n",
      "Epoch 1504/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.2046 - val_loss: 1.8627e-04 - val_mse: 0.0325\n",
      "Epoch 1505/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0012 - mse: 0.2028 - val_loss: 1.4855e-04 - val_mse: 0.0257\n",
      "Epoch 1506/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0011 - mse: 0.1923 - val_loss: 1.6652e-04 - val_mse: 0.0290\n",
      "Epoch 1507/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.2013 - val_loss: 1.4843e-04 - val_mse: 0.0258\n",
      "Epoch 1508/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.2027 - val_loss: 1.6510e-04 - val_mse: 0.0286\n",
      "Epoch 1509/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.1939 - val_loss: 1.6879e-04 - val_mse: 0.0294\n",
      "Epoch 1510/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.2024 - val_loss: 1.7926e-04 - val_mse: 0.0312\n",
      "Epoch 1511/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0013 - mse: 0.2130 - val_loss: 1.5744e-04 - val_mse: 0.0272\n",
      "Epoch 1512/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0012 - mse: 0.1979 - val_loss: 1.8835e-04 - val_mse: 0.0328\n",
      "Epoch 1513/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0011 - mse: 0.1876 - val_loss: 1.5637e-04 - val_mse: 0.0271\n",
      "Epoch 1514/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0011 - mse: 0.1846 - val_loss: 1.5330e-04 - val_mse: 0.0265\n",
      "Epoch 1515/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.1934 - val_loss: 1.5429e-04 - val_mse: 0.0268\n",
      "Epoch 1516/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0011 - mse: 0.1864 - val_loss: 1.5104e-04 - val_mse: 0.0262\n",
      "Epoch 1517/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0010 - mse: 0.1775 - val_loss: 1.5088e-04 - val_mse: 0.0261\n",
      "Epoch 1518/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.1965 - val_loss: 1.6813e-04 - val_mse: 0.0292\n",
      "Epoch 1519/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0011 - mse: 0.1904 - val_loss: 1.6522e-04 - val_mse: 0.0287\n",
      "Epoch 1520/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0012 - mse: 0.2001 - val_loss: 1.5206e-04 - val_mse: 0.0263\n",
      "Epoch 1521/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0012 - mse: 0.1992 - val_loss: 1.6476e-04 - val_mse: 0.0286\n",
      "Epoch 1522/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0012 - mse: 0.1993 - val_loss: 1.4960e-04 - val_mse: 0.0259\n",
      "Epoch 1523/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0011 - mse: 0.1822 - val_loss: 1.5421e-04 - val_mse: 0.0268\n",
      "Epoch 1524/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0012 - mse: 0.1940 - val_loss: 1.4952e-04 - val_mse: 0.0259\n",
      "Epoch 1525/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0011 - mse: 0.1923 - val_loss: 1.5095e-04 - val_mse: 0.0261\n",
      "Epoch 1526/2000\n",
      "1168/1168 [==============================] - 0s 48us/step - loss: 0.0010 - mse: 0.1742 - val_loss: 1.9581e-04 - val_mse: 0.0341\n",
      "Epoch 1527/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 0.0011 - mse: 0.1795 - val_loss: 1.4796e-04 - val_mse: 0.0256\n",
      "Epoch 1528/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0011 - mse: 0.1864 - val_loss: 1.5812e-04 - val_mse: 0.0275\n",
      "Epoch 1529/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0011 - mse: 0.1771 - val_loss: 1.6284e-04 - val_mse: 0.0284\n",
      "Epoch 1530/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0011 - mse: 0.1785 - val_loss: 1.5024e-04 - val_mse: 0.0261\n",
      "Epoch 1531/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.5038e-04 - mse: 0.1604 - val_loss: 1.6001e-04 - val_mse: 0.0279\n",
      "Epoch 1532/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 0.0010 - mse: 0.1677 - val_loss: 1.4868e-04 - val_mse: 0.0258\n",
      "Epoch 1533/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0010 - mse: 0.1711 - val_loss: 1.5511e-04 - val_mse: 0.0270\n",
      "Epoch 1534/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 0.0011 - mse: 0.1778 - val_loss: 1.6399e-04 - val_mse: 0.0285\n",
      "Epoch 1535/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0011 - mse: 0.1854 - val_loss: 1.4970e-04 - val_mse: 0.0259\n",
      "Epoch 1536/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0011 - mse: 0.1829 - val_loss: 1.5782e-04 - val_mse: 0.0274\n",
      "Epoch 1537/2000\n",
      "1168/1168 [==============================] - 0s 45us/step - loss: 0.0010 - mse: 0.1697 - val_loss: 1.5933e-04 - val_mse: 0.0277\n",
      "Epoch 1538/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 9.5097e-04 - mse: 0.1601 - val_loss: 1.5472e-04 - val_mse: 0.0269\n",
      "Epoch 1539/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0010 - mse: 0.1691 - val_loss: 1.7171e-04 - val_mse: 0.0299\n",
      "Epoch 1540/2000\n",
      "1168/1168 [==============================] - 0s 46us/step - loss: 0.0011 - mse: 0.1758 - val_loss: 1.5257e-04 - val_mse: 0.0265\n",
      "Epoch 1541/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.7147e-04 - mse: 0.1626 - val_loss: 1.5959e-04 - val_mse: 0.0278\n",
      "Epoch 1542/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0010 - mse: 0.1675 - val_loss: 1.4942e-04 - val_mse: 0.0260\n",
      "Epoch 1543/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 9.8874e-04 - mse: 0.1670 - val_loss: 1.5219e-04 - val_mse: 0.0265\n",
      "Epoch 1544/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0010 - mse: 0.1725 - val_loss: 1.5598e-04 - val_mse: 0.0272\n",
      "Epoch 1545/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 0.0010 - mse: 0.1758 - val_loss: 1.4889e-04 - val_mse: 0.0259\n",
      "Epoch 1546/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 0.0010 - mse: 0.1767 - val_loss: 1.5006e-04 - val_mse: 0.0260\n",
      "Epoch 1547/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 9.9894e-04 - mse: 0.1671 - val_loss: 1.7482e-04 - val_mse: 0.0305\n",
      "Epoch 1548/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.9171e-04 - mse: 0.1655 - val_loss: 1.5001e-04 - val_mse: 0.0262\n",
      "Epoch 1549/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 9.6566e-04 - mse: 0.1613 - val_loss: 1.4847e-04 - val_mse: 0.0259\n",
      "Epoch 1550/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 9.4111e-04 - mse: 0.1594 - val_loss: 1.4837e-04 - val_mse: 0.0259\n",
      "Epoch 1551/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.6766e-04 - mse: 0.1459 - val_loss: 1.5337e-04 - val_mse: 0.0268\n",
      "Epoch 1552/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 9.7456e-04 - mse: 0.1642 - val_loss: 1.4551e-04 - val_mse: 0.0254\n",
      "Epoch 1553/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 9.3107e-04 - mse: 0.1561 - val_loss: 1.4809e-04 - val_mse: 0.0259\n",
      "Epoch 1554/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 9.6982e-04 - mse: 0.1620 - val_loss: 1.5021e-04 - val_mse: 0.0262\n",
      "Epoch 1555/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.1586e-04 - mse: 0.1540 - val_loss: 1.4540e-04 - val_mse: 0.0252\n",
      "Epoch 1556/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.7838e-04 - mse: 0.1643 - val_loss: 1.4607e-04 - val_mse: 0.0255\n",
      "Epoch 1557/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.4414e-04 - mse: 0.1584 - val_loss: 1.4451e-04 - val_mse: 0.0252\n",
      "Epoch 1558/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.9683e-04 - mse: 0.1513 - val_loss: 1.4806e-04 - val_mse: 0.0259\n",
      "Epoch 1559/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 9.5107e-04 - mse: 0.1592 - val_loss: 1.6619e-04 - val_mse: 0.0291\n",
      "Epoch 1560/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 9.0388e-04 - mse: 0.1514 - val_loss: 1.6107e-04 - val_mse: 0.0282\n",
      "Epoch 1561/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.8594e-04 - mse: 0.1491 - val_loss: 1.4859e-04 - val_mse: 0.0259\n",
      "Epoch 1562/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 9.1424e-04 - mse: 0.1542 - val_loss: 1.5287e-04 - val_mse: 0.0267\n",
      "Epoch 1563/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.6999e-04 - mse: 0.1463 - val_loss: 1.5264e-04 - val_mse: 0.0267\n",
      "Epoch 1564/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.5309e-04 - mse: 0.1439 - val_loss: 1.4928e-04 - val_mse: 0.0262\n",
      "Epoch 1565/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 9.0886e-04 - mse: 0.1531 - val_loss: 1.5074e-04 - val_mse: 0.0264\n",
      "Epoch 1566/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.9276e-04 - mse: 0.1505 - val_loss: 1.5338e-04 - val_mse: 0.0270\n",
      "Epoch 1567/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.3598e-04 - mse: 0.1400 - val_loss: 1.7147e-04 - val_mse: 0.0300\n",
      "Epoch 1568/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.5139e-04 - mse: 0.1426 - val_loss: 1.5317e-04 - val_mse: 0.0268\n",
      "Epoch 1569/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 8.7673e-04 - mse: 0.1489 - val_loss: 1.5000e-04 - val_mse: 0.0261\n",
      "Epoch 1570/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.8516e-04 - mse: 0.1494 - val_loss: 1.6449e-04 - val_mse: 0.0288\n",
      "Epoch 1571/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.7943e-04 - mse: 0.1478 - val_loss: 1.5266e-04 - val_mse: 0.0267\n",
      "Epoch 1572/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.3507e-04 - mse: 0.1407 - val_loss: 1.4606e-04 - val_mse: 0.0255\n",
      "Epoch 1573/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.3069e-04 - mse: 0.1409 - val_loss: 1.4738e-04 - val_mse: 0.0258\n",
      "Epoch 1574/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.7630e-04 - mse: 0.1456 - val_loss: 1.5260e-04 - val_mse: 0.0267\n",
      "Epoch 1575/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.4423e-04 - mse: 0.1411 - val_loss: 1.4609e-04 - val_mse: 0.0255\n",
      "Epoch 1576/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 9.2376e-04 - mse: 0.1556 - val_loss: 1.4863e-04 - val_mse: 0.0260\n",
      "Epoch 1577/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.7996e-04 - mse: 0.1472 - val_loss: 1.5884e-04 - val_mse: 0.0278\n",
      "Epoch 1578/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.2124e-04 - mse: 0.1387 - val_loss: 1.4484e-04 - val_mse: 0.0253\n",
      "Epoch 1579/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.7125e-04 - mse: 0.1462 - val_loss: 1.4492e-04 - val_mse: 0.0253\n",
      "Epoch 1580/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.3568e-04 - mse: 0.1406 - val_loss: 1.4505e-04 - val_mse: 0.0254\n",
      "Epoch 1581/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.1468e-04 - mse: 0.1382 - val_loss: 1.4633e-04 - val_mse: 0.0257\n",
      "Epoch 1582/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 8.1836e-04 - mse: 0.1386 - val_loss: 1.5390e-04 - val_mse: 0.0270\n",
      "Epoch 1583/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.2503e-04 - mse: 0.1393 - val_loss: 1.4449e-04 - val_mse: 0.0254\n",
      "Epoch 1584/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.8023e-04 - mse: 0.1320 - val_loss: 1.4453e-04 - val_mse: 0.0253\n",
      "Epoch 1585/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 8.0825e-04 - mse: 0.1359 - val_loss: 1.5033e-04 - val_mse: 0.0263\n",
      "Epoch 1586/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 8.4520e-04 - mse: 0.1425 - val_loss: 1.4364e-04 - val_mse: 0.0251\n",
      "Epoch 1587/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.5339e-04 - mse: 0.1268 - val_loss: 1.4430e-04 - val_mse: 0.0253\n",
      "Epoch 1588/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.3683e-04 - mse: 0.1416 - val_loss: 1.4132e-04 - val_mse: 0.0247\n",
      "Epoch 1589/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 7.8544e-04 - mse: 0.1323 - val_loss: 1.4212e-04 - val_mse: 0.0248\n",
      "Epoch 1590/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 8.0138e-04 - mse: 0.1353 - val_loss: 1.4263e-04 - val_mse: 0.0249\n",
      "Epoch 1591/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 8.0764e-04 - mse: 0.1365 - val_loss: 1.4482e-04 - val_mse: 0.0253\n",
      "Epoch 1592/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 7.7199e-04 - mse: 0.1299 - val_loss: 1.4884e-04 - val_mse: 0.0261\n",
      "Epoch 1593/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 7.6326e-04 - mse: 0.1292 - val_loss: 1.4417e-04 - val_mse: 0.0252\n",
      "Epoch 1594/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 8.0067e-04 - mse: 0.1355 - val_loss: 1.4680e-04 - val_mse: 0.0255\n",
      "Epoch 1595/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 7.5743e-04 - mse: 0.1276 - val_loss: 1.6149e-04 - val_mse: 0.0282\n",
      "Epoch 1596/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.9666e-04 - mse: 0.1174 - val_loss: 1.4266e-04 - val_mse: 0.0249\n",
      "Epoch 1597/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.5817e-04 - mse: 0.1288 - val_loss: 1.4386e-04 - val_mse: 0.0251\n",
      "Epoch 1598/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.9886e-04 - mse: 0.1337 - val_loss: 1.5631e-04 - val_mse: 0.0273\n",
      "Epoch 1599/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 7.3676e-04 - mse: 0.1246 - val_loss: 1.4120e-04 - val_mse: 0.0247\n",
      "Epoch 1600/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 7.6144e-04 - mse: 0.1279 - val_loss: 1.4586e-04 - val_mse: 0.0255\n",
      "Epoch 1601/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.8179e-04 - mse: 0.1321 - val_loss: 1.4598e-04 - val_mse: 0.0255\n",
      "Epoch 1602/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 7.7954e-04 - mse: 0.1312 - val_loss: 1.4934e-04 - val_mse: 0.0262\n",
      "Epoch 1603/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.5202e-04 - mse: 0.1095 - val_loss: 1.4683e-04 - val_mse: 0.0257\n",
      "Epoch 1604/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.8000e-04 - mse: 0.1157 - val_loss: 1.5056e-04 - val_mse: 0.0264\n",
      "Epoch 1605/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.2879e-04 - mse: 0.1236 - val_loss: 1.5549e-04 - val_mse: 0.0273\n",
      "Epoch 1606/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.1491e-04 - mse: 0.1205 - val_loss: 1.5387e-04 - val_mse: 0.0270\n",
      "Epoch 1607/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.4981e-04 - mse: 0.1264 - val_loss: 1.4637e-04 - val_mse: 0.0256\n",
      "Epoch 1608/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.4535e-04 - mse: 0.1263 - val_loss: 1.5606e-04 - val_mse: 0.0273\n",
      "Epoch 1609/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.0109e-04 - mse: 0.1181 - val_loss: 1.4924e-04 - val_mse: 0.0261\n",
      "Epoch 1610/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.8282e-04 - mse: 0.1155 - val_loss: 1.4577e-04 - val_mse: 0.0255\n",
      "Epoch 1611/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 7.0621e-04 - mse: 0.1195 - val_loss: 1.6309e-04 - val_mse: 0.0285\n",
      "Epoch 1612/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.6562e-04 - mse: 0.1117 - val_loss: 1.4858e-04 - val_mse: 0.0259\n",
      "Epoch 1613/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.9405e-04 - mse: 0.1174 - val_loss: 1.4941e-04 - val_mse: 0.0260\n",
      "Epoch 1614/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.2706e-04 - mse: 0.1231 - val_loss: 1.6100e-04 - val_mse: 0.0281\n",
      "Epoch 1615/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.9345e-04 - mse: 0.1172 - val_loss: 1.4655e-04 - val_mse: 0.0256\n",
      "Epoch 1616/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.8307e-04 - mse: 0.1148 - val_loss: 1.4547e-04 - val_mse: 0.0253\n",
      "Epoch 1617/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.9707e-04 - mse: 0.1184 - val_loss: 1.4868e-04 - val_mse: 0.0260\n",
      "Epoch 1618/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 6.3547e-04 - mse: 0.1078 - val_loss: 1.6062e-04 - val_mse: 0.0281\n",
      "Epoch 1619/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.3274e-04 - mse: 0.1064 - val_loss: 1.5683e-04 - val_mse: 0.0275\n",
      "Epoch 1620/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 7.0679e-04 - mse: 0.1187 - val_loss: 1.4671e-04 - val_mse: 0.0256\n",
      "Epoch 1621/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 6.5464e-04 - mse: 0.1107 - val_loss: 1.4968e-04 - val_mse: 0.0262\n",
      "Epoch 1622/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.9156e-04 - mse: 0.1163 - val_loss: 1.5677e-04 - val_mse: 0.0274\n",
      "Epoch 1623/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.6898e-04 - mse: 0.1126 - val_loss: 1.4938e-04 - val_mse: 0.0261\n",
      "Epoch 1624/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.6702e-04 - mse: 0.1127 - val_loss: 1.4468e-04 - val_mse: 0.0253\n",
      "Epoch 1625/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.6062e-04 - mse: 0.1112 - val_loss: 1.5715e-04 - val_mse: 0.0275\n",
      "Epoch 1626/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.1681e-04 - mse: 0.1039 - val_loss: 1.4585e-04 - val_mse: 0.0255\n",
      "Epoch 1627/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.5352e-04 - mse: 0.1106 - val_loss: 1.5290e-04 - val_mse: 0.0268\n",
      "Epoch 1628/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.1238e-04 - mse: 0.1037 - val_loss: 1.4992e-04 - val_mse: 0.0263\n",
      "Epoch 1629/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.3994e-04 - mse: 0.1093 - val_loss: 1.4617e-04 - val_mse: 0.0256\n",
      "Epoch 1630/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 5.9800e-04 - mse: 0.1011 - val_loss: 1.5803e-04 - val_mse: 0.0277\n",
      "Epoch 1631/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.1413e-04 - mse: 0.1039 - val_loss: 1.5182e-04 - val_mse: 0.0266\n",
      "Epoch 1632/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.4202e-04 - mse: 0.1084 - val_loss: 1.4631e-04 - val_mse: 0.0255\n",
      "Epoch 1633/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 6.3245e-04 - mse: 0.1080 - val_loss: 1.6392e-04 - val_mse: 0.0287\n",
      "Epoch 1634/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.7829e-04 - mse: 0.0975 - val_loss: 1.4509e-04 - val_mse: 0.0254\n",
      "Epoch 1635/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.3331e-04 - mse: 0.1073 - val_loss: 1.5238e-04 - val_mse: 0.0267\n",
      "Epoch 1636/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.2487e-04 - mse: 0.1065 - val_loss: 1.4515e-04 - val_mse: 0.0254\n",
      "Epoch 1637/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.0142e-04 - mse: 0.1024 - val_loss: 1.4512e-04 - val_mse: 0.0254\n",
      "Epoch 1638/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.0779e-04 - mse: 0.1028 - val_loss: 1.5012e-04 - val_mse: 0.0263\n",
      "Epoch 1639/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.1543e-04 - mse: 0.1046 - val_loss: 1.4664e-04 - val_mse: 0.0257\n",
      "Epoch 1640/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.2623e-04 - mse: 0.1064 - val_loss: 1.5214e-04 - val_mse: 0.0267\n",
      "Epoch 1641/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.3950e-04 - mse: 0.1081 - val_loss: 1.4717e-04 - val_mse: 0.0258\n",
      "Epoch 1642/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 6.3483e-04 - mse: 0.1077 - val_loss: 1.4954e-04 - val_mse: 0.0262\n",
      "Epoch 1643/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.8296e-04 - mse: 0.0985 - val_loss: 1.4634e-04 - val_mse: 0.0256\n",
      "Epoch 1644/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 6.1818e-04 - mse: 0.1043 - val_loss: 1.6470e-04 - val_mse: 0.0288\n",
      "Epoch 1645/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.7609e-04 - mse: 0.0972 - val_loss: 1.4631e-04 - val_mse: 0.0257\n",
      "Epoch 1646/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.9223e-04 - mse: 0.1009 - val_loss: 1.4870e-04 - val_mse: 0.0261\n",
      "Epoch 1647/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 6.0127e-04 - mse: 0.1016 - val_loss: 1.5988e-04 - val_mse: 0.0280\n",
      "Epoch 1648/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 6.0143e-04 - mse: 0.1023 - val_loss: 1.4773e-04 - val_mse: 0.0258\n",
      "Epoch 1649/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.6994e-04 - mse: 0.0967 - val_loss: 1.5298e-04 - val_mse: 0.0268\n",
      "Epoch 1650/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 5.8427e-04 - mse: 0.0988 - val_loss: 1.5859e-04 - val_mse: 0.0278\n",
      "Epoch 1651/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 5.6986e-04 - mse: 0.0973 - val_loss: 1.5066e-04 - val_mse: 0.0264\n",
      "Epoch 1652/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.7274e-04 - mse: 0.0971 - val_loss: 1.6498e-04 - val_mse: 0.0290\n",
      "Epoch 1653/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.6166e-04 - mse: 0.0949 - val_loss: 1.5189e-04 - val_mse: 0.0267\n",
      "Epoch 1654/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 6.0108e-04 - mse: 0.1017 - val_loss: 1.5479e-04 - val_mse: 0.0272\n",
      "Epoch 1655/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.7443e-04 - mse: 0.0970 - val_loss: 1.4861e-04 - val_mse: 0.0261\n",
      "Epoch 1656/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 5.4471e-04 - mse: 0.0922 - val_loss: 1.5817e-04 - val_mse: 0.0277\n",
      "Epoch 1657/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.3256e-04 - mse: 0.0904 - val_loss: 1.5740e-04 - val_mse: 0.0276\n",
      "Epoch 1658/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.7835e-04 - mse: 0.0978 - val_loss: 1.4634e-04 - val_mse: 0.0256\n",
      "Epoch 1659/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 5.1365e-04 - mse: 0.0871 - val_loss: 1.4816e-04 - val_mse: 0.0260\n",
      "Epoch 1660/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.3213e-04 - mse: 0.0898 - val_loss: 1.5909e-04 - val_mse: 0.0279\n",
      "Epoch 1661/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.5838e-04 - mse: 0.0943 - val_loss: 1.5127e-04 - val_mse: 0.0266\n",
      "Epoch 1662/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 5.2155e-04 - mse: 0.0888 - val_loss: 1.5046e-04 - val_mse: 0.0264\n",
      "Epoch 1663/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.5373e-04 - mse: 0.0934 - val_loss: 1.5689e-04 - val_mse: 0.0275\n",
      "Epoch 1664/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 5.1688e-04 - mse: 0.0875 - val_loss: 1.4979e-04 - val_mse: 0.0263\n",
      "Epoch 1665/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 5.0089e-04 - mse: 0.0851 - val_loss: 1.5376e-04 - val_mse: 0.0270\n",
      "Epoch 1666/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.1580e-04 - mse: 0.0871 - val_loss: 1.5340e-04 - val_mse: 0.0270\n",
      "Epoch 1667/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.2783e-04 - mse: 0.0892 - val_loss: 1.5409e-04 - val_mse: 0.0271\n",
      "Epoch 1668/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.3750e-04 - mse: 0.0911 - val_loss: 1.4612e-04 - val_mse: 0.0257\n",
      "Epoch 1669/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.0433e-04 - mse: 0.0862 - val_loss: 1.4833e-04 - val_mse: 0.0261\n",
      "Epoch 1670/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.2175e-04 - mse: 0.0887 - val_loss: 1.5226e-04 - val_mse: 0.0267\n",
      "Epoch 1671/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.1316e-04 - mse: 0.0871 - val_loss: 1.4628e-04 - val_mse: 0.0257\n",
      "Epoch 1672/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.2900e-04 - mse: 0.0895 - val_loss: 1.5016e-04 - val_mse: 0.0262\n",
      "Epoch 1673/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 5.0622e-04 - mse: 0.0864 - val_loss: 1.5695e-04 - val_mse: 0.0276\n",
      "Epoch 1674/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 5.1837e-04 - mse: 0.0880 - val_loss: 1.6643e-04 - val_mse: 0.0292\n",
      "Epoch 1675/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.3746e-04 - mse: 0.0911 - val_loss: 1.5095e-04 - val_mse: 0.0266\n",
      "Epoch 1676/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 5.5991e-04 - mse: 0.0958 - val_loss: 1.4705e-04 - val_mse: 0.0258\n",
      "Epoch 1677/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.7139e-04 - mse: 0.0796 - val_loss: 1.4481e-04 - val_mse: 0.0254\n",
      "Epoch 1678/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.1302e-04 - mse: 0.0873 - val_loss: 1.4912e-04 - val_mse: 0.0262\n",
      "Epoch 1679/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.8190e-04 - mse: 0.0809 - val_loss: 1.5162e-04 - val_mse: 0.0266\n",
      "Epoch 1680/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 5.0270e-04 - mse: 0.0857 - val_loss: 1.4518e-04 - val_mse: 0.0254\n",
      "Epoch 1681/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 5.0313e-04 - mse: 0.0853 - val_loss: 1.4902e-04 - val_mse: 0.0261\n",
      "Epoch 1682/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.6824e-04 - mse: 0.0793 - val_loss: 1.4511e-04 - val_mse: 0.0254\n",
      "Epoch 1683/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.8262e-04 - mse: 0.0823 - val_loss: 1.5037e-04 - val_mse: 0.0264\n",
      "Epoch 1684/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.7414e-04 - mse: 0.0810 - val_loss: 1.4912e-04 - val_mse: 0.0261\n",
      "Epoch 1685/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.6832e-04 - mse: 0.0794 - val_loss: 1.5180e-04 - val_mse: 0.0266\n",
      "Epoch 1686/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.7865e-04 - mse: 0.0814 - val_loss: 1.5760e-04 - val_mse: 0.0277\n",
      "Epoch 1687/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.6059e-04 - mse: 0.0785 - val_loss: 1.5087e-04 - val_mse: 0.0265\n",
      "Epoch 1688/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.9353e-04 - mse: 0.0841 - val_loss: 1.6431e-04 - val_mse: 0.0288\n",
      "Epoch 1689/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.3888e-04 - mse: 0.0740 - val_loss: 1.4965e-04 - val_mse: 0.0263\n",
      "Epoch 1690/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 4.5767e-04 - mse: 0.0778 - val_loss: 1.4645e-04 - val_mse: 0.0257\n",
      "Epoch 1691/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 4.9795e-04 - mse: 0.0846 - val_loss: 1.4861e-04 - val_mse: 0.0261\n",
      "Epoch 1692/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.6121e-04 - mse: 0.0787 - val_loss: 1.4529e-04 - val_mse: 0.0255\n",
      "Epoch 1693/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.7295e-04 - mse: 0.0806 - val_loss: 1.5643e-04 - val_mse: 0.0275\n",
      "Epoch 1694/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.4831e-04 - mse: 0.0761 - val_loss: 1.4839e-04 - val_mse: 0.0260\n",
      "Epoch 1695/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.7865e-04 - mse: 0.0809 - val_loss: 1.5266e-04 - val_mse: 0.0268\n",
      "Epoch 1696/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.6612e-04 - mse: 0.0789 - val_loss: 1.5040e-04 - val_mse: 0.0264\n",
      "Epoch 1697/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.4264e-04 - mse: 0.0750 - val_loss: 1.5882e-04 - val_mse: 0.0279\n",
      "Epoch 1698/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.5666e-04 - mse: 0.0780 - val_loss: 1.4920e-04 - val_mse: 0.0262\n",
      "Epoch 1699/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.7107e-04 - mse: 0.0801 - val_loss: 1.5055e-04 - val_mse: 0.0265\n",
      "Epoch 1700/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.2373e-04 - mse: 0.0724 - val_loss: 1.5732e-04 - val_mse: 0.0277\n",
      "Epoch 1701/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.5133e-04 - mse: 0.0762 - val_loss: 1.4975e-04 - val_mse: 0.0263\n",
      "Epoch 1702/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.2589e-04 - mse: 0.0726 - val_loss: 1.5045e-04 - val_mse: 0.0264\n",
      "Epoch 1703/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.9855e-04 - mse: 0.0679 - val_loss: 1.4939e-04 - val_mse: 0.0262\n",
      "Epoch 1704/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.5313e-04 - mse: 0.0765 - val_loss: 1.5186e-04 - val_mse: 0.0267\n",
      "Epoch 1705/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.5014e-04 - mse: 0.0765 - val_loss: 1.4845e-04 - val_mse: 0.0260\n",
      "Epoch 1706/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.1637e-04 - mse: 0.0705 - val_loss: 1.4937e-04 - val_mse: 0.0262\n",
      "Epoch 1707/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.1918e-04 - mse: 0.0709 - val_loss: 1.5474e-04 - val_mse: 0.0272\n",
      "Epoch 1708/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.5798e-04 - mse: 0.0781 - val_loss: 1.4636e-04 - val_mse: 0.0258\n",
      "Epoch 1709/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.5913e-04 - mse: 0.0787 - val_loss: 1.4601e-04 - val_mse: 0.0257\n",
      "Epoch 1710/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.9368e-04 - mse: 0.0665 - val_loss: 1.6752e-04 - val_mse: 0.0294\n",
      "Epoch 1711/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.5821e-04 - mse: 0.0773 - val_loss: 1.4574e-04 - val_mse: 0.0256\n",
      "Epoch 1712/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.9780e-04 - mse: 0.0675 - val_loss: 1.4653e-04 - val_mse: 0.0258\n",
      "Epoch 1713/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.2512e-04 - mse: 0.0722 - val_loss: 1.5284e-04 - val_mse: 0.0269\n",
      "Epoch 1714/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.9969e-04 - mse: 0.0674 - val_loss: 1.5053e-04 - val_mse: 0.0265\n",
      "Epoch 1715/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.0672e-04 - mse: 0.0696 - val_loss: 1.4709e-04 - val_mse: 0.0259\n",
      "Epoch 1716/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.0383e-04 - mse: 0.0690 - val_loss: 1.5621e-04 - val_mse: 0.0275\n",
      "Epoch 1717/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.0373e-04 - mse: 0.0684 - val_loss: 1.4661e-04 - val_mse: 0.0258\n",
      "Epoch 1718/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.1067e-04 - mse: 0.0701 - val_loss: 1.4771e-04 - val_mse: 0.0259\n",
      "Epoch 1719/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.0457e-04 - mse: 0.0690 - val_loss: 1.4820e-04 - val_mse: 0.0261\n",
      "Epoch 1720/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.2313e-04 - mse: 0.0721 - val_loss: 1.4816e-04 - val_mse: 0.0261\n",
      "Epoch 1721/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.2712e-04 - mse: 0.0730 - val_loss: 1.4811e-04 - val_mse: 0.0261\n",
      "Epoch 1722/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 4.0472e-04 - mse: 0.0687 - val_loss: 1.4767e-04 - val_mse: 0.0260\n",
      "Epoch 1723/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 3.8668e-04 - mse: 0.0656 - val_loss: 1.4809e-04 - val_mse: 0.0260\n",
      "Epoch 1724/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.8070e-04 - mse: 0.0650 - val_loss: 1.5223e-04 - val_mse: 0.0268\n",
      "Epoch 1725/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.9477e-04 - mse: 0.0671 - val_loss: 1.5262e-04 - val_mse: 0.0268\n",
      "Epoch 1726/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 4.1046e-04 - mse: 0.0702 - val_loss: 1.5091e-04 - val_mse: 0.0265\n",
      "Epoch 1727/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.8046e-04 - mse: 0.0648 - val_loss: 1.5239e-04 - val_mse: 0.0267\n",
      "Epoch 1728/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.4608e-04 - mse: 0.0587 - val_loss: 1.5294e-04 - val_mse: 0.0269\n",
      "Epoch 1729/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.6911e-04 - mse: 0.0632 - val_loss: 1.5304e-04 - val_mse: 0.0270\n",
      "Epoch 1730/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.6678e-04 - mse: 0.0621 - val_loss: 1.5364e-04 - val_mse: 0.0270\n",
      "Epoch 1731/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 4.0264e-04 - mse: 0.0686 - val_loss: 1.4944e-04 - val_mse: 0.0262\n",
      "Epoch 1732/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.7408e-04 - mse: 0.0632 - val_loss: 1.4919e-04 - val_mse: 0.0262\n",
      "Epoch 1733/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.8616e-04 - mse: 0.0657 - val_loss: 1.4676e-04 - val_mse: 0.0257\n",
      "Epoch 1734/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.8726e-04 - mse: 0.0655 - val_loss: 1.4863e-04 - val_mse: 0.0261\n",
      "Epoch 1735/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.6499e-04 - mse: 0.0622 - val_loss: 1.4489e-04 - val_mse: 0.0254\n",
      "Epoch 1736/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.7280e-04 - mse: 0.0637 - val_loss: 1.4671e-04 - val_mse: 0.0258\n",
      "Epoch 1737/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.7423e-04 - mse: 0.0635 - val_loss: 1.4882e-04 - val_mse: 0.0262\n",
      "Epoch 1738/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.5558e-04 - mse: 0.0605 - val_loss: 1.4609e-04 - val_mse: 0.0257\n",
      "Epoch 1739/2000\n",
      "1168/1168 [==============================] - 0s 36us/step - loss: 3.4951e-04 - mse: 0.0594 - val_loss: 1.4851e-04 - val_mse: 0.0261\n",
      "Epoch 1740/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.7025e-04 - mse: 0.0630 - val_loss: 1.4516e-04 - val_mse: 0.0255\n",
      "Epoch 1741/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.8565e-04 - mse: 0.0660 - val_loss: 1.4862e-04 - val_mse: 0.0261\n",
      "Epoch 1742/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.6959e-04 - mse: 0.0629 - val_loss: 1.4453e-04 - val_mse: 0.0254\n",
      "Epoch 1743/2000\n",
      "1168/1168 [==============================] - 0s 47us/step - loss: 3.4675e-04 - mse: 0.0586 - val_loss: 1.4712e-04 - val_mse: 0.0259\n",
      "Epoch 1744/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.8454e-04 - mse: 0.0656 - val_loss: 1.4520e-04 - val_mse: 0.0255\n",
      "Epoch 1745/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 3.3970e-04 - mse: 0.0580 - val_loss: 1.4631e-04 - val_mse: 0.0256\n",
      "Epoch 1746/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.4740e-04 - mse: 0.0594 - val_loss: 1.5598e-04 - val_mse: 0.0274\n",
      "Epoch 1747/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0406e-04 - mse: 0.0517 - val_loss: 1.4465e-04 - val_mse: 0.0254\n",
      "Epoch 1748/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.5456e-04 - mse: 0.0606 - val_loss: 1.4357e-04 - val_mse: 0.0252\n",
      "Epoch 1749/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.3622e-04 - mse: 0.0570 - val_loss: 1.4969e-04 - val_mse: 0.0263\n",
      "Epoch 1750/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.6437e-04 - mse: 0.0615 - val_loss: 1.4292e-04 - val_mse: 0.0251\n",
      "Epoch 1751/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 3.2737e-04 - mse: 0.0556 - val_loss: 1.4149e-04 - val_mse: 0.0248\n",
      "Epoch 1752/2000\n",
      "1168/1168 [==============================] - 0s 48us/step - loss: 3.5042e-04 - mse: 0.0596 - val_loss: 1.4653e-04 - val_mse: 0.0258\n",
      "Epoch 1753/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 3.7935e-04 - mse: 0.0649 - val_loss: 1.4999e-04 - val_mse: 0.0263\n",
      "Epoch 1754/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.3836e-04 - mse: 0.0576 - val_loss: 1.4805e-04 - val_mse: 0.0259\n",
      "Epoch 1755/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.3088e-04 - mse: 0.0565 - val_loss: 1.4963e-04 - val_mse: 0.0263\n",
      "Epoch 1756/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.5875e-04 - mse: 0.0608 - val_loss: 1.5421e-04 - val_mse: 0.0271\n",
      "Epoch 1757/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.3020e-04 - mse: 0.0562 - val_loss: 1.4672e-04 - val_mse: 0.0258\n",
      "Epoch 1758/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 3.2869e-04 - mse: 0.0560 - val_loss: 1.4478e-04 - val_mse: 0.0254\n",
      "Epoch 1759/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.3212e-04 - mse: 0.0563 - val_loss: 1.5418e-04 - val_mse: 0.0271\n",
      "Epoch 1760/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.4581e-04 - mse: 0.0587 - val_loss: 1.4614e-04 - val_mse: 0.0256\n",
      "Epoch 1761/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0345e-04 - mse: 0.0517 - val_loss: 1.4660e-04 - val_mse: 0.0258\n",
      "Epoch 1762/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0467e-04 - mse: 0.0519 - val_loss: 1.5160e-04 - val_mse: 0.0267\n",
      "Epoch 1763/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.0848e-04 - mse: 0.0530 - val_loss: 1.4742e-04 - val_mse: 0.0259\n",
      "Epoch 1764/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.2960e-04 - mse: 0.0565 - val_loss: 1.4945e-04 - val_mse: 0.0263\n",
      "Epoch 1765/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.9444e-04 - mse: 0.0501 - val_loss: 1.4718e-04 - val_mse: 0.0258\n",
      "Epoch 1766/2000\n",
      "1168/1168 [==============================] - 0s 44us/step - loss: 3.3946e-04 - mse: 0.0580 - val_loss: 1.4454e-04 - val_mse: 0.0253\n",
      "Epoch 1767/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.9353e-04 - mse: 0.0503 - val_loss: 1.4714e-04 - val_mse: 0.0258\n",
      "Epoch 1768/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.3306e-04 - mse: 0.0568 - val_loss: 1.4856e-04 - val_mse: 0.0261\n",
      "Epoch 1769/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.9994e-04 - mse: 0.0513 - val_loss: 1.4871e-04 - val_mse: 0.0260\n",
      "Epoch 1770/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0195e-04 - mse: 0.0512 - val_loss: 1.4632e-04 - val_mse: 0.0257\n",
      "Epoch 1771/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0568e-04 - mse: 0.0518 - val_loss: 1.5098e-04 - val_mse: 0.0265\n",
      "Epoch 1772/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.2643e-04 - mse: 0.0558 - val_loss: 1.4742e-04 - val_mse: 0.0258\n",
      "Epoch 1773/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8974e-04 - mse: 0.0498 - val_loss: 1.4774e-04 - val_mse: 0.0258\n",
      "Epoch 1774/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.9713e-04 - mse: 0.0505 - val_loss: 1.4815e-04 - val_mse: 0.0260\n",
      "Epoch 1775/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.3939e-04 - mse: 0.0579 - val_loss: 1.4924e-04 - val_mse: 0.0262\n",
      "Epoch 1776/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.1372e-04 - mse: 0.0535 - val_loss: 1.4631e-04 - val_mse: 0.0257\n",
      "Epoch 1777/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 3.0406e-04 - mse: 0.0518 - val_loss: 1.4793e-04 - val_mse: 0.0259\n",
      "Epoch 1778/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.1048e-04 - mse: 0.0531 - val_loss: 1.4482e-04 - val_mse: 0.0253\n",
      "Epoch 1779/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.8961e-04 - mse: 0.0495 - val_loss: 1.4419e-04 - val_mse: 0.0253\n",
      "Epoch 1780/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0123e-04 - mse: 0.0515 - val_loss: 1.4636e-04 - val_mse: 0.0257\n",
      "Epoch 1781/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.1393e-04 - mse: 0.0534 - val_loss: 1.4348e-04 - val_mse: 0.0252\n",
      "Epoch 1782/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8043e-04 - mse: 0.0475 - val_loss: 1.4790e-04 - val_mse: 0.0260\n",
      "Epoch 1783/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8690e-04 - mse: 0.0487 - val_loss: 1.4865e-04 - val_mse: 0.0261\n",
      "Epoch 1784/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0249e-04 - mse: 0.0516 - val_loss: 1.4593e-04 - val_mse: 0.0256\n",
      "Epoch 1785/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0365e-04 - mse: 0.0519 - val_loss: 1.4992e-04 - val_mse: 0.0262\n",
      "Epoch 1786/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 3.0020e-04 - mse: 0.0510 - val_loss: 1.6419e-04 - val_mse: 0.0288\n",
      "Epoch 1787/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.9725e-04 - mse: 0.0502 - val_loss: 1.4577e-04 - val_mse: 0.0256\n",
      "Epoch 1788/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 3.0228e-04 - mse: 0.0520 - val_loss: 1.4388e-04 - val_mse: 0.0253\n",
      "\n",
      "Epoch 01788: ReduceLROnPlateau reducing learning rate to 0.001500000071246177.\n",
      "Epoch 1789/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.7986e-04 - mse: 0.0477 - val_loss: 1.4489e-04 - val_mse: 0.0255\n",
      "Epoch 1790/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.8490e-04 - mse: 0.0485 - val_loss: 1.4437e-04 - val_mse: 0.0254\n",
      "Epoch 1791/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8022e-04 - mse: 0.0481 - val_loss: 1.4518e-04 - val_mse: 0.0256\n",
      "Epoch 1792/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.5887e-04 - mse: 0.0438 - val_loss: 1.4744e-04 - val_mse: 0.0259\n",
      "Epoch 1793/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0812e-04 - mse: 0.0526 - val_loss: 1.4376e-04 - val_mse: 0.0252\n",
      "Epoch 1794/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.9103e-04 - mse: 0.0499 - val_loss: 1.4634e-04 - val_mse: 0.0257\n",
      "Epoch 1795/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0832e-04 - mse: 0.0528 - val_loss: 1.4633e-04 - val_mse: 0.0257\n",
      "Epoch 1796/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.9231e-04 - mse: 0.0495 - val_loss: 1.4349e-04 - val_mse: 0.0252\n",
      "Epoch 1797/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 3.0024e-04 - mse: 0.0515 - val_loss: 1.4655e-04 - val_mse: 0.0258\n",
      "Epoch 1798/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.7974e-04 - mse: 0.0477 - val_loss: 1.4297e-04 - val_mse: 0.0251\n",
      "Epoch 1799/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8465e-04 - mse: 0.0491 - val_loss: 1.4302e-04 - val_mse: 0.0251\n",
      "Epoch 1800/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.7364e-04 - mse: 0.0467 - val_loss: 1.4676e-04 - val_mse: 0.0258\n",
      "Epoch 1801/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.6865e-04 - mse: 0.0460 - val_loss: 1.4420e-04 - val_mse: 0.0253\n",
      "Epoch 1802/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.7763e-04 - mse: 0.0474 - val_loss: 1.4712e-04 - val_mse: 0.0258\n",
      "Epoch 1803/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.7195e-04 - mse: 0.0464 - val_loss: 1.4627e-04 - val_mse: 0.0257\n",
      "Epoch 1804/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.8437e-04 - mse: 0.0488 - val_loss: 1.4657e-04 - val_mse: 0.0257\n",
      "Epoch 1805/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.6871e-04 - mse: 0.0461 - val_loss: 1.4852e-04 - val_mse: 0.0261\n",
      "Epoch 1806/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.7610e-04 - mse: 0.0469 - val_loss: 1.5085e-04 - val_mse: 0.0265\n",
      "Epoch 1807/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.6225e-04 - mse: 0.0447 - val_loss: 1.4623e-04 - val_mse: 0.0257\n",
      "Epoch 1808/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.4749e-04 - mse: 0.0423 - val_loss: 1.4637e-04 - val_mse: 0.0257\n",
      "Epoch 1809/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3399e-04 - mse: 0.0398 - val_loss: 1.4627e-04 - val_mse: 0.0257\n",
      "Epoch 1810/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.5610e-04 - mse: 0.0437 - val_loss: 1.5101e-04 - val_mse: 0.0265\n",
      "Epoch 1811/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.4995e-04 - mse: 0.0426 - val_loss: 1.4760e-04 - val_mse: 0.0258\n",
      "Epoch 1812/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.4868e-04 - mse: 0.0423 - val_loss: 1.4737e-04 - val_mse: 0.0258\n",
      "Epoch 1813/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.7371e-04 - mse: 0.0466 - val_loss: 1.5260e-04 - val_mse: 0.0267\n",
      "Epoch 1814/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.5840e-04 - mse: 0.0440 - val_loss: 1.4541e-04 - val_mse: 0.0255\n",
      "Epoch 1815/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.4900e-04 - mse: 0.0429 - val_loss: 1.4534e-04 - val_mse: 0.0254\n",
      "Epoch 1816/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.5369e-04 - mse: 0.0433 - val_loss: 1.4755e-04 - val_mse: 0.0258\n",
      "Epoch 1817/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.5178e-04 - mse: 0.0432 - val_loss: 1.4631e-04 - val_mse: 0.0256\n",
      "Epoch 1818/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3863e-04 - mse: 0.0408 - val_loss: 1.4746e-04 - val_mse: 0.0258\n",
      "Epoch 1819/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3553e-04 - mse: 0.0401 - val_loss: 1.4621e-04 - val_mse: 0.0256\n",
      "Epoch 1820/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.4681e-04 - mse: 0.0423 - val_loss: 1.4665e-04 - val_mse: 0.0256\n",
      "Epoch 1821/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.4363e-04 - mse: 0.0413 - val_loss: 1.4716e-04 - val_mse: 0.0258\n",
      "Epoch 1822/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.6360e-04 - mse: 0.0453 - val_loss: 1.4972e-04 - val_mse: 0.0262\n",
      "Epoch 1823/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.5573e-04 - mse: 0.0436 - val_loss: 1.4728e-04 - val_mse: 0.0258\n",
      "Epoch 1824/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3301e-04 - mse: 0.0398 - val_loss: 1.4829e-04 - val_mse: 0.0259\n",
      "Epoch 1825/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.5403e-04 - mse: 0.0433 - val_loss: 1.4844e-04 - val_mse: 0.0260\n",
      "Epoch 1826/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.5981e-04 - mse: 0.0445 - val_loss: 1.4646e-04 - val_mse: 0.0257\n",
      "Epoch 1827/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.8629e-04 - mse: 0.0490 - val_loss: 1.4697e-04 - val_mse: 0.0258\n",
      "Epoch 1828/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.5508e-04 - mse: 0.0438 - val_loss: 1.4669e-04 - val_mse: 0.0258\n",
      "Epoch 1829/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.6177e-04 - mse: 0.0448 - val_loss: 1.4543e-04 - val_mse: 0.0255\n",
      "Epoch 1830/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.6153e-04 - mse: 0.0451 - val_loss: 1.4488e-04 - val_mse: 0.0254\n",
      "Epoch 1831/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.6644e-04 - mse: 0.0457 - val_loss: 1.4838e-04 - val_mse: 0.0260\n",
      "Epoch 1832/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.5307e-04 - mse: 0.0433 - val_loss: 1.4410e-04 - val_mse: 0.0253\n",
      "Epoch 1833/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3021e-04 - mse: 0.0390 - val_loss: 1.5115e-04 - val_mse: 0.0265\n",
      "Epoch 1834/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.4724e-04 - mse: 0.0426 - val_loss: 1.4562e-04 - val_mse: 0.0255\n",
      "Epoch 1835/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.6373e-04 - mse: 0.0455 - val_loss: 1.4677e-04 - val_mse: 0.0257\n",
      "Epoch 1836/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.5742e-04 - mse: 0.0438 - val_loss: 1.5244e-04 - val_mse: 0.0267\n",
      "Epoch 1837/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.5118e-04 - mse: 0.0431 - val_loss: 1.4695e-04 - val_mse: 0.0256\n",
      "Epoch 1838/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.3845e-04 - mse: 0.0409 - val_loss: 1.4726e-04 - val_mse: 0.0257\n",
      "Epoch 1839/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.5991e-04 - mse: 0.0441 - val_loss: 1.5475e-04 - val_mse: 0.0272\n",
      "Epoch 1840/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.5680e-04 - mse: 0.0437 - val_loss: 1.4611e-04 - val_mse: 0.0256\n",
      "Epoch 1841/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3776e-04 - mse: 0.0406 - val_loss: 1.4490e-04 - val_mse: 0.0255\n",
      "Epoch 1842/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.4407e-04 - mse: 0.0421 - val_loss: 1.4836e-04 - val_mse: 0.0261\n",
      "Epoch 1843/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.4697e-04 - mse: 0.0418 - val_loss: 1.4762e-04 - val_mse: 0.0259\n",
      "Epoch 1844/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.4340e-04 - mse: 0.0418 - val_loss: 1.4659e-04 - val_mse: 0.0257\n",
      "Epoch 1845/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.4402e-04 - mse: 0.0417 - val_loss: 1.4867e-04 - val_mse: 0.0261\n",
      "Epoch 1846/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.5258e-04 - mse: 0.0431 - val_loss: 1.5149e-04 - val_mse: 0.0266\n",
      "Epoch 1847/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.4833e-04 - mse: 0.0424 - val_loss: 1.4775e-04 - val_mse: 0.0259\n",
      "Epoch 1848/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.2036e-04 - mse: 0.0376 - val_loss: 1.4780e-04 - val_mse: 0.0259\n",
      "Epoch 1849/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3201e-04 - mse: 0.0394 - val_loss: 1.4743e-04 - val_mse: 0.0259\n",
      "Epoch 1850/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.1500e-04 - mse: 0.0364 - val_loss: 1.4929e-04 - val_mse: 0.0263\n",
      "Epoch 1851/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3898e-04 - mse: 0.0411 - val_loss: 1.4829e-04 - val_mse: 0.0261\n",
      "Epoch 1852/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3895e-04 - mse: 0.0408 - val_loss: 1.4569e-04 - val_mse: 0.0256\n",
      "Epoch 1853/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3371e-04 - mse: 0.0400 - val_loss: 1.4858e-04 - val_mse: 0.0261\n",
      "Epoch 1854/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.6202e-04 - mse: 0.0450 - val_loss: 1.4707e-04 - val_mse: 0.0258\n",
      "Epoch 1855/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.1796e-04 - mse: 0.0370 - val_loss: 1.4539e-04 - val_mse: 0.0255\n",
      "Epoch 1856/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.2570e-04 - mse: 0.0386 - val_loss: 1.4684e-04 - val_mse: 0.0258\n",
      "Epoch 1857/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.2566e-04 - mse: 0.0385 - val_loss: 1.4754e-04 - val_mse: 0.0260\n",
      "Epoch 1858/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.2478e-04 - mse: 0.0383 - val_loss: 1.4829e-04 - val_mse: 0.0261\n",
      "Epoch 1859/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.2410e-04 - mse: 0.0382 - val_loss: 1.4570e-04 - val_mse: 0.0256\n",
      "Epoch 1860/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3024e-04 - mse: 0.0396 - val_loss: 1.4432e-04 - val_mse: 0.0254\n",
      "Epoch 1861/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.3709e-04 - mse: 0.0407 - val_loss: 1.4449e-04 - val_mse: 0.0254\n",
      "Epoch 1862/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3038e-04 - mse: 0.0395 - val_loss: 1.4566e-04 - val_mse: 0.0256\n",
      "Epoch 1863/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.9829e-04 - mse: 0.0337 - val_loss: 1.4669e-04 - val_mse: 0.0257\n",
      "Epoch 1864/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3197e-04 - mse: 0.0398 - val_loss: 1.4696e-04 - val_mse: 0.0258\n",
      "Epoch 1865/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3090e-04 - mse: 0.0396 - val_loss: 1.4872e-04 - val_mse: 0.0260\n",
      "Epoch 1866/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.2628e-04 - mse: 0.0386 - val_loss: 1.4853e-04 - val_mse: 0.0261\n",
      "Epoch 1867/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.2681e-04 - mse: 0.0387 - val_loss: 1.4635e-04 - val_mse: 0.0257\n",
      "Epoch 1868/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.2525e-04 - mse: 0.0383 - val_loss: 1.4792e-04 - val_mse: 0.0260\n",
      "Epoch 1869/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.5079e-04 - mse: 0.0430 - val_loss: 1.5019e-04 - val_mse: 0.0264\n",
      "Epoch 1870/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3284e-04 - mse: 0.0396 - val_loss: 1.4885e-04 - val_mse: 0.0261\n",
      "Epoch 1871/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.1888e-04 - mse: 0.0374 - val_loss: 1.4813e-04 - val_mse: 0.0260\n",
      "Epoch 1872/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1583e-04 - mse: 0.0369 - val_loss: 1.4906e-04 - val_mse: 0.0262\n",
      "Epoch 1873/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.1461e-04 - mse: 0.0367 - val_loss: 1.4654e-04 - val_mse: 0.0257\n",
      "Epoch 1874/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.2951e-04 - mse: 0.0394 - val_loss: 1.5616e-04 - val_mse: 0.0275\n",
      "Epoch 1875/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1315e-04 - mse: 0.0364 - val_loss: 1.4909e-04 - val_mse: 0.0261\n",
      "Epoch 1876/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.1531e-04 - mse: 0.0368 - val_loss: 1.4820e-04 - val_mse: 0.0260\n",
      "Epoch 1877/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.2992e-04 - mse: 0.0392 - val_loss: 1.4758e-04 - val_mse: 0.0258\n",
      "Epoch 1878/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.2982e-04 - mse: 0.0395 - val_loss: 1.4587e-04 - val_mse: 0.0255\n",
      "Epoch 1879/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.0932e-04 - mse: 0.0357 - val_loss: 1.4594e-04 - val_mse: 0.0255\n",
      "Epoch 1880/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.2466e-04 - mse: 0.0383 - val_loss: 1.4809e-04 - val_mse: 0.0259\n",
      "Epoch 1881/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.2457e-04 - mse: 0.0383 - val_loss: 1.4838e-04 - val_mse: 0.0260\n",
      "Epoch 1882/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.3925e-04 - mse: 0.0411 - val_loss: 1.6511e-04 - val_mse: 0.0289\n",
      "Epoch 1883/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3504e-04 - mse: 0.0405 - val_loss: 1.4796e-04 - val_mse: 0.0259\n",
      "Epoch 1884/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.0445e-04 - mse: 0.0351 - val_loss: 1.4774e-04 - val_mse: 0.0259\n",
      "Epoch 1885/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0399e-04 - mse: 0.0351 - val_loss: 1.5107e-04 - val_mse: 0.0265\n",
      "Epoch 1886/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0813e-04 - mse: 0.0356 - val_loss: 1.4705e-04 - val_mse: 0.0257\n",
      "Epoch 1887/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1477e-04 - mse: 0.0368 - val_loss: 1.4677e-04 - val_mse: 0.0257\n",
      "Epoch 1888/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1443e-04 - mse: 0.0368 - val_loss: 1.4789e-04 - val_mse: 0.0259\n",
      "Epoch 1889/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1594e-04 - mse: 0.0370 - val_loss: 1.4853e-04 - val_mse: 0.0260\n",
      "Epoch 1890/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0891e-04 - mse: 0.0354 - val_loss: 1.4486e-04 - val_mse: 0.0253\n",
      "Epoch 1891/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.0473e-04 - mse: 0.0352 - val_loss: 1.4474e-04 - val_mse: 0.0253\n",
      "Epoch 1892/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.1769e-04 - mse: 0.0371 - val_loss: 1.5108e-04 - val_mse: 0.0264\n",
      "Epoch 1893/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.1804e-04 - mse: 0.0372 - val_loss: 1.5287e-04 - val_mse: 0.0267\n",
      "Epoch 1894/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0598e-04 - mse: 0.0351 - val_loss: 1.4780e-04 - val_mse: 0.0258\n",
      "Epoch 1895/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1878e-04 - mse: 0.0374 - val_loss: 1.4755e-04 - val_mse: 0.0258\n",
      "Epoch 1896/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7961e-04 - mse: 0.0306 - val_loss: 1.4716e-04 - val_mse: 0.0257\n",
      "Epoch 1897/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.0221e-04 - mse: 0.0346 - val_loss: 1.4733e-04 - val_mse: 0.0257\n",
      "Epoch 1898/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9331e-04 - mse: 0.0331 - val_loss: 1.4648e-04 - val_mse: 0.0256\n",
      "Epoch 1899/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.3007e-04 - mse: 0.0395 - val_loss: 1.4577e-04 - val_mse: 0.0256\n",
      "Epoch 1900/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.9976e-04 - mse: 0.0339 - val_loss: 1.5735e-04 - val_mse: 0.0276\n",
      "Epoch 1901/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.9583e-04 - mse: 0.0333 - val_loss: 1.4891e-04 - val_mse: 0.0261\n",
      "Epoch 1902/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.1084e-04 - mse: 0.0360 - val_loss: 1.4796e-04 - val_mse: 0.0260\n",
      "Epoch 1903/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.0722e-04 - mse: 0.0356 - val_loss: 1.6153e-04 - val_mse: 0.0284\n",
      "Epoch 1904/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.0638e-04 - mse: 0.0353 - val_loss: 1.4558e-04 - val_mse: 0.0255\n",
      "Epoch 1905/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.9634e-04 - mse: 0.0333 - val_loss: 1.4704e-04 - val_mse: 0.0258\n",
      "Epoch 1906/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.0485e-04 - mse: 0.0350 - val_loss: 1.5104e-04 - val_mse: 0.0265\n",
      "Epoch 1907/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.9827e-04 - mse: 0.0338 - val_loss: 1.4924e-04 - val_mse: 0.0261\n",
      "Epoch 1908/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 2.0179e-04 - mse: 0.0347 - val_loss: 1.4910e-04 - val_mse: 0.0261\n",
      "Epoch 1909/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0014e-04 - mse: 0.0340 - val_loss: 1.4750e-04 - val_mse: 0.0258\n",
      "Epoch 1910/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.9900e-04 - mse: 0.0343 - val_loss: 1.4814e-04 - val_mse: 0.0260\n",
      "Epoch 1911/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 2.0265e-04 - mse: 0.0348 - val_loss: 1.4919e-04 - val_mse: 0.0262\n",
      "Epoch 1912/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9984e-04 - mse: 0.0342 - val_loss: 1.4816e-04 - val_mse: 0.0260\n",
      "Epoch 1913/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8021e-04 - mse: 0.0308 - val_loss: 1.4948e-04 - val_mse: 0.0263\n",
      "Epoch 1914/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.8683e-04 - mse: 0.0319 - val_loss: 1.4811e-04 - val_mse: 0.0260\n",
      "Epoch 1915/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.9178e-04 - mse: 0.0331 - val_loss: 1.4762e-04 - val_mse: 0.0259\n",
      "Epoch 1916/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7960e-04 - mse: 0.0307 - val_loss: 1.5196e-04 - val_mse: 0.0266\n",
      "Epoch 1917/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9388e-04 - mse: 0.0330 - val_loss: 1.4834e-04 - val_mse: 0.0260\n",
      "Epoch 1918/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9296e-04 - mse: 0.0332 - val_loss: 1.5073e-04 - val_mse: 0.0264\n",
      "Epoch 1919/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 2.0362e-04 - mse: 0.0350 - val_loss: 1.4715e-04 - val_mse: 0.0258\n",
      "Epoch 1920/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.9245e-04 - mse: 0.0330 - val_loss: 1.4676e-04 - val_mse: 0.0257\n",
      "Epoch 1921/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.9266e-04 - mse: 0.0329 - val_loss: 1.4730e-04 - val_mse: 0.0258\n",
      "Epoch 1922/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0151e-04 - mse: 0.0344 - val_loss: 1.4995e-04 - val_mse: 0.0262\n",
      "Epoch 1923/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.8785e-04 - mse: 0.0320 - val_loss: 1.4538e-04 - val_mse: 0.0254\n",
      "Epoch 1924/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7639e-04 - mse: 0.0303 - val_loss: 1.4515e-04 - val_mse: 0.0254\n",
      "Epoch 1925/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8904e-04 - mse: 0.0322 - val_loss: 1.4622e-04 - val_mse: 0.0255\n",
      "Epoch 1926/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0366e-04 - mse: 0.0350 - val_loss: 1.4852e-04 - val_mse: 0.0258\n",
      "Epoch 1927/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7898e-04 - mse: 0.0304 - val_loss: 1.4515e-04 - val_mse: 0.0253\n",
      "Epoch 1928/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8379e-04 - mse: 0.0314 - val_loss: 1.5513e-04 - val_mse: 0.0272\n",
      "Epoch 1929/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.9462e-04 - mse: 0.0333 - val_loss: 1.4515e-04 - val_mse: 0.0254\n",
      "Epoch 1930/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.9056e-04 - mse: 0.0326 - val_loss: 1.4577e-04 - val_mse: 0.0255\n",
      "Epoch 1931/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.1113e-04 - mse: 0.0362 - val_loss: 1.4572e-04 - val_mse: 0.0255\n",
      "Epoch 1932/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8280e-04 - mse: 0.0314 - val_loss: 1.4494e-04 - val_mse: 0.0254\n",
      "Epoch 1933/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8336e-04 - mse: 0.0312 - val_loss: 1.4765e-04 - val_mse: 0.0258\n",
      "Epoch 1934/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8711e-04 - mse: 0.0321 - val_loss: 1.4538e-04 - val_mse: 0.0254\n",
      "Epoch 1935/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8449e-04 - mse: 0.0315 - val_loss: 1.4680e-04 - val_mse: 0.0257\n",
      "Epoch 1936/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7950e-04 - mse: 0.0306 - val_loss: 1.4788e-04 - val_mse: 0.0258\n",
      "Epoch 1937/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6578e-04 - mse: 0.0283 - val_loss: 1.4769e-04 - val_mse: 0.0258\n",
      "Epoch 1938/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8990e-04 - mse: 0.0326 - val_loss: 1.4638e-04 - val_mse: 0.0256\n",
      "Epoch 1939/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.8967e-04 - mse: 0.0324 - val_loss: 1.5089e-04 - val_mse: 0.0264\n",
      "Epoch 1940/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8820e-04 - mse: 0.0322 - val_loss: 1.4738e-04 - val_mse: 0.0258\n",
      "Epoch 1941/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8661e-04 - mse: 0.0317 - val_loss: 1.4915e-04 - val_mse: 0.0261\n",
      "Epoch 1942/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 2.0388e-04 - mse: 0.0350 - val_loss: 1.4993e-04 - val_mse: 0.0262\n",
      "Epoch 1943/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6854e-04 - mse: 0.0286 - val_loss: 1.5203e-04 - val_mse: 0.0266\n",
      "Epoch 1944/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8227e-04 - mse: 0.0311 - val_loss: 1.5228e-04 - val_mse: 0.0267\n",
      "Epoch 1945/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7626e-04 - mse: 0.0300 - val_loss: 1.5397e-04 - val_mse: 0.0270\n",
      "Epoch 1946/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.7942e-04 - mse: 0.0311 - val_loss: 1.4951e-04 - val_mse: 0.0262\n",
      "Epoch 1947/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.7372e-04 - mse: 0.0297 - val_loss: 1.4948e-04 - val_mse: 0.0262\n",
      "Epoch 1948/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.7970e-04 - mse: 0.0307 - val_loss: 1.4912e-04 - val_mse: 0.0261\n",
      "Epoch 1949/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7717e-04 - mse: 0.0302 - val_loss: 1.4760e-04 - val_mse: 0.0258\n",
      "Epoch 1950/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8364e-04 - mse: 0.0314 - val_loss: 1.5113e-04 - val_mse: 0.0265\n",
      "Epoch 1951/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.5725e-04 - mse: 0.0267 - val_loss: 1.4691e-04 - val_mse: 0.0257\n",
      "Epoch 1952/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.6899e-04 - mse: 0.0290 - val_loss: 1.4951e-04 - val_mse: 0.0262\n",
      "Epoch 1953/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.6513e-04 - mse: 0.0283 - val_loss: 1.4829e-04 - val_mse: 0.0260\n",
      "Epoch 1954/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8912e-04 - mse: 0.0326 - val_loss: 1.4911e-04 - val_mse: 0.0262\n",
      "Epoch 1955/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 1.8526e-04 - mse: 0.0320 - val_loss: 1.5309e-04 - val_mse: 0.0268\n",
      "Epoch 1956/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8929e-04 - mse: 0.0326 - val_loss: 1.4681e-04 - val_mse: 0.0257\n",
      "Epoch 1957/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7168e-04 - mse: 0.0296 - val_loss: 1.4745e-04 - val_mse: 0.0258\n",
      "Epoch 1958/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.8537e-04 - mse: 0.0316 - val_loss: 1.4984e-04 - val_mse: 0.0262\n",
      "Epoch 1959/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8080e-04 - mse: 0.0311 - val_loss: 1.4675e-04 - val_mse: 0.0256\n",
      "Epoch 1960/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 1.8527e-04 - mse: 0.0317 - val_loss: 1.4755e-04 - val_mse: 0.0258\n",
      "Epoch 1961/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.8696e-04 - mse: 0.0319 - val_loss: 1.4899e-04 - val_mse: 0.0260\n",
      "Epoch 1962/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.5994e-04 - mse: 0.0273 - val_loss: 1.4837e-04 - val_mse: 0.0259\n",
      "Epoch 1963/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.6250e-04 - mse: 0.0279 - val_loss: 1.4907e-04 - val_mse: 0.0261\n",
      "Epoch 1964/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.6928e-04 - mse: 0.0289 - val_loss: 1.4942e-04 - val_mse: 0.0262\n",
      "Epoch 1965/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.7159e-04 - mse: 0.0294 - val_loss: 1.4681e-04 - val_mse: 0.0257\n",
      "Epoch 1966/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.8527e-04 - mse: 0.0322 - val_loss: 1.4491e-04 - val_mse: 0.0254\n",
      "Epoch 1967/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.6324e-04 - mse: 0.0278 - val_loss: 1.4863e-04 - val_mse: 0.0260\n",
      "Epoch 1968/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.6448e-04 - mse: 0.0280 - val_loss: 1.4685e-04 - val_mse: 0.0257\n",
      "Epoch 1969/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7931e-04 - mse: 0.0310 - val_loss: 1.4774e-04 - val_mse: 0.0258\n",
      "Epoch 1970/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7282e-04 - mse: 0.0295 - val_loss: 1.4860e-04 - val_mse: 0.0260\n",
      "Epoch 1971/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7618e-04 - mse: 0.0301 - val_loss: 1.4907e-04 - val_mse: 0.0260\n",
      "Epoch 1972/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.7438e-04 - mse: 0.0297 - val_loss: 1.4805e-04 - val_mse: 0.0258\n",
      "Epoch 1973/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7188e-04 - mse: 0.0295 - val_loss: 1.4957e-04 - val_mse: 0.0262\n",
      "Epoch 1974/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.6818e-04 - mse: 0.0286 - val_loss: 1.4781e-04 - val_mse: 0.0259\n",
      "Epoch 1975/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7842e-04 - mse: 0.0306 - val_loss: 1.4794e-04 - val_mse: 0.0259\n",
      "Epoch 1976/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6115e-04 - mse: 0.0278 - val_loss: 1.5194e-04 - val_mse: 0.0266\n",
      "Epoch 1977/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7327e-04 - mse: 0.0297 - val_loss: 1.5019e-04 - val_mse: 0.0262\n",
      "Epoch 1978/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7547e-04 - mse: 0.0298 - val_loss: 1.5107e-04 - val_mse: 0.0264\n",
      "Epoch 1979/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.6523e-04 - mse: 0.0281 - val_loss: 1.4854e-04 - val_mse: 0.0259\n",
      "Epoch 1980/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7282e-04 - mse: 0.0295 - val_loss: 1.4973e-04 - val_mse: 0.0261\n",
      "Epoch 1981/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.7742e-04 - mse: 0.0305 - val_loss: 1.4756e-04 - val_mse: 0.0257\n",
      "Epoch 1982/2000\n",
      "1168/1168 [==============================] - 0s 42us/step - loss: 1.6223e-04 - mse: 0.0277 - val_loss: 1.4988e-04 - val_mse: 0.0261\n",
      "Epoch 1983/2000\n",
      "1168/1168 [==============================] - 0s 40us/step - loss: 1.7644e-04 - mse: 0.0302 - val_loss: 1.5230e-04 - val_mse: 0.0265\n",
      "Epoch 1984/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.6247e-04 - mse: 0.0277 - val_loss: 1.5362e-04 - val_mse: 0.0268\n",
      "Epoch 1985/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.5184e-04 - mse: 0.0259 - val_loss: 1.5347e-04 - val_mse: 0.0268\n",
      "Epoch 1986/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 1.6963e-04 - mse: 0.0290 - val_loss: 1.5653e-04 - val_mse: 0.0273\n",
      "Epoch 1987/2000\n",
      "1168/1168 [==============================] - 0s 43us/step - loss: 1.5662e-04 - mse: 0.0266 - val_loss: 1.5104e-04 - val_mse: 0.0263\n",
      "Epoch 1988/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6949e-04 - mse: 0.0291 - val_loss: 1.4921e-04 - val_mse: 0.0260\n",
      "\n",
      "Epoch 01988: ReduceLROnPlateau reducing learning rate to 0.001125000009778887.\n",
      "Epoch 1989/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.5958e-04 - mse: 0.0274 - val_loss: 1.5019e-04 - val_mse: 0.0263\n",
      "Epoch 1990/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.6024e-04 - mse: 0.0273 - val_loss: 1.5116e-04 - val_mse: 0.0264\n",
      "Epoch 1991/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.5939e-04 - mse: 0.0272 - val_loss: 1.4996e-04 - val_mse: 0.0262\n",
      "Epoch 1992/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.5056e-04 - mse: 0.0256 - val_loss: 1.5038e-04 - val_mse: 0.0263\n",
      "Epoch 1993/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.7271e-04 - mse: 0.0296 - val_loss: 1.5131e-04 - val_mse: 0.0265\n",
      "Epoch 1994/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.5173e-04 - mse: 0.0260 - val_loss: 1.5092e-04 - val_mse: 0.0264\n",
      "Epoch 1995/2000\n",
      "1168/1168 [==============================] - 0s 37us/step - loss: 1.6796e-04 - mse: 0.0284 - val_loss: 1.5109e-04 - val_mse: 0.0264\n",
      "Epoch 1996/2000\n",
      "1168/1168 [==============================] - 0s 38us/step - loss: 1.8342e-04 - mse: 0.0313 - val_loss: 1.5373e-04 - val_mse: 0.0269\n",
      "Epoch 1997/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.6338e-04 - mse: 0.0280 - val_loss: 1.5224e-04 - val_mse: 0.0267\n",
      "Epoch 1998/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.4821e-04 - mse: 0.0253 - val_loss: 1.5272e-04 - val_mse: 0.0267\n",
      "Epoch 1999/2000\n",
      "1168/1168 [==============================] - 0s 39us/step - loss: 1.6128e-04 - mse: 0.0276 - val_loss: 1.5403e-04 - val_mse: 0.0270\n",
      "Epoch 2000/2000\n",
      "1168/1168 [==============================] - 0s 41us/step - loss: 1.5559e-04 - mse: 0.0266 - val_loss: 1.5435e-04 - val_mse: 0.0270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc294064eb8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lrr = ReduceLROnPlateau(monitor = 'val_mse',\n",
    "                         patience = 200,\n",
    "                         verbose = 1,\n",
    "                         factor = 0.75,\n",
    "                         min_lr = 1e-4)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   mode='min',\n",
    "                   verbose=1,\n",
    "                   patience=500,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "model.fit([num_data_train, cat_train_x.values],\n",
    "          train_y.values,\n",
    "         batch_size=128,\n",
    "         epochs=2000,\n",
    "         verbose=1,\n",
    "         validation_split=0.2,\n",
    "          shuffle=True,\n",
    "         callbacks=[es, lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(history):\n",
    "    plt.plot(history['mse'])\n",
    "    plt.plot(history['val_mse'])\n",
    "    plt.title('MODEL MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.ylim(top=.1, bottom=0.01)\n",
    "#     plt.savefig('history_mse_{}.png'.format(n))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgU1dn38e89MzCssrsAKhCNCiqC474EQjTuSKIRTB6J8sRoYnx8jTGauBBjTDRGE6NJ1GhUjCJxJW64L7gyIMiiLCLoALLv2zAz5/2jqpma7uqe7pleprt/n+vqq6tOVXXfNNN19zmn6hxzziEiIhKtJNcBiIhIy6QEISIioZQgREQklBKEiIiEUoIQEZFQShAiIhJKCUJEREIpQUjBMrNFZlZtZt2jyqebmTOzPoGyo83sNTPbaGbrzey/ZtY/sH2ImdWZ2Sb/UWVmE8zssKjXdma2ObDfJjO70t821sweTjJ2Z2bLzawsUFZmZivMzAXKBpjZS2a21szWmdlUMzslTsyRx1GpfZJSrJQgpNB9DoyKrJjZQUDb4A7+CfMl4BmgJ9AXmAG8Y2b9Arsudc51ADoCRwKfAm+b2bCo9xzonOsQeNzSxNjXAScH1k8B1kbt81/gZWA3YFfgUmBDdMxRj/eaGI8UGSUIKXTjgPMC66OBh6L2uQV4yDn3F+fcRufcGufcNcD7wNjoF3SeKufcdcA/gZszE3pM7OcRiN2vGfUF7nXOVfuPd5xzkzMUjxQZJQgpdO8Du5jZAWZWCpwD7GzmMbN2wNHAf0KOnQCc0MjrPwkMNrP2aYo36GngeDPrbGadgePwajkRq4EFwMNmdqaZ7ZaBGKSIKUFIMYj8Ej8Br1loSWBbV7zvwbKQ45YB3UPKg5YCBnQOlE3z+wMij283Me5teE1I5wAjgYl+GeDVZIChwCLgT8AyM3vLzPYNvEbPqFjWZSiZSQEqa3wXkbw3DngLrzkmunlpLVAH7IGXPIL2AFY18tq9AIfXXxAx2Dm3oMnRNvQQ8Hu8JPTL6I3OuSrgEgAz2xO4xz8m0hG91DnXO02xSJFRDUIKnnNuMV5n9Sl4TULBbZuB94CzQw79HvBqIy8/Apjmv04mvI2XqHYDEvYtOOe+BO4CDsxQLFJkVIOQYjEG6OKc2xy8dNR3FTDJzD4F/oX3vfg53q/ww6L2xcwM72qn//UfZ6QQR4mZtQmsO+fc9ng7O+ecmZ0eWA7G0QW4DK+GtBCvuewCvH4XkWZTDUKKgnPuM+dcZZxtk4FvA9/B63dYDAwCjnXOzQ/s2tPMNgGbgCnAQcAQ59xLUS85I+q+gz8Hto0CtgYenyUR+2zn3OyQTdVAH+AVvEtbZwHbgR9Gxxz1+G5j7ykCYJowSEREwqgGISIioTKaIMzsJDOba2YLzOyqkO3Hm9k0M6sxs7Oito02s/n+Y3Qm4xQRkVgZa2Lyb0qah3fteRVem+0o59ycwD59gF2AK4CJzrnH/fKuQCVQgXcJ4VTgUOdc9DADIiKSIZmsQRwOLHDOLXTOVQPjgeHBHZxzi5xzH+Ndhx70beBlf8iDtXhjzZyUwVhFRCRKJi9z7QV8GVivAo5oxrG9oncyswuBCwHat29/6P7779+0SCX/rF4A2zdCq3awYwt07QdtOuU6KmmBZi5ZH1M2oOculAQuGS5mU6dOXeWc6xG2LZMJIuzTT7Y9K6ljnXP34N05SkVFhausDL2KUQrRuBHw2WvQqwKWVML3boX+wxs/TopOn6ueiyl7Y+yJ7NKmVQ6iaXnMbHG8bZlsYqoC9gys98YbtybTx0ox+Ow177l6k/c8ZyLMfzl38Uheqa3V5f3JyGSCmALsa2Z9zaw19YONJWMScKKZdfHvFj3RLxNpaIP/u2HW4/DvsxLvK+LbURfd7SlhMpYgnHM1eIOITQI+ASY452ab2Q1mdgaAmR1mZlV44+DcbWaz/WPXAL/FSzJTgBv8MpGGdmzNdQSSh7ZVK0EkI6NjMTnnngeejyq7LrA8Ba/5KOzY+4H7MxmfFAI1FUjqRt37Pu9c9U127NhBVVUV27Zta/ygPNemTRt69+5Nq1bJ971osD7Jb6Wtoa4m11FIC3b813vw1ryVDcqWrPNqnlVVVXTs2JE+ffpgBXxVk3OO1atXU1VVRd++fZM+TkNtSH4z/QlLYveNrmDODeFzNm3bto1u3boVdHIAMDO6deuWck1J3y7Jb0oQ0ohWpSW0a13Gw2PCb8Mq9OQQ0ZR/p75dkt+UICRJx+4bO3tsbZ1DI1rHp2+X5Keeg73nktLcxiF56+OqdSxbv401m6tzFsPq1as55JBDOOSQQ9h9993p1avXzvXq6sRxVVZWcumll2Y0PnVSS3769u/gXyerBiFNNm/5JjoBW6pr6ZajGLp168b06dMBGDt2LB06dOCKK67Yub2mpoaysvDTdEVFBRUVFRmNT98uyU+RxKAEIU1UV9cym5Z++MMfcvnllzN06FB++ctf8uGHH3L00UczaNAgjj76aObOnQvAG2+8wWmnnQZ4yeWCCy5gyJAh9OvXjzvuuCMtsagGIXnK73AzNTFJ8m773kAunzADgFq/7yHSdfub/85mztINaX2//j134frTB6R83Lx583jllVcoLS1lw4YNvPXWW5SVlfHKK6/wq1/9iieeeCLmmE8//ZTXX3+djRs3st9++3HxxRendM9DGCUIyU+RmoP6ICQFe3drv3N5zeZqupcTPjRojp199tmUlnp/2+vXr2f06NHMnz8fM2PHjh2hx5x66qmUl5dTXl7OrrvuyvLly+ndO/Q+5KQpQUh+2tm01AK/3dJilZXU/71s2LoDyuv/gprySz9T2revT2TXXnstQ4cO5amnnmLRokUMGTIk9Jjy8vKdy6WlpdTUNP8GUjXgSn7aeU13y2xHlpapNJAg7n5robfQwu+DWL9+Pb16edPhPPDAA1l9byUIyU+RL7WuYZcUhOWClp0e4Morr+Tqq6/mmGOOoba2NqvvnbE5qbNNEwYVmWUz4O7jYZdesGFJffnY2NnDRCLmLN3AKXe8vXP93jP24MD+B7BH57Y5jCp7PvnkEw444IAGZWY21TkXer2sahCSnyJ9EE7DNkvySsLOeC29CpFDShCSp9TEJKkrDWljUn6ITwlC8tPOq5iUICR54QPWKUXEowQh+UlNTNIEJWGd1MoPcSlBSH7SVUzSBB3a6NavVChBSH5SE5M0wa4d28SUqQIRnxKE5KedTUxKENJMOcwQQ4YMYdKkSQ3K/vznP/OTn/wk7v7ZvJxfCULym/ogpJkshxli1KhRjB8/vkHZ+PHjGTVqVI4iakgJQvJTsInpwO/mNBSRpjrrrLN49tln2b59OwCLFi1i6dKlPPLII1RUVDBgwACuv/76nMWnHhvJTzubmFAzkzTLzquYXrgKvpqZ3hff/SA4+Q9xN3fr1o3DDz+cF198keHDhzN+/HjOOeccrr76arp27UptbS3Dhg3j448/5uCDD05vbElQDULyU4PB+pQgpOly3UkdbGaKNC9NmDCBwYMHM2jQIGbPns2cOXNyEptqEJKfgp3U6oeQZti6wx8AL8Ev/Uw688wzufzyy5k2bRpbt26lS5cu3HrrrUyZMoUuXbrwwx/+kG3btuUkNtUgJD8Fb5RTE5M0w5rN1Tl9/w4dOjBkyBAuuOACRo0axYYNG2jfvj2dOnVi+fLlvPDCCzmLTQlC8lSgiUk1CEnBW78YmusQYowaNYoZM2YwcuRIBg4cyKBBgxgwYAAXXHABxxxzTM7iUhOT5KdgE1NddsfIl/y2V7d2uQ4hxogRIwhOvRBvYqA33ngjOwH5VIOQ/BRsYqpr/tSKIhJLCULyU/AqJiUIaabaOvVjhVGCkPzUoIlJCUJS17ldKxwO5xzVNbUFnySaMnuo+iAkPzWoQagPQlIzc+yJbN5ey3/fmU63bhuYtxzatCpjv9075jq0jHDOsXr1atq0iR2sMBElCMlTkeG+62CvI+CLd3MbjuSVjm1aUVvn+OsHa/kZsHfnVRhG3drCnZu6TZs29O7dO6VjlCAkPwWbmIZeA6vmw/yXchuT5BXD2LC9jt+9tXpn2aI/nJrDiFoe9UFIfgoO1ldaBj320/0Qkppcj7GRB5QgJD/FzBNpShCSEk012jglCMlPVhK7riE3JAXKD41TgpD8FJYgcEoSkjRTFaJRShCSp6K+3JqCVFKk9NA4JQjJTzE1iMBlryJJUAWicRlNEGZ2kpnNNbMFZnZVyPZyM3vM3/6BmfXxy1uZ2YNmNtPMPjGzqzMZp+SheAlCkwdJksLmon5r3socRNJyZSxBmFkpcBdwMtAfGGVm/aN2GwOsdc7tA9wO3OyXnw2UO+cOAg4FfhxJHiJA7M+/4OB9IklwIT8mnpm+NAeRtFyZrEEcDixwzi10zlUD44HhUfsMBx70lx8HhpnXc+SA9mZWBrQFqoENGYxV8o0ShDRTWHfVE9Oqsh9IC5bJBNEL+DKwXuWXhe7jnKsB1gPd8JLFZmAZ8AVwq3NuTfQbmNmFZlZpZpUrV6pqWNzUByGpKStVJ0RjMpkgwj796Jwdb5/DgVqgJ9AX+LmZ9YvZ0bl7nHMVzrmKHj16NDdeyWe6iklSVF5Wyh/POjjXYbRomUwQVcCegfXeQHQD3859/OakTsAa4FzgRefcDufcCuAdoCKDsUq+6rG/96wmJmmCsyv2jCnrc9VzvKnOaiCzCWIKsK+Z9TWz1sBIYGLUPhOB0f7yWcBrzhu0/Avgm+ZpDxwJfJrBWCUf/e9rcL4/obsShDRR9w7lMWUT1VkNZDBB+H0KlwCTgE+ACc652WZ2g5md4e92H9DNzBYAlwORS2HvAjoAs/ASzb+ccx9nKlbJU70PhXZdvWXdByFNdNOIA2PKOrdrlYNIWp6MDvftnHseeD6q7LrA8ja8S1qjj9sUVi4SV/R9ESJJChty47OVm3IQScujb5UUBjUxSROFTTX6xlz1QYAShBQKNTFJEzVlruZioQQhBUIJQpqmVgkiLiUIKQy6D0KaKKyJSTxKEFIY1AchTVSnHxVxKUFIYVCCkCaq059MXEoQUhjUSS1NpD6I+JQgpDDsvA9CX3ZJTZ36IOJSgpDCoCYmaaJhB+wWOtyGKEFIodBVTNJEPTqWU3nNt2LKdX+EEoQUDPVBSHr1vfp5Fhb5kBtKEFIYdnZS61efpM+cZcU9kaUShBQG9UFIM/3PkXvHlJWGDORXTJQgpDAoQUgznXVo75iy0hIlCJH8p/sgpJnCkkGxz1utBCGFocSf2qRuR27jkLwV1ppUWlLcp8ji/tdL4WjV1nu+Zwh89HBOQ5H8VBKSIeYv35iDSFoOJQgpDGVt65ef+Sl89lruYpG8FJYgbnzukxxE0nIoQUhhaNWm4fq4EbmJQ/JWqc6GMfSRSGEo3yXXEUjeK+4O6TBKEFIYuvSJLauqhAmjoWZ71sOR/BPvitZZS9ZnN5AWRAlCCkNJaWzZO3+BOU/D3OezH4/knbA+CIDT/jo5y5G0HEoQUrjadfWet6zJbRySF1qX6XQYTZ+IFC7zaxW6eU6S0LNzW24acVCuw2hRlCCkcEWandQHIUkaedieuQ6hRVGCkMIVqUHUbMttHJI3inxsvhhKEFKYrKT+264ahCTJ/L+Z6JFdl63fmotwck4JQgqTlUKtPy6TahCSgkV/OJVfnXJAg7Kjfv8aE2cszVFEuaMEIYXjwjfrl0tK6wfuU4KQFLUKGcX10kc/ykEkuaUEIYWj5yH1y6pBSDOUxRl34y+vzC+quaqVIKQwlZQFEoT6ICR1++/eMabs9lfmsXJT8fw9KUFIYXJ1sPB1b3lHcXYwSvN8P2QK0mJTlusARDKieqP3ACUIaZJ481HHG5KjEKkGIYVvx5ZcRyB5KN7gfcWTHpQgpBgoQUgTfL5qc2h58XRRK0FIoTnqktiyaiUISV1JnCpEXV3xpAglCCksJ94Iu/RqWKYahDRBeZzRXYsoPyhBSIExg7qahmVKEJJGdboPQiSPRe5/iFATkzRBvJqCEkSamNlJZjbXzBaY2VUh28vN7DF/+wdm1iew7WAze8/MZpvZTDNrE328SKjS1g3Xa7ZCneaEkPT46It1uQ4hazKWIMysFLgLOBnoD4wys/5Ru40B1jrn9gFuB272jy0DHgYucs4NAIYAUT8LReLY++jYsm3F86WWNIlTU/hZEY3JlMkaxOHAAufcQudcNTAeGB61z3DgQX/5cWCYeePtngh87JybAeCcW+2cq81grFJIht8VW/bOX7Ifh0iey2SC6AV8GViv8stC93HO1QDrgW7A1wFnZpPMbJqZXRn2BmZ2oZlVmlnlypUr0/4PkDzVul1sWXnsuDoiiRRPT0N8mUwQYRcRR3/m8fYpA44Fvu8/jzCzYTE7OnePc67COVfRo0eP5sYrhUwJQlJURH3RcWUyQVQBwQleewPRM27s3Mfvd+gErPHL33TOrXLObQGeBwZnMFYpdBryW1Lk/N+zlwzdJ3ZbkWSPTCaIKcC+ZtbXzFoDI4GJUftMBEb7y2cBrznvk58EHGxm7fzE8Q1gTgZjlUJz0WTv+eCR3rOG/JYUnVOxF907tOacw/aM2TZn2YYcRJR9CROEmf0gsHxM1LaQMQ3q+X0Kl+Cd7D8BJjjnZpvZDWZ2hr/bfUA3M1sAXA5c5R+7FrgNL8lMB6Y5555L5R8mRW73g+DS6TD8Tm9uiEQ1iMp/werPsheb5IW9urWj8poT2LNrbJ/WqXdM5oF3PmfN5uocRJY9lqiqZGbTnHODo5fD1nOtoqLCVVZW5joMaYlu6gWDR8NJN8Vuq6uDG7pAu+5wpZKEhOtzVfjv0+P27c64MUdkOZr0MrOpzrmKsG2NNTFZnOWwdZGWqaw8fg3C+TfQbVmVvXgk7/Tu0ja0fNWmwq5BNJYgXJzlsHWRlqmsTcM+iFdvgMXvestOd1hL47p1KA8tL/SRXRubUW5/M/sYr7bwNX8Zf71fRiMTSZfoGsTbf/IeY9crQUhS2rYK/y1dW+BXMzWWIA7IShQimVTWpvEmJpEmKOoahHNucXDdzLoBxwNfOOemZjIwkbQpK69vYooZtK+wv+CSHhany7XQaxCNXeb6rJkd6C/vAcwCLgDGmdllWYhPpPmCNYjouSJUg5AUHLp3lwbrNbVFnCCAvs65Wf7y+cDLzrnTgSPwEoVIyxfspFaCkCYwvwJxUK9ODcoL/Y7qxhJEcIjtYXhDXuCc2wjomyX5IVM1iLo6mPUE1Gmg4WJRYg2bmoq6iQn40sx+ZmYj8MZCehHAzNoCrTIdnEhaNOiDiE4QzfiCT38YHr8Apvyz6a8heaUkqiuitsA7qRtLEGOAAcAPgXOcc5FZV44E/pXBuETSp6yNN6tcbQ0sfKPhtuYkiE0rvOeNy5r+GpIXIhWHkqgMsWpTNXOWFu64TI1dxbQCuCik/HXg9UwFJZJWZa2hphpevxEm395wW3OamCJnjQJvZpB6FnIx04PvLmL00X3o16M9bVqVZj+oDEqYIMwsevTVBpxzZyTaLtIilPo3yn35Yew2dVJLCqL7IABen7uCxyq/LIhxmaI1dqPcUXgzvj0KfIDGX5J8VFYOtdWxyeDLD6FT7FDOyYt8HVSDKBZhfQ4rNnr9W2/PL7zxvBpLELsDJwCjgHOB54BHnXOzMx2YSNqUlcOOLWBR1f+abWpikpRs3l7T+E4FJGEntXOu1jn3onNuNF7H9ALgDTP7WVaiE0mHZf4QYosnNywva9PMJibVIIrF70cczBkDe3LZt76e61CyqrEaBGZWDpyKV4voA9wBPJnZsETSaOva8PKSUpp1clcNomjs1a0dd4walOswsq6xTuoHgQOBF4DfBO6qFskfrcLH8mfLWmjTuX597SLo0ieFF1aXnBS2xmoQ/wNsBr4OXGr1PfgGOOfcLhmMTSQ94iWIf38Xeh9Wv/6XgXDtKihN8h5Q1SCkwDXWB1HinOvoP3YJPDoqOUjeKGsTf1vVlIbrwYmFGmP+1yeVfoztm+CLD5LfX1qcJy4+ijZx5ocoNMXxr5TilihBRKtNZQpJvwZRvSn5Q54YA/efCFvWpPA+IT5/G6q3NO81pEkO3bsrM64/Me40pBHrt+5IuD0fKEFI4dt1/+T3vaUv7Nia3L6RJqaPxkFtkieDZTO852TfI8zaRfDgafDfS5v+GtIs5WWlPP3TY2LKx723CIDZS9cz8Dcv8fRHS7IbWJopQUjhOyZq6pKLJofvF7H6s9TfI+maRxo6trf5Y/+s+KT5ryVN1qok9vR57TPeLWKz/fGZJi/I75vnlCCk8JVE3SBX0kgndG2y/RCBk310R/WMx2BsJ9i8OuqYdHZo6yqqXArJDztF5omIHv013yhBSHE55rLGr1KqSbI2EDZyW8SH93jPaxamfqzkvVr/uoWwsZvySaM3yokUhG/fBF36wv6nwNrFiffdEv2rP8rk26HfUBL+go9c2RTvBKFLY/Ne21aldGnXirVbYvuf6vz/X8vzBKEahBSHo37qJQdovAaxYWni7a+MhXu+0fDkH3Opq58AYk4Q6ThhKLm0BGWlJXx03Ykx5fdP/nxngijN8zOsahBSfKL7IEpbR3UyN+EEHJ0gdq5n8Bdkfv84LVg3PDuH4/btDoDl+X9Snuc3kSaI7rRuv2vD9eDJfv0S+Oy1wLZA8khUg3DxahA7d/CedmyDdV80GnLoa0uLtXJjCjdctmBKEFJ82nRquL6hquF6XW398r1DYdwIWDIN7j4eZj9Vvy3hZaaRk7jBppX1N8ZFJ4wnxsCfD2r4nknL71+nhWZg7/q/qw3+TXLj3l/MBwsb6dNqwZQgpPiUlMLRUTeZnRaYirQu0Om4abn3fO9Q7ya3x8+v3xYcJTamBuE/Wwncuo93A16YeS/675lKglANoiW6dNi+O5eXrt+2c/mce94HvKlJV2zYFnNcS6YEIcVp2HUN1/c5oX65LslJYYITEMXrg7Cor1g6m4fy/AqZQpNoPurFqzdz/cTZ/PjhqVmMqPmUIKQ4lbaCnoPr18vK65eXToeZjzc+XlJJ4BqPYIKorYHNK7zlpE/iqhXku/Ky+KfTHf6NEfk2PpOuYpLi1b57/XIwQXz6rPcobZ34+GBnd7Bm8OIvYfNKfyWQILZvCgwRHnWVU7NmtpOWoHWCBDF1sdccmW83zqkGIcVr+N+85857Q1nIyJyNja8UbD4KnuA/+W9gp0DiuPu4QLFruD2VpiddxdSi3DFqEIP36pwwQcxa4o3NlF/pQQlCilmHHnDJVPjxm1DWGk6+JbXjIx3M0DBBBE/gb91av7xmIWzym57mvxT1Yk056TfzdLN9U/LDikhcZwzsyZM/OYZWCe6KG/e+d/e+Gbw5byVTFjVzuPcsUYKQ4tZ9H2jbxVs+4sepHRu5wgniNxHNjpq+PXKF1Af/8Aty2MT0+17e3BSSFq2TuG3aMEbf/yFn/+O9LETUfEoQIukQvJkuGdHNRLlqNlr6UW7etwAl6qSOyLMuCCUIkbR49rLG90kkpRqE+iBaokR9EBH5NnifEoRI0Fn/ytIbRZ3k1zUywmyYPDvZFLqkEkQW4kinjCYIMzvJzOaa2QIzuypke7mZPeZv/8DM+kRt38vMNpnZFZmMU2Sn3hUN10fcnZn3iW5Suvv4FI5NbyiSHsn0QdQF/t+H3/UOP3qoMpMhNVvGEoSZlQJ3AScD/YFRZtY/arcxwFrn3D7A7cDNUdtvB17IVIwiMco7Nlw/4IzcxJGUfPs9WtjKkkgQn361cefyjC/X8fKc5Qn2zr1M1iAOBxY45xY656qB8cDwqH2GAw/6y48Dw8xvpDOzM4GFwOwMxijSUNsucOGb9eutQu6PuHY1fP3k+K8RuYs6oeZUAzJYhdi2AeY8k7nXL0LJ1CxaqkxG3gv4MrBe5ZeF7uOcqwHWA93MrD3wS+A3id7AzC40s0ozq1y5cmWiXUWS1/MQGHiuN16TWcNxmvYYCKVlMOSXscdtXA5TH0juPVK5amnHtszfr/D3Y+GZS+Dpi2HCebBqfmbfr4hccGycgRoDZlat3zmPdUuSyQQRVv+N/gTi7fMb4Hbn3KZEb+Ccu8c5V+Gcq+jRo0cTwxQJMeLvcNzPveVzxkHFBd7yD/zhvktCRqlZvQD++3/Jvf66xd4Q4nVRY/M4Fzuy6+92gzsPjX2NsE7qHVvhpWugenNycUQsnwkfjavvLN+xJbXjBYBxYw7n7SuH8vRPj6FPt3YAtCpN3BT4ypzlnH7nZP5TWZVwv1zIZIKoAvYMrPcGoudy3LmPmZUBnYA1wBHALWa2CLgM+JWZXZLBWEXia9UWTr3Na1pq380rC/tFv21daq87YXRs2fNXwA1dY8sTTSpUVwufPucllw/vgXf/Cu/ckVos0Vrgr9l8cNy+PdizazsO2bMzP/7G1wDo0619wmM+X+Ul87nLNybcLxcymSCmAPuaWV8zaw2MBCZG7TMRiHxLzgJec57jnHN9nHN9gD8DNznn7sxgrCKJmXlNSxE1W2P32ZxiM+f6kJP+lH96z7UpjPr5/t9g/LneXduR8aOiaybpsHm114wmSRl52J6Mv/BITh/YM+F+Lflq5YyN5uqcq/F/9U8CSoH7nXOzzewGoNI5NxG4DxhnZgvwag4jMxWPSFrtdXRs2QsxV3InZiUNb5Cb+mD98vaN0C6kJgGxv+7X+00Tm5LpHG+GP/bznseuz+z7FAgz48h+3airS6421hIrbRkd7ts59zzwfFTZdYHlbcDZjbzG2IwEJ9IcJSGV77BaRcLXaAW1gbmL/xuY5a56U/wE8fF4fyEyjlMGzizrv/Q66yN9Ga0TN5NIfCUlLbiK0Ij8vf5KpCXoORiuaeIVdLUJJrb/z/mwdhF8Nau+bMdWr7YQaYaKEXIiWjK1aQnksR94zzf19B6SMTc+581t7lrgHZBKECJNdc1KGPOyN1R4WZv0vvaSSnj+yoZXIz06Cm4f0HC/sZ3hwzh3ey98E+79Jrz/9/TGpktgi4YShEhTlbWu77ge9SgMuz69r19S1rAHc+HrDbcvn03smE6BW49WfrTDxFQAABMiSURBVOo9v3RN7Gu/9rv65WDfRzI+npDa/pIUC9QAnXNs3p7k3OgZpAQhkg5f+yYcd7nXgfv/5sAVC9L0wgnar8P6PKb5J/t1X8ILV3rLrjZ2v8m31y8H+z40fEdG/PbMA/nZN/fZud6+dWnMPo9Nqb+qbULllwy4ftLOS2BzRQlCJN069fJmq2uuuc/BhP+Jv92ivr4rAqPSzGzkV35pq6bH9dYtLfOSmxbsf47cm5+fuN/O9atPOSBmn83V9Yl80mzvcuKFKxPeK5xxShAimXLSH5r/GhuXxd8WPYfEtIeSf91k7pRenGDWs5oEHezSqHMP3yu0fEdtHbOWrOe1T71Llpeu38aCFbm7gU4JQiRTjrwYDjzLW/7JB3DOv2nxTThbA3eDL54cf7+6JraPV02FFZ807dgCUlJi/PGsg2PK9/31C5z21/rP/dqnZ/Gt297KZmgNKEGIZNJZ98H162DX/eGA02DsupZ9o1nw7u7Xboy/X22SgwdWb4Eta+rX//lN+NuRTYutwJxdsSeL/nBqrsNISAlCJNPCxlI49bb0v0/YAIJh0tF/EFaDqKuLHWjw3qFwS+OjmcZ/n1oY26nhVVeSNUoQIrmw74npf81ECWLWk/XLD6VhEqSwGsQDp8YONBi51DbakmnJvU8kEb3z5+Rjk7RRghDJhc57Nr5PqhIliMfPh0fP9SYE+jwNbdphgwl+8W7yx987FOZNany/Arta6oNfDePtK4fmOoykKUGI5Epw5rp0qG7kksi5z8FzlzfttZ/+acP16CamlXNTf801C8PLnYOvZnpNSwU2u91uu7Rhz67tQrc9dmH8vpkXZy1j3HuLMhNUAkoQIrnS8xA48++w5xHe+uhnM/+eM//TtOOmP9xwPboGEbxs9t2/eif3pv76f/9v8I9jveVULt3Nc13at4677aKHp3HtM7N5+P3FfLE6e5M5KUGI5NIh58KYl7wrm/oeB5dOz3VEyfn7UXD3N7yO6Yk/azio4Mv+kCML32jaawebnqLv9ShgZUmM+nrN07MYde/7WYjGowQh0pJ07Qu/+CzXUSRn2XRY+7n3K39iYMLHVm2953FnNvICBts3ebWNmY97Rds3weJ36ncpqgSR3Ol43ZbqBsuvfpK5SZyUIERamvbd4ZoVcMV8+M69sSPF9m/sxAu07ghlbTMTX2OSHdnWrH6yozf8u86f+UnD/o3tG9IbWwtWU5dcMgwOyfGjhyoZ82Blg6SRTkoQIi1RWTl02BUO/h5cE/iFeN4z8L0HoevXEh8/6hHoOSizMYLXmRwt3tVU26JuEJw3Cf7m97+sng9P/KhhUxXEDgny1UxYnSc1rBS1a538/G1XPzmTaV+sZeFKbzC/miRnrUtVRmeUE5E0uegd+Opj6DfEWz/t9vD7GY6+1EsMfY+H3Q+G2w5IbtylpvrP6Mb3ifhD1PhDn73acH3mhNgBCHc2Mfnt85HO67HrvQmVrDQzlwxn0V9GHsKKDdvZvVMbbvveQH7+nxmN9u8/+uEXPPrhF3Rp5w26WJehy4GVIETywe4Heo+Ift8I3+9bY6HEH0q6bWdvGPJPs3B1VFDYnePJKm0NNdvq12v95qbaaq+vIugvA73nljx0SRKGH9Jr5/J3BvfmxAG78+S0Km589hOqaxM3O63d4l1NVlObmQShJiaRfHXpdBgRmE1u2PX1ySGiz7HZjQm88Zeivf2n5I6NrkFsXOovZOAEWL05tkkLvJn75r2U/vdLUofyMs47qg8d2yT/+10JQkQa6toXBo6Eob+Gw3/sTVgU7bD/rV/u0owxkVKxPeQX/as3JHdsss1hv0thnuyaam948nmTvDGdZj/llU84D/5xjHd3eWQokro6mPs8PHJ2cq+9dR18+nzysQTNmehNCxtHaRKXvUY0VtNoKjUxieS7b1wZf1tpK/jeOO8y1AsmQcfdYOl0uCdOE1W+2BGYaW3R5IY1Jefgtd/CoB9A135w2/6wZXXD4weMqB9y5Pkr4OPHoMNu0LsitTie+F9Y8LI3i2CnXo3vHxSZDGrseti61ktUXfbeuTmVBJHsFVCpUg1CpND1PwOu+sJLDuDdwT12vTct6o/fbrhvn+PgJ9m7ESst1nzuPU9/BO46whvC4+0/wR2DvKueopMDwMav6jvAIwMKrprrNTulYvV87znYb9IUdx0Jf2k4P8TXd+uY9OGZamJSDUKkWHXo4T2uW+PdnNbnuPoO5qMvhXfvyG18yZp4iddp//TFsdv+EacP5k/7sfPKqGUzvOdn/5/3iKirje3TiRa5eijVjvnoYdE3fRWzy1/PHcS0xWt5/dMVPPje4oQvt3j1Fg7s1SnhPk2hGoRIsSsp9S6LDZ7kTrgBTv5j7mJK1fRH65f/OjjJgxr51f3ajV6fBMA7d8Bvd/Xuwdi0MvASjbxGTXXskCM11Q2HRY/cLBi0ci67bF3CkP12pTbqPe4bXcFuu5Tzm7J/cVTJbPay5fzfIx8mjqOJVIMQkVhmcMSF8PF4WDI119E07o2b0v+ak2/zHifdDC9f65VFks+1q7z+nUiSiVyOW1cLn7/pXV4M8PRFMOsJ+NHr0Ms/dkdUM1Zw7KnaHd6d5Hcd7q1fMpXrZgyjtvQHdOixF5v3HsawA3bjTzvWc+yTLzOalwF4vXYgMDyt/3xQDUJEEhn5KBxwOpxxp7de1ga67wfnvxD/mA67Zye2bJkfcsnr7/aAKffV1yDqdsDSj7yawbgR3kl/fZWXHMCb/2KxP19G9HwcwSHYf9sdfhf4/O48lNZuO79vdR+/Xnc9N404CN69k2OfPKzBS7xUl2LnepLMFciEHBUVFa6ysjLXYYgUj2Ufe3dDvzK2YflF73hXBL10jVcDiShrCzVb4ZJKuNM/oXX9GqwpgKEzTrgBJt/uXY2UA322/ZtFfzitScea2VTnXGiGUYIQkeapq4MbunjLV34O7bqG77d5lfereo+B8JvO0KvCq4nc2MPbfu5/YMUceOX67MRdAN6r7c+5O37FN/bbjQfOP7xJr5EoQagPQkSap6QEfv2Vd+lovOQA3ii17bt7y8HhMca8DOu+gK+f6D2O/hm8fB0cc5l3ldWbt3iXkR7/C2848Fv38Y478+/hVy4l8o2rYPNKaN8D3vxD7PZffwW37uf1F4y4Gxa9DU+MSe09ktFj//D5un/0utccFfT9J+CtP8KXgcuPRz5KXduu/PyRzbj122jXupGrrZpINQgRyS+PjIR5L8Dln3oj3r5wJUz5Z8N9frEQ5jzl9RH0GwJVlXDQWX7HcsDcF7zxnyI32pWVx77fynneZcDPXuatX1Lp3WuxY6s3WGG77rBllbftigXeEOWdesOSaTD1ATjhN94+JaXeFKp9joV23by7u1fNhc/fhqMv8WI1g82rvZv3aqvh9Dugfbf6WBa8CnscsrOsts5x+8vzuODYvnRNMCNdImpiEpHC9tK19fdt7H0snP9c+t9j5uPeSX7AiNhtznk33jV230QLpAQhIoXNOe8Xt3PefBSlaj1PlvogRKSwmYU3D0mz6D4IEREJpQQhIiKhlCBERCSUEoSIiIRSghARkVAZTRBmdpKZzTWzBWZ2Vcj2cjN7zN/+gZn18ctPMLOpZjbTf/5mJuMUEZFYGUsQZlYK3AWcDPQHRplZ/6jdxgBrnXP7ALcDN/vlq4DTnXMHAaOBcZmKU0REwmWyBnE4sMA5t9A5Vw2MJ3bA8uHAg/7y48AwMzPn3EfOuaV++WygjZnpImcRkSzKZILoBXwZWK/yy0L3cc7VAOuBblH7fBf4yDm3PUNxiohIiEzeSR02SWv0uB4J9zGzAXjNTieGvoHZhcCFAHvttVfTohQRkVCZrEFUAXsG1nsDS+PtY2ZlQCdgjb/eG3gKOM85FzqjiHPuHudchXOuokePHmkOX0SkuGUyQUwB9jWzvmbWGhgJTIzaZyJeJzTAWcBrzjlnZp2B54CrnXPvZDBGERGJI2MJwu9TuASYBHwCTHDOzTazG8zsDH+3+4BuZrYAuByIXAp7CbAPcK2ZTfcfu2YqVhERiaXhvkVEilii4b51J7WIiIRSghARkVBKECIiEkoJQkREQilBiIhIKCUIEREJpQQhIiKhlCBERCSUEoSIiIRSghARkVBKECIiEkoJQkREQilBiIhIKCUIEREJpQQhIiKhlCBERCSUEoSIiIRSghARkVBKECIiEqpg5qQ2s5XA4ma8RHdgVZrCSSfFlRrFlRrFlZpCjGtv51yPsA0FkyCay8wq403cnUuKKzWKKzWKKzXFFpeamEREJJQShIiIhFKCqHdPrgOIQ3GlRnGlRnGlpqjiUh+EiIiEUg1CRERCKUGIiEiook8QZnaSmc01swVmdlWW33tPM3vdzD4xs9lm9n9++VgzW2Jm0/3HKYFjrvZjnWtm385gbIvMbKb//pV+WVcze9nM5vvPXfxyM7M7/Lg+NrPBGYppv8BnMt3MNpjZZbn4vMzsfjNbYWazAmUpfz5mNtrff76Zjc5QXH80s0/9937KzDr75X3MbGvgc/tH4JhD/f//BX7sloG4Uv5/S/f3NU5cjwViWmRm0/3ybH5e8c4N2f0bc84V7QMoBT4D+gGtgRlA/yy+/x7AYH+5IzAP6A+MBa4I2b+/H2M50NePvTRDsS0CukeV3QJc5S9fBdzsL58CvAAYcCTwQZb+774C9s7F5wUcDwwGZjX18wG6Agv95y7+cpcMxHUiUOYv3xyIq09wv6jX+RA4yo/5BeDkDMSV0v9bJr6vYXFFbf8TcF0OPq9454as/o0Vew3icGCBc26hc64aGA8Mz9abO+eWOeem+csbgU+AXgkOGQ6Md85td859DizA+zdky3DgQX/5QeDMQPlDzvM+0NnM9shwLMOAz5xzie6ez9jn5Zx7C1gT8n6pfD7fBl52zq1xzq0FXgZOSndczrmXnHM1/ur7QO9Er+HHtotz7j3nnWUeCvxb0hZXAvH+39L+fU0Ul18L+B7waKLXyNDnFe/ckNW/sWJPEL2ALwPrVSQ+QWeMmfUBBgEf+EWX+FXF+yPVSLIbrwNeMrOpZnahX7abc24ZeH/AwK45iCtiJA2/uLn+vCD1zycXn9sFeL80I/qa2Udm9qaZHeeX9fJjyUZcqfy/ZfvzOg5Y7pybHyjL+ucVdW7I6t9YsSeIsHbCrF/3a2YdgCeAy5xzG4C/A18DDgGW4VVzIbvxHuOcGwycDPzUzI5PsG9WP0czaw2cAfzHL2oJn1ci8eLI9uf2a6AG+LdftAzYyzk3CLgceMTMdsliXKn+v2X7/3MUDX+EZP3zCjk3xN01TgzNiq3YE0QVsGdgvTewNJsBmFkrvD+AfzvnngRwzi13ztU65+qAe6lvFslavM65pf7zCuApP4blkaYj/3lFtuPynQxMc84t92PM+eflS/XzyVp8fufkacD3/WYQ/Cac1f7yVLz2/a/7cQWboTISVxP+37L5eZUB3wEeC8Sb1c8r7NxAlv/Gij1BTAH2NbO+/q/SkcDEbL2538Z5H/CJc+62QHmw/X4EELnCYiIw0szKzawvsC9e51i642pvZh0jy3idnLP8949cBTEaeCYQ13n+lRRHAusj1eAMafDLLtefV0Cqn88k4EQz6+I3r5zol6WVmZ0E/BI4wzm3JVDew8xK/eV+eJ/PQj+2jWZ2pP83el7g35LOuFL9f8vm9/VbwKfOuZ1NR9n8vOKdG8j231hzetoL4YHX+z8P79fAr7P83sfiVfc+Bqb7j1OAccBMv3wisEfgmF/7sc6lmVdKJIirH94VIjOA2ZHPBegGvArM95+7+uUG3OXHNROoyOBn1g5YDXQKlGX988JLUMuAHXi/0sY05fPB6xNY4D/Oz1BcC/DaoSN/Y//w9/2u//87A5gGnB54nQq8E/ZnwJ34oy6kOa6U/9/S/X0Ni8svfwC4KGrfbH5e8c4NWf0b01AbIiISqtibmEREJA4lCBERCaUEISIioZQgREQklBKEiIiEUoIQSYGZ1VrDEWXTNgKweaOFzmp8T5HsKMt1ACJ5Zqtz7pBcByGSDapBiKSBefMG3GxmH/qPffzyvc3sVX9AulfNbC+/fDfz5maY4T+O9l+q1MzuNW8OgJfMrG3O/lFS9JQgRFLTNqqJ6ZzAtg3OucPx7qT9s192J94wzAfjDZJ3h19+B/Cmc24g3nwEs/3yfYG7nHMDgHV4d++K5ITupBZJgZltcs51CClfBHzTObfQH2TtK+dcNzNbhTeExA6/fJlzrruZrQR6O+e2B16jD97Y/fv6678EWjnnbsz8v0wklmoQIunj4izH2yfM9sByLeonlBxSghBJn3MCz+/5y+/ijToK8H1gsr/8KnAxgJmV+vMKiLQo+nUikpq25k9i73vRORe51LXczD7A++E1yi+7FLjfzH4BrATO98v/D7jHzMbg1RQuxhtVVKTFUB+ESBr4fRAVzrlVuY5FJF3UxCQiIqFUgxARkVCqQYiISCglCBERCaUEISIioZQgREQklBKEiIiE+v/k+EiLa6r6GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.history.history\n",
    "plotter(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = model.predict([num_data_test, cat_test_x])\n",
    "submit_data = np.exp(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = submit_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_index\n",
    "submission['SalePrice'] = submit_data\n",
    "print(\"Saving ...\")\n",
    "submission.to_csv(\"submission_NN_regression.csv\", index=False)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
